{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "title-markdown",
            "metadata": {},
            "source": [
                "# LDA Hyperparameter Tuning\n",
                "\n",
                "Grid-search hyperparameter tuning for Gensim LDA across subjects (cs, math, physics).\n",
                "Evaluates coherence (C_v) and saves the best model immediately when a new best is found."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "imports",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import gc\n",
                "import pickle\n",
                "import time\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "from pathlib import Path\n",
                "from itertools import product\n",
                "from gensim.corpora import Dictionary\n",
                "from gensim.models import LdaMulticore\n",
                "from gensim.models.coherencemodel import CoherenceModel\n",
                "import warnings\n",
                "\n",
                "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "config-markdown",
            "metadata": {},
            "source": [
                "## Configuration"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "config",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Subjects: ['math']\n",
                        "Output directory: tunning\n"
                    ]
                }
            ],
            "source": [
                "LIST_SUBJECT = [ \"math\"]\n",
                "\n",
                "BASE_DIR = Path(\"../../dataset\")\n",
                "TUNNING_DIR = Path(\"./tunning\")\n",
                "VERSION = \"v1\"\n",
                "\n",
                "for subject in LIST_SUBJECT:\n",
                "    (TUNNING_DIR / subject).mkdir(parents=True, exist_ok=True)\n",
                "\n",
                "print(f\"Subjects: {LIST_SUBJECT}\")\n",
                "print(f\"Output directory: {TUNNING_DIR}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "grid-markdown",
            "metadata": {},
            "source": [
                "## Hyperparameter Grid"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "grid",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Tunable parameters: ['num_topics', 'alpha', 'eta', 'passes']\n",
                        "Total parameter combinations: 16\n",
                        "Total runs (combinations x subjects): 16\n"
                    ]
                }
            ],
            "source": [
                "\n",
                "PARAM_GRID = {\n",
                "    \"num_topics\": [25, 50, 75, 150],   \n",
                "    \"alpha\": [\"asymmetric\", 0.01], \n",
                "    \"eta\": [\"auto\", 0.01],             \n",
                "    \"passes\": [15],                   \n",
                "}\n",
                "\n",
                "FIXED_PARAMS = {\n",
                "    \"chunksize\": 2000,\n",
                "    \"random_state\": 42,\n",
                "    \"workers\": 5,\n",
                "}\n",
                "\n",
                "keys = list(PARAM_GRID.keys())\n",
                "values = list(PARAM_GRID.values())\n",
                "all_combos = list(product(*values))\n",
                "\n",
                "print(f\"Tunable parameters: {keys}\")\n",
                "print(f\"Total parameter combinations: {len(all_combos)}\")\n",
                "print(f\"Total runs (combinations x subjects): {len(all_combos) * len(LIST_SUBJECT)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "helpers-markdown",
            "metadata": {},
            "source": [
                "## Helper Functions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "helper-functions",
            "metadata": {},
            "outputs": [],
            "source": [
                "def load_and_preprocess(subject: str):\n",
                "    file_path = BASE_DIR / subject / \"emb\" / f\"{VERSION}.csv\"\n",
                "    df = pd.read_csv(file_path)\n",
                "    \n",
                "    token_list = df[\"text\"].tolist()\n",
                "    tokens = [x.split() for x in token_list]\n",
                "\n",
                "    dictionary = Dictionary(tokens)\n",
                "    dictionary.filter_extremes(no_below=15, no_above=0.5)\n",
                "    dictionary.compactify()\n",
                "\n",
                "    corpus = [dictionary.doc2bow(text) for text in tokens]\n",
                "\n",
                "    return df, tokens, dictionary, corpus\n",
                "\n",
                "\n",
                "def train_lda(corpus, dictionary, params: dict) -> LdaMulticore:\n",
                "    model = LdaMulticore(\n",
                "        corpus=corpus,\n",
                "        id2word=dictionary,\n",
                "        num_topics=params[\"num_topics\"],\n",
                "        alpha=params[\"alpha\"],\n",
                "        eta=params[\"eta\"],\n",
                "        passes=params[\"passes\"],\n",
                "        chunksize=FIXED_PARAMS[\"chunksize\"],\n",
                "        random_state=FIXED_PARAMS[\"random_state\"],\n",
                "        workers=FIXED_PARAMS[\"workers\"],\n",
                "    )\n",
                "    return model\n",
                "\n",
                "\n",
                "def calculate_coherence(model: LdaMulticore, texts, dictionary: Dictionary) -> float:\n",
                "    topic_tuples = model.show_topics(\n",
                "        num_topics=model.num_topics,\n",
                "        num_words=10,\n",
                "        formatted=False\n",
                "    )\n",
                "    topics = [[word for word, _ in words_probs] for _, words_probs in topic_tuples]\n",
                "\n",
                "    cm = CoherenceModel(\n",
                "        topics=topics,\n",
                "        texts=texts,\n",
                "        dictionary=dictionary,\n",
                "        coherence='c_v',\n",
                "        processes=5\n",
                "    )\n",
                "    return cm.get_coherence()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "load-data-markdown",
            "metadata": {},
            "source": [
                "## Load & Preprocess All Subjects"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "load-data",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loading math...\n",
                        "  math: 157,085 documents, 16,835 terms in dictionary\n",
                        "\n",
                        "Subjects ready: ['math']\n"
                    ]
                }
            ],
            "source": [
                "all_data = {}\n",
                "all_tokens = {}\n",
                "all_dictionaries = {}\n",
                "all_corpora = {}\n",
                "\n",
                "for subject in LIST_SUBJECT:\n",
                "    print(f\"Loading {subject}...\")\n",
                "    df, tokens, dictionary, corpus = load_and_preprocess(subject)\n",
                "    all_data[subject] = df\n",
                "    all_tokens[subject] = tokens\n",
                "    all_dictionaries[subject] = dictionary\n",
                "    all_corpora[subject] = corpus\n",
                "    print(f\"  {subject}: {len(df):,} documents, {len(dictionary):,} terms in dictionary\")\n",
                "\n",
                "print(f\"\\nSubjects ready: {list(all_data.keys())}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "tuning-markdown",
            "metadata": {},
            "source": [
                "## Hyperparameter Tuning Grid Search"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "id": "tuning-loop",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "======================================================================\n",
                        "Subject: MATH (157,085 documents)\n",
                        "======================================================================\n",
                        "\n",
                        "[1/16] math | k=25 α=asymmetric η=auto passes=15\n",
                        "  ⭐ NEW BEST | Coherence: 0.5598 (123.8s) → Saved to tunning/math/best_model.pkl\n",
                        "\n",
                        "[2/16] math | k=25 α=asymmetric η=0.01 passes=15\n",
                        "  ⭐ NEW BEST | Coherence: 0.5638 (140.7s) → Saved to tunning/math/best_model.pkl\n",
                        "\n",
                        "[3/16] math | k=25 α=0.01 η=auto passes=15\n",
                        "  ⭐ NEW BEST | Coherence: 0.5694 (126.6s) → Saved to tunning/math/best_model.pkl\n",
                        "\n",
                        "[4/16] math | k=25 α=0.01 η=0.01 passes=15\n",
                        "  ✓ Coherence: 0.5611 (142.7s) | Best: 0.5694\n",
                        "\n",
                        "[5/16] math | k=50 α=asymmetric η=auto passes=15\n",
                        "  ✓ Coherence: 0.5562 (223.4s) | Best: 0.5694\n",
                        "\n",
                        "[6/16] math | k=50 α=asymmetric η=0.01 passes=15\n",
                        "  ✓ Coherence: 0.5613 (227.2s) | Best: 0.5694\n",
                        "\n",
                        "[7/16] math | k=50 α=0.01 η=auto passes=15\n",
                        "  ✓ Coherence: 0.5559 (160.0s) | Best: 0.5694\n",
                        "\n",
                        "[8/16] math | k=50 α=0.01 η=0.01 passes=15\n",
                        "  ✓ Coherence: 0.5600 (191.5s) | Best: 0.5694\n",
                        "\n",
                        "[9/16] math | k=75 α=asymmetric η=auto passes=15\n",
                        "  ✓ Coherence: 0.5472 (397.5s) | Best: 0.5694\n",
                        "\n",
                        "[10/16] math | k=75 α=asymmetric η=0.01 passes=15\n",
                        "  ✓ Coherence: 0.5503 (286.5s) | Best: 0.5694\n",
                        "\n",
                        "[11/16] math | k=75 α=0.01 η=auto passes=15\n",
                        "  ✓ Coherence: 0.5420 (352.1s) | Best: 0.5694\n",
                        "\n",
                        "[12/16] math | k=75 α=0.01 η=0.01 passes=15\n",
                        "  ✓ Coherence: 0.5470 (238.2s) | Best: 0.5694\n",
                        "\n",
                        "[13/16] math | k=150 α=asymmetric η=auto passes=15\n",
                        "  ✓ Coherence: 0.5033 (332.2s) | Best: 0.5694\n",
                        "\n",
                        "[14/16] math | k=150 α=asymmetric η=0.01 passes=15\n",
                        "  ✓ Coherence: 0.4978 (388.1s) | Best: 0.5694\n",
                        "\n",
                        "[15/16] math | k=150 α=0.01 η=auto passes=15\n",
                        "  ✓ Coherence: 0.5021 (317.3s) | Best: 0.5694\n",
                        "\n",
                        "[16/16] math | k=150 α=0.01 η=0.01 passes=15\n",
                        "  ✓ Coherence: 0.4977 (370.2s) | Best: 0.5694\n",
                        "\n",
                        "======================================================================\n",
                        "✅ MATH COMPLETE | Best coherence: 0.5694\n",
                        "Results saved to: tunning/math/tuning_results.csv\n",
                        "Best model saved to: tunning/math/best_model.pkl\n",
                        "======================================================================\n"
                    ]
                }
            ],
            "source": [
                "total_runs = len(all_combos) * len(LIST_SUBJECT)\n",
                "run_counter = 0\n",
                "\n",
                "for subject in LIST_SUBJECT:\n",
                "    corpus = all_corpora[subject]\n",
                "    dictionary = all_dictionaries[subject]\n",
                "    tokens = all_tokens[subject]\n",
                "    n_docs = len(all_data[subject])\n",
                "\n",
                "    results_csv_path = TUNNING_DIR / subject / \"tuning_results.csv\"\n",
                "    best_model_path = TUNNING_DIR / subject / \"best_model.pkl\"\n",
                "    best_coherence = -1.0\n",
                "\n",
                "    existing_results = []\n",
                "    if results_csv_path.exists():\n",
                "        existing_df = pd.read_csv(results_csv_path)\n",
                "        existing_results = existing_df.to_dict('records')\n",
                "        if len(existing_results) > 0:\n",
                "            best_coherence = existing_df[\"coherence_cv\"].max()\n",
                "            print(f\"Resuming {subject}: {len(existing_results)} previous runs found, best coherence so far: {best_coherence:.4f}\")\n",
                "\n",
                "    results = existing_results.copy()\n",
                "\n",
                "    completed_param_sets = set()\n",
                "    for r in existing_results:\n",
                "        param_key = (r[\"num_topics\"], str(r[\"alpha\"]), str(r[\"eta\"]), r[\"passes\"])\n",
                "        completed_param_sets.add(param_key)\n",
                "\n",
                "    print(f\"\\n{'='*70}\")\n",
                "    print(f\"Subject: {subject.upper()} ({n_docs:,} documents)\")\n",
                "    print(f\"{'='*70}\")\n",
                "\n",
                "    for combo in all_combos:\n",
                "        run_counter += 1\n",
                "        params = dict(zip(keys, combo))\n",
                "\n",
                "        param_key = (params[\"num_topics\"], str(params[\"alpha\"]), str(params[\"eta\"]), params[\"passes\"])\n",
                "        if param_key in completed_param_sets:\n",
                "            continue\n",
                "\n",
                "        print(f\"\\n[{run_counter}/{total_runs}] {subject} | \"\n",
                "              f\"k={params['num_topics']} α={params['alpha']} η={params['eta']} \"\n",
                "              f\"passes={params['passes']}\")\n",
                "\n",
                "        try:\n",
                "            start_time = time.time()\n",
                "\n",
                "            model = train_lda(corpus, dictionary, params)\n",
                "            coherence = calculate_coherence(model, tokens, dictionary)\n",
                "\n",
                "            elapsed = time.time() - start_time\n",
                "\n",
                "            result_row = {\n",
                "                \"subject\": subject,\n",
                "                \"num_topics\": params[\"num_topics\"],\n",
                "                \"alpha\": str(params[\"alpha\"]),\n",
                "                \"eta\": str(params[\"eta\"]),\n",
                "                \"passes\": params[\"passes\"],\n",
                "                \"chunksize\": FIXED_PARAMS[\"chunksize\"],\n",
                "                \"random_state\": FIXED_PARAMS[\"random_state\"],\n",
                "                \"workers\": FIXED_PARAMS[\"workers\"],\n",
                "                \"coherence_cv\": coherence,\n",
                "                \"time_seconds\": round(elapsed, 1),\n",
                "            }\n",
                "            results.append(result_row)\n",
                "\n",
                "            is_new_best = coherence > best_coherence\n",
                "            if is_new_best:\n",
                "                best_coherence = coherence\n",
                "                with open(best_model_path, \"wb\") as f:\n",
                "                    pickle.dump(model, f)\n",
                "                print(f\"  ⭐ NEW BEST | Coherence: {coherence:.4f} ({elapsed:.1f}s) → Saved to {best_model_path}\")\n",
                "            else:\n",
                "                print(f\"  ✓ Coherence: {coherence:.4f} ({elapsed:.1f}s) | Best: {best_coherence:.4f}\")\n",
                "\n",
                "            pd.DataFrame(results).to_csv(results_csv_path, index=False)\n",
                "\n",
                "            del model\n",
                "            gc.collect()\n",
                "\n",
                "        except Exception as e:\n",
                "            print(f\"  ✗ ERROR: {e}\")\n",
                "            result_row = {\n",
                "                \"subject\": subject,\n",
                "                \"num_topics\": params[\"num_topics\"],\n",
                "                \"alpha\": str(params[\"alpha\"]),\n",
                "                \"eta\": str(params[\"eta\"]),\n",
                "                \"passes\": params[\"passes\"],\n",
                "                \"chunksize\": FIXED_PARAMS[\"chunksize\"],\n",
                "                \"random_state\": FIXED_PARAMS[\"random_state\"],\n",
                "                \"workers\": FIXED_PARAMS[\"workers\"],\n",
                "                \"coherence_cv\": None,\n",
                "                \"time_seconds\": None,\n",
                "            }\n",
                "            results.append(result_row)\n",
                "            pd.DataFrame(results).to_csv(results_csv_path, index=False)\n",
                "            gc.collect()\n",
                "\n",
                "    print(f\"\\n{'='*70}\")\n",
                "    print(f\"✅ {subject.upper()} COMPLETE | Best coherence: {best_coherence:.4f}\")\n",
                "    print(f\"Results saved to: {results_csv_path}\")\n",
                "    print(f\"Best model saved to: {best_model_path}\")\n",
                "    print(f\"{'='*70}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "summary-markdown",
            "metadata": {},
            "source": [
                "## Summary: Best Parameters Per Subject"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "id": "summary",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "==========================================================================================\n",
                        "FINAL RESULTS: Best Parameters Per Subject\n",
                        "==========================================================================================\n",
                        "\n",
                        "──────────────────────────────────────────────────\n",
                        "  Subject: MATH\n",
                        "  Total runs: 16\n",
                        "  Best Coherence (C_v): 0.5694\n",
                        "  Parameters:\n",
                        "    num_topics = 25\n",
                        "    alpha      = 0.01\n",
                        "    eta        = auto\n",
                        "    passes     = 15\n",
                        "    chunksize  = 2000\n",
                        "──────────────────────────────────────────────────\n",
                        "\n",
                        "==========================================================================================\n",
                        "Top 5 configurations per subject:\n",
                        "==========================================================================================\n",
                        "\n",
                        "MATH:\n",
                        " num_topics      alpha  eta  passes  coherence_cv  time_seconds\n",
                        "         25       0.01 auto      15      0.569442         126.6\n",
                        "         25 asymmetric 0.01      15      0.563847         140.7\n",
                        "         50 asymmetric 0.01      15      0.561318         227.2\n",
                        "         25       0.01 0.01      15      0.561129         142.7\n",
                        "         50       0.01 0.01      15      0.559955         191.5\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "print(\"\\n\" + \"=\" * 90)\n",
                "print(\"FINAL RESULTS: Best Parameters Per Subject\")\n",
                "print(\"=\" * 90)\n",
                "\n",
                "for subject in LIST_SUBJECT:\n",
                "    results_csv_path = TUNNING_DIR / subject / \"tuning_results.csv\"\n",
                "    if not results_csv_path.exists():\n",
                "        print(f\"\\n{subject.upper()}: No results found\")\n",
                "        continue\n",
                "\n",
                "    df = pd.read_csv(results_csv_path)\n",
                "    df_valid = df.dropna(subset=[\"coherence_cv\"])\n",
                "\n",
                "    if len(df_valid) == 0:\n",
                "        print(f\"\\n{subject.upper()}: No valid results\")\n",
                "        continue\n",
                "\n",
                "    best_row = df_valid.loc[df_valid[\"coherence_cv\"].idxmax()]\n",
                "\n",
                "    print(f\"\\n{'─'*50}\")\n",
                "    print(f\"  Subject: {subject.upper()}\")\n",
                "    print(f\"  Total runs: {len(df_valid)}\")\n",
                "    print(f\"  Best Coherence (C_v): {best_row['coherence_cv']:.4f}\")\n",
                "    print(f\"  Parameters:\")\n",
                "    print(f\"    num_topics = {best_row['num_topics']}\")\n",
                "    print(f\"    alpha      = {best_row['alpha']}\")\n",
                "    print(f\"    eta        = {best_row['eta']}\")\n",
                "    print(f\"    passes     = {best_row['passes']}\")\n",
                "    print(f\"    chunksize  = {best_row['chunksize']}\")\n",
                "    print(f\"{'─'*50}\")\n",
                "\n",
                "print(\"\\n\" + \"=\" * 90)\n",
                "print(\"Top 5 configurations per subject:\")\n",
                "print(\"=\" * 90)\n",
                "\n",
                "for subject in LIST_SUBJECT:\n",
                "    results_csv_path = TUNNING_DIR / subject / \"tuning_results.csv\"\n",
                "    if not results_csv_path.exists():\n",
                "        continue\n",
                "\n",
                "    df = pd.read_csv(results_csv_path)\n",
                "    df_valid = df.dropna(subset=[\"coherence_cv\"]).sort_values(\"coherence_cv\", ascending=False)\n",
                "\n",
                "    print(f\"\\n{subject.upper()}:\")\n",
                "    print(df_valid[[\"num_topics\", \"alpha\", \"eta\", \"passes\", \"coherence_cv\", \"time_seconds\"]].head(5).to_string(index=False))\n",
                "    print()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.11"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
