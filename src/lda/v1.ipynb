{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e28db6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from gensim.parsing.preprocessing import STOPWORDS as gensim_stopwords\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import LdaModel\n",
    "import os,pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e812ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "CS = \"cs\"\n",
    "MATH = \"math\"\n",
    "PHYSICS = \"physics\"\n",
    "SUBJECT = CS\n",
    "LIST_SUBJECT = [CS, MATH , PHYSICS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2474edc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "for i in LIST_SUBJECT:\n",
    "    data[i] = pd.read_csv(f\"../../dataset/{i}/emb/v1.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b95ce77",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "243281b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = {}\n",
    "for i in LIST_SUBJECT:\n",
    "    token_list = data[i][\"text\"].tolist()\n",
    "    tokens[i] = [x.split() for x in token_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6415704a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import ast\n",
    "# tokens = {}\n",
    "# for i in LIST_SUBJECT:\n",
    "#   token_list = data[i][\"text\"].tolist()\n",
    "#   tokens[i] = [ast.literal_eval(x) for x in token_list]\n",
    "  # print(token_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ac196a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df: pd.DataFrame, token):\n",
    "    df['year'] = pd.to_datetime(df[\"submitted_date\"]).dt.year\n",
    "    slice_counts = df.groupby('year').size()\n",
    "    time_slices = slice_counts.tolist()\n",
    "    year_list = slice_counts.index.tolist()\n",
    "    dictionary = Dictionary(token)\n",
    "    dictionary.filter_extremes(no_below=15, no_above=0.5, keep_n=100000)\n",
    "    dictionary.compactify()\n",
    "\n",
    "    corpus_sorted = [dictionary.doc2bow(text) for text in token]\n",
    "\n",
    "    print(f\"Sample total: {len(df)} docs across {len(year_list)} years\")\n",
    "    print(f\"Time slices: {time_slices}\")\n",
    "\n",
    "    return corpus_sorted, dictionary, time_slices, year_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a72daba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample total: 165756 docs across 26 years\n",
      "Time slices: [488, 594, 648, 825, 948, 1000, 1000, 1000, 1000, 1000, 1362, 1622, 2254, 2719, 2989, 3345, 4280, 5534, 7470, 9549, 12352, 14096, 14993, 17825, 23529, 33334]\n",
      "Sample total: 126192 docs across 26 years\n",
      "Time slices: [1000, 1000, 1000, 1069, 1289, 1538, 1876, 2253, 2478, 2778, 3178, 3719, 4236, 4805, 5185, 5747, 6120, 6419, 6803, 7250, 7992, 8144, 8131, 8640, 10291, 13251]\n",
      "Sample total: 28965 docs across 23 years\n",
      "Time slices: [2, 2, 1, 6, 293, 520, 556, 798, 1000, 1000, 1000, 1000, 1000, 1000, 1163, 1936, 2845, 3202, 2220, 1929, 1986, 2322, 3184]\n"
     ]
    }
   ],
   "source": [
    "corpus_sorted = {}\n",
    "dictionary = {}\n",
    "time_slices = {}\n",
    "year_list = {}\n",
    "for i in LIST_SUBJECT:\n",
    "  corpus_sorted[i], dictionary[i], time_slices[i], year_list[i] = preprocess_for_dtm(data[i], tokens[i])\n",
    "  dictionary[i].save(f\"model_results/dictionary_{i}.gensim\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633edff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Checkpoint saved] model_results/lda_global_cs_num_topic_100.pkl\n",
      "[Checkpoint saved] model_results/lda_global_cs_num_topic_150.pkl\n",
      "[Checkpoint saved] model_results/lda_global_cs_num_topic_200.pkl\n",
      "[Checkpoint saved] model_results/lda_global_math_num_topic_100.pkl\n",
      "[Checkpoint saved] model_results/lda_global_math_num_topic_150.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-26:\n",
      "Process ForkPoolWorker-29:\n",
      "Process ForkPoolWorker-30:\n",
      "Process ForkPoolWorker-28:\n",
      "Process ForkPoolWorker-27:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nedo/.local/share/uv/python/cpython-3.13.11-linux-x86_64-gnu/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/home/nedo/.local/share/uv/python/cpython-3.13.11-linux-x86_64-gnu/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/home/nedo/.local/share/uv/python/cpython-3.13.11-linux-x86_64-gnu/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/home/nedo/.local/share/uv/python/cpython-3.13.11-linux-x86_64-gnu/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/home/nedo/.local/share/uv/python/cpython-3.13.11-linux-x86_64-gnu/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/home/nedo/.local/share/uv/python/cpython-3.13.11-linux-x86_64-gnu/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nedo/.local/share/uv/python/cpython-3.13.11-linux-x86_64-gnu/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nedo/.local/share/uv/python/cpython-3.13.11-linux-x86_64-gnu/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nedo/.local/share/uv/python/cpython-3.13.11-linux-x86_64-gnu/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nedo/.local/share/uv/python/cpython-3.13.11-linux-x86_64-gnu/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nedo/.local/share/uv/python/cpython-3.13.11-linux-x86_64-gnu/lib/python3.13/multiprocessing/pool.py\", line 109, in worker\n",
      "    initializer(*initargs)\n",
      "    ~~~~~~~~~~~^^^^^^^^^^^\n",
      "  File \"/home/nedo/.local/share/uv/python/cpython-3.13.11-linux-x86_64-gnu/lib/python3.13/multiprocessing/pool.py\", line 109, in worker\n",
      "    initializer(*initargs)\n",
      "    ~~~~~~~~~~~^^^^^^^^^^^\n",
      "  File \"/home/nedo/.local/share/uv/python/cpython-3.13.11-linux-x86_64-gnu/lib/python3.13/multiprocessing/pool.py\", line 109, in worker\n",
      "    initializer(*initargs)\n",
      "    ~~~~~~~~~~~^^^^^^^^^^^\n",
      "  File \"/home/nedo/.local/share/uv/python/cpython-3.13.11-linux-x86_64-gnu/lib/python3.13/multiprocessing/pool.py\", line 109, in worker\n",
      "    initializer(*initargs)\n",
      "    ~~~~~~~~~~~^^^^^^^^^^^\n",
      "  File \"/home/nedo/.local/share/uv/python/cpython-3.13.11-linux-x86_64-gnu/lib/python3.13/multiprocessing/pool.py\", line 109, in worker\n",
      "    initializer(*initargs)\n",
      "    ~~~~~~~~~~~^^^^^^^^^^^\n",
      "  File \"/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/gensim/models/ldamulticore.py\", line 344, in worker_e_step\n",
      "    worker_lda.sync_state()\n",
      "    ~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/gensim/models/ldamulticore.py\", line 346, in worker_e_step\n",
      "    worker_lda.do_estep(chunk)  # TODO: auto-tune alpha?\n",
      "    ~~~~~~~~~~~~~~~~~~~^^^^^^^\n",
      "  File \"/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/gensim/models/ldamulticore.py\", line 346, in worker_e_step\n",
      "    worker_lda.do_estep(chunk)  # TODO: auto-tune alpha?\n",
      "    ~~~~~~~~~~~~~~~~~~~^^^^^^^\n",
      "  File \"/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/gensim/models/ldamulticore.py\", line 346, in worker_e_step\n",
      "    worker_lda.do_estep(chunk)  # TODO: auto-tune alpha?\n",
      "    ~~~~~~~~~~~~~~~~~~~^^^^^^^\n",
      "  File \"/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/gensim/models/ldamulticore.py\", line 346, in worker_e_step\n",
      "    worker_lda.do_estep(chunk)  # TODO: auto-tune alpha?\n",
      "    ~~~~~~~~~~~~~~~~~~~^^^^^^^\n",
      "  File \"/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/gensim/models/ldamodel.py\", line 636, in sync_state\n",
      "    self.expElogbeta = np.exp(current_Elogbeta)\n",
      "                       ~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/gensim/models/ldamodel.py\", line 769, in do_estep\n",
      "    gamma, sstats = self.inference(chunk, collect_sstats=True)\n",
      "                    ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/gensim/models/ldamodel.py\", line 769, in do_estep\n",
      "    gamma, sstats = self.inference(chunk, collect_sstats=True)\n",
      "                    ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/gensim/models/ldamodel.py\", line 769, in do_estep\n",
      "    gamma, sstats = self.inference(chunk, collect_sstats=True)\n",
      "                    ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/gensim/models/ldamodel.py\", line 769, in do_estep\n",
      "    gamma, sstats = self.inference(chunk, collect_sstats=True)\n",
      "                    ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "  File \"/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/gensim/models/ldamodel.py\", line 734, in inference\n",
      "    sstats[:, ids] += np.outer(expElogthetad.T, cts / phinorm)\n",
      "                      ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/gensim/models/ldamodel.py\", line 712, in inference\n",
      "    phinorm = np.dot(expElogthetad, expElogbetad) + epsilon\n",
      "              ~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/gensim/models/ldamodel.py\", line 734, in inference\n",
      "    sstats[:, ids] += np.outer(expElogthetad.T, cts / phinorm)\n",
      "                      ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/gensim/models/ldamodel.py\", line 734, in inference\n",
      "    sstats[:, ids] += np.outer(expElogthetad.T, cts / phinorm)\n",
      "    ~~~~~~^^^^^^^^\n",
      "  File \"/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/numpy/_core/numeric.py\", line 995, in outer\n",
      "    return multiply(a.ravel()[:, newaxis], b.ravel()[newaxis, :], out)\n",
      "  File \"/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/numpy/_core/numeric.py\", line 906, in _outer_dispatcher\n",
      "    def _outer_dispatcher(a, b, out=None):\n",
      "    \n",
      "  File \"/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/numpy/_core/multiarray.py\", line 769, in dot\n",
      "    @array_function_from_c_func_and_dispatcher(_multiarray_umath.dot)\n",
      "    \n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m LIST_SUBJECT:\n\u001b[32m      4\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m topic_range:\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m         lda = \u001b[43mLdaMulticore\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcorpus\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcorpus_sorted\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m            \u001b[49m\u001b[43mid2word\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdictionary\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnum_topics\u001b[49m\u001b[43m=\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpasses\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m15\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m         \u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m42\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m            \u001b[49m\u001b[43mworkers\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m           \u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m         ckpt_path = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mmodel_results/lda_global_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_num_topic_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.pkl\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     14\u001b[39m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(ckpt_path, \u001b[33m\"\u001b[39m\u001b[33mwb\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/gensim/models/ldamulticore.py:186\u001b[39m, in \u001b[36mLdaMulticore.__init__\u001b[39m\u001b[34m(self, corpus, num_topics, id2word, workers, chunksize, passes, batch, alpha, eta, decay, offset, eval_every, iterations, gamma_threshold, random_state, minimum_probability, minimum_phi_value, per_word_topics, dtype)\u001b[39m\n\u001b[32m    183\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(alpha, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m alpha == \u001b[33m'\u001b[39m\u001b[33mauto\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m    184\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mauto-tuning alpha not implemented in LdaMulticore; use plain LdaModel.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m186\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mLdaMulticore\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    187\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcorpus\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcorpus\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_topics\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_topics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    188\u001b[39m \u001b[43m    \u001b[49m\u001b[43mid2word\u001b[49m\u001b[43m=\u001b[49m\u001b[43mid2word\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpasses\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpasses\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m=\u001b[49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meta\u001b[49m\u001b[43m=\u001b[49m\u001b[43meta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    189\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecay\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[43m=\u001b[49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_every\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_every\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterations\u001b[49m\u001b[43m=\u001b[49m\u001b[43miterations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    190\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgamma_threshold\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgamma_threshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mminimum_probability\u001b[49m\u001b[43m=\u001b[49m\u001b[43mminimum_probability\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    191\u001b[39m \u001b[43m    \u001b[49m\u001b[43mminimum_phi_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mminimum_phi_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mper_word_topics\u001b[49m\u001b[43m=\u001b[49m\u001b[43mper_word_topics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    192\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/gensim/models/ldamodel.py:522\u001b[39m, in \u001b[36mLdaModel.__init__\u001b[39m\u001b[34m(self, corpus, num_topics, id2word, distributed, chunksize, passes, update_every, alpha, eta, decay, offset, eval_every, iterations, gamma_threshold, minimum_probability, random_state, ns_conf, minimum_phi_value, per_word_topics, callbacks, dtype)\u001b[39m\n\u001b[32m    520\u001b[39m use_numpy = \u001b[38;5;28mself\u001b[39m.dispatcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    521\u001b[39m start = time.time()\n\u001b[32m--> \u001b[39m\u001b[32m522\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcorpus\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunks_as_numpy\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_numpy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    523\u001b[39m \u001b[38;5;28mself\u001b[39m.add_lifecycle_event(\n\u001b[32m    524\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcreated\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    525\u001b[39m     msg=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mtrained \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime.time()\u001b[38;5;250m \u001b[39m-\u001b[38;5;250m \u001b[39mstart\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33ms\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    526\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/gensim/models/ldamulticore.py:316\u001b[39m, in \u001b[36mLdaMulticore.update\u001b[39m\u001b[34m(self, corpus, chunks_as_numpy)\u001b[39m\n\u001b[32m    312\u001b[39m \u001b[38;5;66;03m# endfor single corpus pass\u001b[39;00m\n\u001b[32m    313\u001b[39m \n\u001b[32m    314\u001b[39m \u001b[38;5;66;03m# wait for all outstanding jobs to finish\u001b[39;00m\n\u001b[32m    315\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m queue_size[\u001b[32m0\u001b[39m] > \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m316\u001b[39m     \u001b[43mprocess_result_queue\u001b[49m\u001b[43m(\u001b[49m\u001b[43mforce\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    318\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m reallen != lencorpus:\n\u001b[32m    319\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33minput corpus size changed during training (don\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt use generators as input)\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/gensim/models/ldamulticore.py:275\u001b[39m, in \u001b[36mLdaMulticore.update.<locals>.process_result_queue\u001b[39m\u001b[34m(force)\u001b[39m\n\u001b[32m    273\u001b[39m merged_new = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    274\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m result_queue.empty():\n\u001b[32m--> \u001b[39m\u001b[32m275\u001b[39m     other.merge(\u001b[43mresult_queue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    276\u001b[39m     queue_size[\u001b[32m0\u001b[39m] -= \u001b[32m1\u001b[39m\n\u001b[32m    277\u001b[39m     merged_new = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.13.11-linux-x86_64-gnu/lib/python3.13/multiprocessing/queues.py:101\u001b[39m, in \u001b[36mQueue.get\u001b[39m\u001b[34m(self, block, timeout)\u001b[39m\n\u001b[32m     99\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m block \u001b[38;5;129;01mand\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    100\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._rlock:\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m         res = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_recv_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    102\u001b[39m     \u001b[38;5;28mself\u001b[39m._sem.release()\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.13.11-linux-x86_64-gnu/lib/python3.13/multiprocessing/connection.py:216\u001b[39m, in \u001b[36m_ConnectionBase.recv_bytes\u001b[39m\u001b[34m(self, maxlength)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m maxlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m maxlength < \u001b[32m0\u001b[39m:\n\u001b[32m    215\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mnegative maxlength\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m buf = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_recv_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaxlength\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m buf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    218\u001b[39m     \u001b[38;5;28mself\u001b[39m._bad_message_length()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.13.11-linux-x86_64-gnu/lib/python3.13/multiprocessing/connection.py:437\u001b[39m, in \u001b[36mConnection._recv_bytes\u001b[39m\u001b[34m(self, maxsize)\u001b[39m\n\u001b[32m    435\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m maxsize \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m size > maxsize:\n\u001b[32m    436\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m437\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_recv\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.13.11-linux-x86_64-gnu/lib/python3.13/multiprocessing/connection.py:395\u001b[39m, in \u001b[36mConnection._recv\u001b[39m\u001b[34m(self, size, read)\u001b[39m\n\u001b[32m    393\u001b[39m remaining = size\n\u001b[32m    394\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m remaining > \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m395\u001b[39m     chunk = \u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    396\u001b[39m     n = \u001b[38;5;28mlen\u001b[39m(chunk)\n\u001b[32m    397\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n == \u001b[32m0\u001b[39m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from gensim.models import LdaMulticore, LdaModel\n",
    "\n",
    "topic_range = range(100, 201, 50)\n",
    "for i in LIST_SUBJECT:\n",
    "    for k in topic_range:\n",
    "        lda = LdaMulticore(\n",
    "            corpus=corpus_sorted[i],\n",
    "            id2word=dictionary[i],\n",
    "            num_topics=k,\n",
    "            passes=15,         \n",
    "            random_state=42,\n",
    "            workers=5\n",
    "                       \n",
    "        )\n",
    "        ckpt_path = f\"model_results/lda_global_{i}_num_topic_{k}.pkl\"\n",
    "        with open(ckpt_path, \"wb\") as f:\n",
    "            pickle.dump(lda, f)\n",
    "        print(f\"[Checkpoint saved] {ckpt_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37c8932",
   "metadata": {},
   "source": [
    "# Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad84eff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA model loaded.\n"
     ]
    }
   ],
   "source": [
    "model_path = f\"model_results/lda_global_{SUBJECT}_num_topic_{50}.pkl\"\n",
    "try:\n",
    "    with open(model_path, \"rb\") as f:\n",
    "        loaded_lda_model = pickle.load(f)\n",
    "    print(\"LDA model loaded.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERROR: Model file not found at {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9150461",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "<b>Topic 24</b><br><b>Top words:</b><br>be, can, not, it, or<br>which, one, such, they, how<br>but, have, these, more, some<br>Year: %{x}<br>Weight: %{y:.4f}<extra></extra>",
         "mode": "lines+markers",
         "name": "Topic 24",
         "type": "scatter",
         "x": [
          2000,
          2001,
          2002,
          2003,
          2004,
          2005,
          2006,
          2007,
          2008,
          2009,
          2010,
          2011,
          2012,
          2013,
          2014,
          2015,
          2016,
          2017,
          2018,
          2019,
          2020,
          2021,
          2022,
          2023,
          2024,
          2025
         ],
         "y": {
          "bdata": "0lQUPojE6z3++gA+vNH4Pe1H7D22IdA91P7VPaRSvT1kM8k9biPUPa3syj0zIso9fxW9PUDTvj2ZfrM95CemPadYoD0RR5Y99kSWPZn/jj2Zq4o9VYiBPepoez2sGF49Y64pPWT09zw=",
          "dtype": "f4"
         }
        },
        {
         "hovertemplate": "<b>Topic 42</b><br><b>Top words:</b><br>algorithm, problem, algorithms, problems, optimization<br>search, based, method, proposed, solution<br>approach, be, which, can, optimal<br>Year: %{x}<br>Weight: %{y:.4f}<extra></extra>",
         "mode": "lines+markers",
         "name": "Topic 42",
         "type": "scatter",
         "x": [
          2000,
          2001,
          2002,
          2003,
          2004,
          2005,
          2006,
          2007,
          2008,
          2009,
          2010,
          2011,
          2012,
          2013,
          2014,
          2015,
          2016,
          2017,
          2018,
          2019,
          2020,
          2021,
          2022,
          2023,
          2024,
          2025
         ],
         "y": {
          "bdata": "g9N1PVphWz1bTYE9X/ZePbMaez0/a4E98JFXPdV2Zj0NCFU9GhVtPRKBcz39BYY9CByGPc1ugD1XdIA9/udrPdXoVj0Cg1A9QKRNPV8nQD34CzQ9OSkoPQKEIj2K9Qw9rZHwPHlCsjw=",
          "dtype": "f4"
         }
        },
        {
         "hovertemplate": "<b>Topic 33</b><br><b>Top words:</b><br>system, software, design, systems, data<br>based, tool, tools, can, open<br>it, process, use, applications, be<br>Year: %{x}<br>Weight: %{y:.4f}<extra></extra>",
         "mode": "lines+markers",
         "name": "Topic 33",
         "type": "scatter",
         "x": [
          2000,
          2001,
          2002,
          2003,
          2004,
          2005,
          2006,
          2007,
          2008,
          2009,
          2010,
          2011,
          2012,
          2013,
          2014,
          2015,
          2016,
          2017,
          2018,
          2019,
          2020,
          2021,
          2022,
          2023,
          2024,
          2025
         ],
         "y": {
          "bdata": "lhZkPRE9sj2jiV89IHn4PSeWpT1IozI94hBSPQdBej2KPC09TjgdPXf3Rj2BKDI9VuUtPeBOIj0kJjo9T4skPcgTGz1jGhk9GzMVPVOcBz2d1QE9m1wDPc4D8DzG8us8zjblPMJK7jw=",
          "dtype": "f4"
         }
        },
        {
         "hovertemplate": "<b>Topic 2</b><br><b>Top words:</b><br>research, ai, from, has, have<br>their, review, how, survey, paper<br>study, future, these, systems, challenges<br>Year: %{x}<br>Weight: %{y:.4f}<extra></extra>",
         "mode": "lines+markers",
         "name": "Topic 2",
         "type": "scatter",
         "x": [
          2000,
          2001,
          2002,
          2003,
          2004,
          2005,
          2006,
          2007,
          2008,
          2009,
          2010,
          2011,
          2012,
          2013,
          2014,
          2015,
          2016,
          2017,
          2018,
          2019,
          2020,
          2021,
          2022,
          2023,
          2024,
          2025
         ],
         "y": {
          "bdata": "LEkWPXxytz3oqjE9IdVOPT8QWT2ZHR49BUwrPZjXFT1QrA89apRKPdAnHj0joiQ9uTggPbrSOz2K7T89Qc4mPVRpKz1jayA9tf4mPZ0+GT3pHjM9xPw8PRrhLz377zk9MVM6PT2UGz0=",
          "dtype": "f4"
         }
        },
        {
         "hovertemplate": "<b>Topic 21</b><br><b>Top words:</b><br>logic, verification, program, programs, reasoning<br>symbolic, semantics, formal, rules, model<br>our, programming, systems, proof, logical<br>Year: %{x}<br>Weight: %{y:.4f}<extra></extra>",
         "mode": "lines+markers",
         "name": "Topic 21",
         "type": "scatter",
         "x": [
          2000,
          2001,
          2002,
          2003,
          2004,
          2005,
          2006,
          2007,
          2008,
          2009,
          2010,
          2011,
          2012,
          2013,
          2014,
          2015,
          2016,
          2017,
          2018,
          2019,
          2020,
          2021,
          2022,
          2023,
          2024,
          2025
         ],
         "y": {
          "bdata": "opATPjy9nj2wYMA9cYyRPdPXnz3xfWg9VUhxPSuqMT29Wi09dbwcPbArLj2i7i49dcwfPbIfIz3sZBA9UzT+PNCz0DySC8A8bE2sPCtjjjzn/3M8a/R3PK9MWzwnIlE8nnA9PJjXTTw=",
          "dtype": "f4"
         }
        },
        {
         "hovertemplate": "<b>Topic 16</b><br><b>Top words:</b><br>functions, linear, over, finite, polynomial<br>set, sets, function, theory, class<br>which, algebraic, paper, fuzzy, invariant<br>Year: %{x}<br>Weight: %{y:.4f}<extra></extra>",
         "mode": "lines+markers",
         "name": "Topic 16",
         "type": "scatter",
         "x": [
          2000,
          2001,
          2002,
          2003,
          2004,
          2005,
          2006,
          2007,
          2008,
          2009,
          2010,
          2011,
          2012,
          2013,
          2014,
          2015,
          2016,
          2017,
          2018,
          2019,
          2020,
          2021,
          2022,
          2023,
          2024,
          2025
         ],
         "y": {
          "bdata": "7mw3PQfNST0B34U9NdeGPTXUaT2NG4U94UKBPYBcbT2Ftpc9mnRsPTrmWT3Bxkg9JkUqPdYnOj0mRho9YQcLPRCGAz0Bqtk8FiegPM0tljzvA308KctvPKo7ZTznEFA8DAosPD6gIDw=",
          "dtype": "f4"
         }
        },
        {
         "hovertemplate": "<b>Topic 22</b><br><b>Top words:</b><br>wireless, channel, power, performance, proposed<br>communication, multiple, based, system, transmission<br>signal, interference, systems, results, user<br>Year: %{x}<br>Weight: %{y:.4f}<extra></extra>",
         "mode": "lines+markers",
         "name": "Topic 22",
         "type": "scatter",
         "x": [
          2000,
          2001,
          2002,
          2003,
          2004,
          2005,
          2006,
          2007,
          2008,
          2009,
          2010,
          2011,
          2012,
          2013,
          2014,
          2015,
          2016,
          2017,
          2018,
          2019,
          2020,
          2021,
          2022,
          2023,
          2024,
          2025
         ],
         "y": {
          "bdata": "7XaAOxHi4zu0orA7sBeUO0OYJTxDUyM9j9wCPWMaWz1Z3mI9YulvPaO6Rz1S4Uo9nyc3PWF2Oz16il898CtuPaaURj28NCc9WJkBPTBz1Dwi8ro8k6KqPC7goDz/Foo81SFlPH4tLzw=",
          "dtype": "f4"
         }
        },
        {
         "hovertemplate": "<b>Topic 12</b><br><b>Top words:</b><br>n, o, log, algorithm, time<br>bound, our, problem, al, nn<br>et, sqrt, algorithms, bounds, lower<br>Year: %{x}<br>Weight: %{y:.4f}<extra></extra>",
         "mode": "lines+markers",
         "name": "Topic 12",
         "type": "scatter",
         "x": [
          2000,
          2001,
          2002,
          2003,
          2004,
          2005,
          2006,
          2007,
          2008,
          2009,
          2010,
          2011,
          2012,
          2013,
          2014,
          2015,
          2016,
          2017,
          2018,
          2019,
          2020,
          2021,
          2022,
          2023,
          2024,
          2025
         ],
         "y": {
          "bdata": "dN4EPWKIAT2VCyo9/OETPQ7mDT0BTRQ99IExPWZXCz0zLx89w+ksPXTZLj2GeSU9qq4VPS81Kj0QMiI9lQcSPbKNDj17n+k8kYa9PNNUtTzrhbE8eqmdPGyokzwYkok8jIR2PIx7XDw=",
          "dtype": "f4"
         }
        },
        {
         "hovertemplate": "<b>Topic 28</b><br><b>Top words:</b><br>graph, graphs, problem, edge, vertex<br>edges, vertices, time, np, number<br>set, show, g, directed, at<br>Year: %{x}<br>Weight: %{y:.4f}<extra></extra>",
         "mode": "lines+markers",
         "name": "Topic 28",
         "type": "scatter",
         "x": [
          2000,
          2001,
          2002,
          2003,
          2004,
          2005,
          2006,
          2007,
          2008,
          2009,
          2010,
          2011,
          2012,
          2013,
          2014,
          2015,
          2016,
          2017,
          2018,
          2019,
          2020,
          2021,
          2022,
          2023,
          2024,
          2025
         ],
         "y": {
          "bdata": "f2vSPDbx3jywfwo93Na2PMub7Twgads8B2v7PMR3Cj0gSh09jDEQPTvbCz03cRI9wnwNPSI5Bj3CywQ9Bcv7PBFK7zwfzsI8nTycPC7ikDypSoM815RmPKFebzxH2lw8sRg4PHIDKjw=",
          "dtype": "f4"
         }
        },
        {
         "hovertemplate": "<b>Topic 17</b><br><b>Top words:</b><br>information, channel, rate, capacity, channels<br>communication, feedback, side, two, coding<br>at, which, region, message, messages<br>Year: %{x}<br>Weight: %{y:.4f}<extra></extra>",
         "mode": "lines+markers",
         "name": "Topic 17",
         "type": "scatter",
         "x": [
          2000,
          2001,
          2002,
          2003,
          2004,
          2005,
          2006,
          2007,
          2008,
          2009,
          2010,
          2011,
          2012,
          2013,
          2014,
          2015,
          2016,
          2017,
          2018,
          2019,
          2020,
          2021,
          2022,
          2023,
          2024,
          2025
         ],
         "y": {
          "bdata": "lVZMPMtSQzwRB2A8HsAsPAhpmjwT+WU9JUxtPfrRTD0hUXE9rOBZPbosQT3C/yY9Y1YOPUMG6zwMZP08dr7mPC5qxTwEZqA8JcxrPH6RODzlpCk8dQwePJE5CTxfWuM775/EO9ursjs=",
          "dtype": "f4"
         }
        }
       ],
       "layout": {
        "height": 550,
        "hovermode": "closest",
        "legend": {
         "title": {
          "text": "Topics"
         }
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#C8D4E3"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Top 5 Topics Over Time (LDA Global Model)"
        },
        "width": 950,
        "xaxis": {
         "title": {
          "text": "Year"
         }
        },
        "yaxis": {
         "title": {
          "text": "Average Topic Weight"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import textwrap\n",
    "\n",
    "split_corpus = []\n",
    "idx = 0\n",
    "for slice_size in time_slices[SUBJECT]:\n",
    "    split_corpus.append(corpus_sorted[SUBJECT][idx: idx + slice_size])\n",
    "    idx += slice_size\n",
    "\n",
    "topic_activity = []\n",
    "for i, corpus_year in enumerate(split_corpus):\n",
    "    gamma = [loaded_lda_model.get_document_topics(doc, minimum_probability=0) for doc in corpus_year]\n",
    "    avg_topic_dist = np.mean([[p for _, p in g] for g in gamma], axis=0)\n",
    "    topic_activity.append(avg_topic_dist)\n",
    "\n",
    "topic_activity = np.array(topic_activity)\n",
    "\n",
    "mean_activity = topic_activity.mean(axis=0)\n",
    "top_topics_idx = np.argsort(mean_activity)[::-1][:10]\n",
    "\n",
    "top_words = {}\n",
    "for idx in top_topics_idx:\n",
    "    words = [w for w, _ in loaded_lda_model.show_topic(idx, topn=15)]\n",
    "    wrapped = \"<br>\".join(\n",
    "        [\", \".join(words[i:i + 5]) for i in range(0, len(words), 5)]\n",
    "    )\n",
    "    top_words[idx] = wrapped\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "for idx in top_topics_idx:\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=year_list[SUBJECT],\n",
    "        y=topic_activity[:, idx],\n",
    "        mode='lines+markers',\n",
    "        name=f\"Topic {idx}\",\n",
    "        hovertemplate=(\n",
    "            f\"<b>Topic {idx}</b><br>\"\n",
    "            f\"<b>Top words:</b><br>{top_words[idx]}<br>\"\n",
    "            \"Year: %{x}<br>\"\n",
    "            \"Weight: %{y:.4f}<extra></extra>\"\n",
    "        )\n",
    "    ))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Top 5 Topics Over Time (LDA Global Model)\",\n",
    "    xaxis_title=\"Year\",\n",
    "    yaxis_title=\"Average Topic Weight\",\n",
    "    legend_title=\"Topics\",\n",
    "    template=\"plotly_white\",\n",
    "    hovermode=\"closest\",\n",
    "    width=950,\n",
    "    height=550\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3785ca0",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce2c66f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from gensim.models import CoherenceModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5655e708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score Subject: cs\n",
      "LDA model loaded.\n",
      "Skor Koherensi LDA Statis (C_v) 100 topics: 0.5332\n",
      "LDA model loaded.\n",
      "Skor Koherensi LDA Statis (C_v) 150 topics: 0.5164\n",
      "LDA model loaded.\n",
      "Skor Koherensi LDA Statis (C_v) 200 topics: 0.4825\n"
     ]
    }
   ],
   "source": [
    "\n",
    "topic_range = range(100, 201, 50)\n",
    "for k in ['cs']:\n",
    "    print(f\"Coherence Score Subject: {k}\")\n",
    "    for i in topic_range:\n",
    "        MODEL_PATH = f\"model_results/lda_global_{k}_num_topic_{i}.pkl\"\n",
    "        DICTIONARY_PATH = f\"model_results/dictionary_{k}.gensim\"\n",
    "        try:\n",
    "            with open(MODEL_PATH, \"rb\") as f:\n",
    "                loaded_lda_model = pickle.load(f)\n",
    "            print(\"LDA model loaded.\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"ERROR: Model file not found at {MODEL_PATH}\")\n",
    "        topic_tuples = loaded_lda_model.show_topics(\n",
    "            num_topics=1000,\n",
    "            num_words=10,\n",
    "            formatted=False              \n",
    "        )\n",
    "        lda_static_topics = []\n",
    "        for topic_id, words_probs in topic_tuples:\n",
    "            top_words = [word for word, prob in words_probs]\n",
    "            lda_static_topics.append(top_words)\n",
    "        import ast\n",
    "        token_list = data[k][\"text\"].explode().tolist()\n",
    "        # tokens = [ast.literal_eval(x) for x in token_list]\n",
    "        tokens = [x.split() for x in token_list]\n",
    "\n",
    "        dictionary_bow = Dictionary(tokens)\n",
    "        cm_lda_static = CoherenceModel(\n",
    "                topics=lda_static_topics,       \n",
    "                texts=tokens,\n",
    "                dictionary=dictionary_bow,\n",
    "                coherence='c_v' ,\n",
    "                processes=5\n",
    "            )\n",
    "        coherence_score = cm_lda_static.get_coherence()\n",
    "        print(f\"Skor Koherensi LDA Statis (C_v) {i} topics: {coherence_score:.4f}\")\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
