{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "intro-markdown",
            "metadata": {},
            "source": [
                "# Top2Vec Hyperparameter Tuning\n",
                "\n",
                "Based on `coherence_results_v1.csv`, `sentence-transformers/all-MiniLM-L6-v2` achieved the highest average coherence across all subjects. This notebook performs grid-search hyperparameter tuning over UMAP and HDBSCAN parameters to find the best Top2Vec configuration."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "imports",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import gc\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "from pathlib import Path\n",
                "from typing import List, Optional, Dict, Any\n",
                "from tqdm import tqdm\n",
                "from itertools import product\n",
                "import warnings\n",
                "import time\n",
                "\n",
                "from top2vec import Top2Vec\n",
                "from sentence_transformers import SentenceTransformer\n",
                "from sklearn.preprocessing import normalize\n",
                "from gensim.corpora import Dictionary\n",
                "from gensim.models.coherencemodel import CoherenceModel\n",
                "\n",
                "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "config-markdown",
            "metadata": {},
            "source": [
                "## Configuration"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "config",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Embedding: sentence-transformers/all-MiniLM-L6-v2\n",
                        "Output directory: tunning/sentence_transformers_all_MiniLM_L6_v2\n"
                    ]
                }
            ],
            "source": [
                "VERSION = \"v1\"\n",
                "LIST_SUBJECT = [\"cs\", \"math\", \"physics\"]\n",
                "\n",
                "TRANSFORMER = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
                "EMBEDDING_DIM = 384\n",
                "\n",
                "BASE_DIR = Path(\"../../dataset\")\n",
                "EMBEDDING_DIR = Path(\"../bertopic/embedding\")\n",
                "TUNNING_DIR = Path(\"./tunning\")\n",
                "\n",
                "SAFE_MODEL_NAME = TRANSFORMER.replace(\"/\", \"_\").replace(\"-\", \"_\")\n",
                "OUTPUT_DIR = TUNNING_DIR / SAFE_MODEL_NAME\n",
                "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
                "\n",
                "print(f\"Embedding: {TRANSFORMER}\")\n",
                "print(f\"Output directory: {OUTPUT_DIR}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "grid-markdown",
            "metadata": {},
            "source": [
                "## Hyperparameter Grid"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "grid",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Total parameter combinations: 27\n",
                        "Total runs (combinations x subjects): 81\n"
                    ]
                }
            ],
            "source": [
                "PARAM_GRID = {\n",
                "    \"umap_n_neighbors\": [10, 15, 30],\n",
                "    \"umap_n_components\": [5, 10, 30],\n",
                "    \"hdbscan_min_cluster_size\": [15, 30, 50],\n",
                "    \"hdbscan_cluster_selection_method\": [\"eom\"],\n",
                "    \"min_count\": [50],\n",
                "}\n",
                "\n",
                "keys = list(PARAM_GRID.keys())\n",
                "values = list(PARAM_GRID.values())\n",
                "all_combos = list(product(*values))\n",
                "\n",
                "print(f\"Total parameter combinations: {len(all_combos)}\")\n",
                "print(f\"Total runs (combinations x subjects): {len(all_combos) * len(LIST_SUBJECT)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "helpers-markdown",
            "metadata": {},
            "source": [
                "## Helper Functions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "helper-functions",
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_model_safe_name(model_name: str) -> str:\n",
                "    return model_name.replace(\"/\", \"_\").replace(\"-\", \"_\")\n",
                "\n",
                "\n",
                "def load_dataset(subject: str) -> Optional[pd.DataFrame]:\n",
                "    file_path = BASE_DIR / subject / \"emb\" / f\"{VERSION}.csv\"\n",
                "    if not file_path.exists():\n",
                "        print(f\"File not found: {file_path}\")\n",
                "        return None\n",
                "    return pd.read_csv(file_path)\n",
                "\n",
                "\n",
                "def load_mmap_embeddings(\n",
                "    mmap_path: str,\n",
                "    num_documents: int,\n",
                "    embedding_dim: int,\n",
                "    dtype: str = \"float32\"\n",
                ") -> Optional[np.ndarray]:\n",
                "    try:\n",
                "        embs = np.array(np.memmap(\n",
                "            mmap_path, dtype=dtype, mode=\"r\",\n",
                "            shape=(num_documents, embedding_dim)\n",
                "        ))\n",
                "        return normalize(embs)\n",
                "    except FileNotFoundError:\n",
                "        print(f\"Embedding not found: {mmap_path}\")\n",
                "        return None\n",
                "    except Exception as e:\n",
                "        print(f\"Error loading embeddings: {e}\")\n",
                "        return None\n",
                "\n",
                "\n",
                "def train_top2vec_with_precomputed(\n",
                "    documents: List[str],\n",
                "    precomputed_embeddings: np.ndarray,\n",
                "    transformer_name: str,\n",
                "    umap_args: Dict[str, Any] = None,\n",
                "    hdbscan_args: Dict[str, Any] = None,\n",
                "    min_count: int = 50,\n",
                ") -> Top2Vec:\n",
                "    num_docs = len(documents)\n",
                "    st_model = SentenceTransformer(transformer_name)\n",
                "\n",
                "    original_embed_docs = Top2Vec._embed_documents\n",
                "\n",
                "    def patched_embed_documents(self, train_corpus, batch_size):\n",
                "        if len(train_corpus) == num_docs:\n",
                "            return precomputed_embeddings\n",
                "        else:\n",
                "            return st_model.encode(train_corpus, batch_size=batch_size, show_progress_bar=False)\n",
                "\n",
                "    Top2Vec._embed_documents = patched_embed_documents\n",
                "\n",
                "    model = Top2Vec(\n",
                "        documents=documents,\n",
                "        embedding_model='all-MiniLM-L6-v2',\n",
                "        min_count=min_count,\n",
                "        contextual_top2vec=False,\n",
                "        ngram_vocab=False,\n",
                "        umap_args=umap_args,\n",
                "        hdbscan_args=hdbscan_args,\n",
                "        verbose=False,\n",
                "    )\n",
                "\n",
                "    Top2Vec._embed_documents = original_embed_docs\n",
                "    del st_model\n",
                "\n",
                "    return model\n",
                "\n",
                "\n",
                "def calculate_coherence(\n",
                "    model: Top2Vec,\n",
                "    texts_tokenized: List[List[str]],\n",
                "    dictionary: Dictionary,\n",
                "    top_n: int = 5\n",
                ") -> float:\n",
                "    num_topics = model.get_num_topics()\n",
                "    topic_words, _, _ = model.get_topics(num_topics)\n",
                "    topic_words_sliced = topic_words[:, :top_n]\n",
                "\n",
                "    cm = CoherenceModel(\n",
                "        topics=topic_words_sliced.tolist(),\n",
                "        texts=texts_tokenized,\n",
                "        dictionary=dictionary,\n",
                "        coherence='c_v',\n",
                "        processes=1\n",
                "    )\n",
                "\n",
                "    return cm.get_coherence()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "load-data-markdown",
            "metadata": {},
            "source": [
                "## Load Datasets, Embeddings & Tokenize"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "load-data",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "cs: 165,756 documents loaded\n",
                        "  Embeddings loaded: (165756, 384)\n",
                        "  Tokenizing for coherence...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "  cs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 165756/165756 [00:02<00:00, 74037.54it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "math: 126,192 documents loaded\n",
                        "  Embeddings loaded: (126192, 384)\n",
                        "  Tokenizing for coherence...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "  math: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 126192/126192 [00:00<00:00, 137450.95it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "physics: 146,311 documents loaded\n",
                        "  Embeddings loaded: (146311, 384)\n",
                        "  Tokenizing for coherence...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "  physics: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 146311/146311 [00:02<00:00, 63863.18it/s] \n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Subjects ready: ['cs', 'math', 'physics']\n"
                    ]
                }
            ],
            "source": [
                "all_data = {}\n",
                "all_embeddings = {}\n",
                "all_texts_tokenized = {}\n",
                "all_dictionaries = {}\n",
                "\n",
                "safe_name = get_model_safe_name(TRANSFORMER)\n",
                "\n",
                "for subject in LIST_SUBJECT:\n",
                "    df = load_dataset(subject)\n",
                "    if df is None:\n",
                "        continue\n",
                "\n",
                "    all_data[subject] = df\n",
                "    print(f\"{subject}: {len(df):,} documents loaded\")\n",
                "\n",
                "    mmap_path = EMBEDDING_DIR / subject / f\"{safe_name}_{VERSION}.mmap\"\n",
                "    embs = load_mmap_embeddings(str(mmap_path), len(df), EMBEDDING_DIM)\n",
                "    if embs is None:\n",
                "        print(f\"  âš  Skipping {subject}: embedding not found\")\n",
                "        continue\n",
                "    all_embeddings[subject] = embs\n",
                "    print(f\"  Embeddings loaded: {embs.shape}\")\n",
                "\n",
                "    print(f\"  Tokenizing for coherence...\")\n",
                "    texts_tokenized = [text.split() for text in tqdm(df['text'].fillna('').tolist(), desc=f\"  {subject}\")]\n",
                "    all_texts_tokenized[subject] = texts_tokenized\n",
                "    all_dictionaries[subject] = Dictionary(texts_tokenized)\n",
                "\n",
                "print(f\"\\nSubjects ready: {list(all_embeddings.keys())}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "tuning-markdown",
            "metadata": {},
            "source": [
                "## Hyperparameter Tuning Grid Search"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "id": "tuning-loop",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "======================================================================\n",
                        "Subject: CS (165,756 documents)\n",
                        "======================================================================\n",
                        "\n",
                        "[1/81] cs | nn=10 nc=5 mcs=15 csm=eom mc=50\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
                        "  warnings.warn(\n",
                        "2026-02-12 23:21:27,494 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "  âœ“ Topics: 919 | Coherence: 0.5735 (80.6s)\n",
                        "\n",
                        "[2/81] cs | nn=10 nc=5 mcs=30 csm=eom mc=50\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
                        "  warnings.warn(\n",
                        "2026-02-12 23:24:56,741 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "  âœ“ Topics: 499 | Coherence: 0.5744 (65.6s)\n",
                        "\n",
                        "[3/81] cs | nn=10 nc=5 mcs=50 csm=eom mc=50\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
                        "  warnings.warn(\n",
                        "2026-02-12 23:27:45,301 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "  âœ“ Topics: 302 | Coherence: 0.5702 (65.3s)\n",
                        "\n",
                        "[4/81] cs | nn=10 nc=10 mcs=15 csm=eom mc=50\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
                        "  warnings.warn(\n",
                        "2026-02-12 23:30:13,978 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "  âœ“ Topics: 906 | Coherence: 0.5712 (67.7s)\n",
                        "\n",
                        "[5/81] cs | nn=10 nc=10 mcs=30 csm=eom mc=50\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
                        "  warnings.warn(\n",
                        "2026-02-12 23:33:31,619 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "  âœ“ Topics: 516 | Coherence: 0.5802 (67.1s)\n",
                        "\n",
                        "[6/81] cs | nn=10 nc=10 mcs=50 csm=eom mc=50\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
                        "  warnings.warn(\n",
                        "2026-02-12 23:36:18,975 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "  âœ“ Topics: 303 | Coherence: 0.5740 (67.2s)\n",
                        "\n",
                        "[7/81] cs | nn=10 nc=30 mcs=15 csm=eom mc=50\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
                        "  warnings.warn(\n",
                        "2026-02-12 23:38:50,875 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "  âœ“ Topics: 935 | Coherence: 0.5703 (84.3s)\n",
                        "\n",
                        "[8/81] cs | nn=10 nc=30 mcs=30 csm=eom mc=50\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
                        "  warnings.warn(\n",
                        "2026-02-12 23:42:26,616 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "  âœ“ Topics: 492 | Coherence: 0.5744 (83.5s)\n",
                        "\n",
                        "[9/81] cs | nn=10 nc=30 mcs=50 csm=eom mc=50\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
                        "  warnings.warn(\n",
                        "2026-02-12 23:45:32,041 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "  âœ“ Topics: 311 | Coherence: 0.5785 (83.2s)\n",
                        "\n",
                        "[10/81] cs | nn=15 nc=5 mcs=15 csm=eom mc=50\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
                        "  warnings.warn(\n",
                        "2026-02-12 23:48:18,092 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "  âœ“ Topics: 810 | Coherence: 0.5761 (70.4s)\n",
                        "  ðŸ’¾ Checkpoint saved (10/81)\n",
                        "\n",
                        "[11/81] cs | nn=15 nc=5 mcs=30 csm=eom mc=50\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
                        "  warnings.warn(\n",
                        "2026-02-12 23:51:33,615 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "  âœ“ Topics: 455 | Coherence: 0.5722 (69.8s)\n",
                        "\n",
                        "[12/81] cs | nn=15 nc=5 mcs=50 csm=eom mc=50\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
                        "  warnings.warn(\n",
                        "2026-02-12 23:54:20,901 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "  âœ“ Topics: 292 | Coherence: 0.5727 (69.0s)\n",
                        "\n",
                        "[13/81] cs | nn=15 nc=10 mcs=15 csm=eom mc=50\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
                        "  warnings.warn(\n",
                        "2026-02-12 23:56:52,355 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "  âœ“ Topics: 829 | Coherence: 0.5722 (70.7s)\n",
                        "\n",
                        "[14/81] cs | nn=15 nc=10 mcs=30 csm=eom mc=50\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
                        "  warnings.warn(\n",
                        "2026-02-13 00:00:07,260 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "  âœ“ Topics: 488 | Coherence: 0.5778 (71.0s)\n",
                        "\n",
                        "[15/81] cs | nn=15 nc=10 mcs=50 csm=eom mc=50\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
                        "  warnings.warn(\n",
                        "2026-02-13 00:02:57,309 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "  âœ“ Topics: 284 | Coherence: 0.5770 (70.6s)\n",
                        "\n",
                        "[16/81] cs | nn=15 nc=30 mcs=15 csm=eom mc=50\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
                        "  warnings.warn(\n",
                        "2026-02-13 00:05:29,360 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "  âœ“ Topics: 843 | Coherence: 0.5712 (88.5s)\n",
                        "\n",
                        "[17/81] cs | nn=15 nc=30 mcs=30 csm=eom mc=50\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
                        "  warnings.warn(\n",
                        "2026-02-13 00:08:58,210 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "  âœ“ Topics: 457 | Coherence: 0.5736 (87.5s)\n",
                        "\n",
                        "[18/81] cs | nn=15 nc=30 mcs=50 csm=eom mc=50\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
                        "  warnings.warn(\n",
                        "2026-02-13 00:12:00,673 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "  âœ“ Topics: 297 | Coherence: 0.5793 (87.9s)\n",
                        "\n",
                        "[19/81] cs | nn=30 nc=5 mcs=15 csm=eom mc=50\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
                        "  warnings.warn(\n",
                        "2026-02-13 00:14:51,227 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "  âœ“ Topics: 678 | Coherence: 0.5818 (76.9s)\n",
                        "\n",
                        "[20/81] cs | nn=30 nc=5 mcs=30 csm=eom mc=50\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
                        "  warnings.warn(\n",
                        "2026-02-13 00:18:02,087 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "  âœ“ Topics: 410 | Coherence: 0.5757 (77.6s)\n",
                        "  ðŸ’¾ Checkpoint saved (20/81)\n",
                        "\n",
                        "[21/81] cs | nn=30 nc=5 mcs=50 csm=eom mc=50\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
                        "  warnings.warn(\n",
                        "2026-02-13 00:20:49,605 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "  âœ“ Topics: 261 | Coherence: 0.5853 (77.5s)\n",
                        "\n",
                        "[22/81] cs | nn=30 nc=10 mcs=15 csm=eom mc=50\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
                        "  warnings.warn(\n",
                        "2026-02-13 00:23:25,165 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "  âœ“ Topics: 711 | Coherence: 0.5761 (81.3s)\n",
                        "\n",
                        "[23/81] cs | nn=30 nc=10 mcs=30 csm=eom mc=50\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
                        "  warnings.warn(\n",
                        "2026-02-13 00:26:43,403 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "  âœ“ Topics: 417 | Coherence: 0.5761 (81.2s)\n",
                        "\n",
                        "[24/81] cs | nn=30 nc=10 mcs=50 csm=eom mc=50\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
                        "  warnings.warn(\n",
                        "2026-02-13 00:29:34,586 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "  âœ“ Topics: 258 | Coherence: 0.5828 (81.9s)\n",
                        "\n",
                        "[25/81] cs | nn=30 nc=30 mcs=15 csm=eom mc=50\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
                        "  warnings.warn(\n",
                        "2026-02-13 00:32:15,681 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "  âœ“ Topics: 700 | Coherence: 0.5760 (99.4s)\n",
                        "\n",
                        "[26/81] cs | nn=30 nc=30 mcs=30 csm=eom mc=50\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
                        "  warnings.warn(\n",
                        "2026-02-13 00:35:49,721 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "  âœ“ Topics: 423 | Coherence: 0.5771 (100.4s)\n",
                        "\n",
                        "[27/81] cs | nn=30 nc=30 mcs=50 csm=eom mc=50\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
                        "  warnings.warn(\n",
                        "2026-02-13 00:39:04,622 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "  âœ“ Topics: 239 | Coherence: 0.5893 (99.6s)\n",
                        "\n",
                        "======================================================================\n",
                        "Subject: MATH (126,192 documents)\n",
                        "======================================================================\n",
                        "\n",
                        "[28/81] math | nn=10 nc=5 mcs=15 csm=eom mc=50\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
                        "  warnings.warn(\n",
                        "2026-02-13 00:41:45,495 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "  âœ“ Topics: 637 | Coherence: 0.5457 (42.6s)\n",
                        "\n",
                        "[29/81] math | nn=10 nc=5 mcs=30 csm=eom mc=50\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
                        "  warnings.warn(\n",
                        "2026-02-13 00:43:07,810 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "  âœ“ Topics: 316 | Coherence: 0.5599 (42.5s)\n",
                        "\n",
                        "[30/81] math | nn=10 nc=5 mcs=50 csm=eom mc=50\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
                        "  warnings.warn(\n",
                        "2026-02-13 00:44:22,104 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "  âœ“ Topics: 208 | Coherence: 0.5534 (43.1s)\n",
                        "  ðŸ’¾ Checkpoint saved (30/81)\n",
                        "\n",
                        "[31/81] math | nn=10 nc=10 mcs=15 csm=eom mc=50\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
                        "  warnings.warn(\n",
                        "2026-02-13 00:45:33,706 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "  âœ“ Topics: 629 | Coherence: 0.5433 (43.5s)\n",
                        "\n",
                        "[32/81] math | nn=10 nc=10 mcs=30 csm=eom mc=50\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
                        "  warnings.warn(\n",
                        "2026-02-13 00:46:55,251 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "  âœ“ Topics: 337 | Coherence: 0.5543 (43.4s)\n",
                        "\n",
                        "[33/81] math | nn=10 nc=10 mcs=50 csm=eom mc=50\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
                        "  warnings.warn(\n",
                        "2026-02-13 00:48:11,627 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "  âœ“ Topics: 190 | Coherence: 0.5410 (43.9s)\n",
                        "\n",
                        "[34/81] math | nn=10 nc=30 mcs=15 csm=eom mc=50\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
                        "  warnings.warn(\n",
                        "2026-02-13 00:49:23,685 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "  âœ“ Topics: 634 | Coherence: 0.5444 (52.7s)\n",
                        "\n",
                        "[35/81] math | nn=10 nc=30 mcs=30 csm=eom mc=50\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
                        "  warnings.warn(\n",
                        "2026-02-13 00:50:56,609 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "  âœ“ Topics: 330 | Coherence: 0.5617 (54.3s)\n",
                        "\n",
                        "[36/81] math | nn=10 nc=30 mcs=50 csm=eom mc=50\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
                        "  warnings.warn(\n",
                        "2026-02-13 00:52:22,633 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "  âœ“ Topics: 178 | Coherence: 0.5446 (54.1s)\n",
                        "\n",
                        "[37/81] math | nn=15 nc=5 mcs=15 csm=eom mc=50\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
                        "  warnings.warn(\n",
                        "2026-02-13 00:53:42,921 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "  âœ“ Topics: 565 | Coherence: 0.5470 (44.9s)\n",
                        "\n",
                        "[38/81] math | nn=15 nc=5 mcs=30 csm=eom mc=50\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
                        "  warnings.warn(\n",
                        "2026-02-13 00:55:05,138 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "  âœ“ Topics: 300 | Coherence: 0.5586 (44.6s)\n",
                        "\n",
                        "[39/81] math | nn=15 nc=5 mcs=50 csm=eom mc=50\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
                        "  warnings.warn(\n",
                        "2026-02-13 00:56:20,866 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "  âœ“ Topics: 175 | Coherence: 0.5615 (44.7s)\n",
                        "\n",
                        "[40/81] math | nn=15 nc=10 mcs=15 csm=eom mc=50\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
                        "  warnings.warn(\n",
                        "2026-02-13 00:57:31,409 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "  âœ“ Topics: 569 | Coherence: 0.5534 (45.4s)\n",
                        "  ðŸ’¾ Checkpoint saved (40/81)\n",
                        "\n",
                        "[41/81] math | nn=15 nc=10 mcs=30 csm=eom mc=50\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
                        "  warnings.warn(\n",
                        "2026-02-13 00:58:55,234 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "  âœ“ Topics: 307 | Coherence: 0.5509 (45.5s)\n",
                        "\n",
                        "[42/81] math | nn=15 nc=10 mcs=50 csm=eom mc=50\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
                        "  warnings.warn(\n",
                        "2026-02-13 01:00:12,799 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "  âœ“ Topics: 166 | Coherence: 0.5586 (45.6s)\n",
                        "\n",
                        "[43/81] math | nn=15 nc=30 mcs=15 csm=eom mc=50\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
                        "  warnings.warn(\n",
                        "2026-02-13 01:01:24,826 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "  âœ“ Topics: 569 | Coherence: 0.5525 (56.8s)\n",
                        "\n",
                        "[44/81] math | nn=15 nc=30 mcs=30 csm=eom mc=50\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
                        "  warnings.warn(\n",
                        "2026-02-13 01:02:59,024 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "  âœ“ Topics: 313 | Coherence: 0.5615 (57.4s)\n",
                        "\n",
                        "[45/81] math | nn=15 nc=30 mcs=50 csm=eom mc=50\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
                        "  warnings.warn(\n",
                        "2026-02-13 01:04:28,703 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "  âœ“ Topics: 176 | Coherence: 0.5645 (55.5s)\n",
                        "\n",
                        "[46/81] math | nn=30 nc=5 mcs=15 csm=eom mc=50\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
                        "  warnings.warn(\n",
                        "2026-02-13 01:05:51,502 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "  âœ“ Topics: 468 | Coherence: 0.5494 (51.7s)\n",
                        "\n",
                        "[47/81] math | nn=30 nc=5 mcs=30 csm=eom mc=50\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
                        "  warnings.warn(\n",
                        "2026-02-13 01:07:19,367 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "  âœ“ Topics: 252 | Coherence: 0.5684 (52.0s)\n",
                        "\n",
                        "[48/81] math | nn=30 nc=5 mcs=50 csm=eom mc=50\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
                        "  warnings.warn(\n",
                        "2026-02-13 01:08:40,755 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "  âœ“ Topics: 154 | Coherence: 0.5676 (51.6s)\n",
                        "\n",
                        "[49/81] math | nn=30 nc=10 mcs=15 csm=eom mc=50\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
                        "  warnings.warn(\n",
                        "2026-02-13 01:09:57,267 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "  âœ“ Topics: 481 | Coherence: 0.5498 (52.1s)\n",
                        "\n",
                        "[50/81] math | nn=30 nc=10 mcs=30 csm=eom mc=50\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
                        "  warnings.warn(\n",
                        "2026-02-13 01:11:26,459 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "  âœ“ Topics: 247 | Coherence: 0.5534 (51.8s)\n",
                        "  ðŸ’¾ Checkpoint saved (50/81)\n",
                        "\n",
                        "[51/81] math | nn=30 nc=10 mcs=50 csm=eom mc=50\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
                        "  warnings.warn(\n",
                        "2026-02-13 01:12:47,790 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "  âœ“ Topics: 157 | Coherence: 0.5607 (51.9s)\n",
                        "\n",
                        "[52/81] math | nn=30 nc=30 mcs=15 csm=eom mc=50\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
                        "  warnings.warn(\n",
                        "2026-02-13 01:14:05,246 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "  âœ“ Topics: 465 | Coherence: 0.5540 (63.8s)\n",
                        "\n",
                        "[53/81] math | nn=30 nc=30 mcs=30 csm=eom mc=50\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
                        "  warnings.warn(\n",
                        "2026-02-13 01:15:45,257 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "  âœ“ Topics: 256 | Coherence: 0.5661 (63.5s)\n",
                        "\n",
                        "[54/81] math | nn=30 nc=30 mcs=50 csm=eom mc=50\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
                        "  warnings.warn(\n",
                        "2026-02-13 01:17:19,165 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "  âœ“ Topics: 2 | Coherence: 0.4889 (64.9s)\n",
                        "\n",
                        "======================================================================\n",
                        "Subject: PHYSICS (146,311 documents)\n",
                        "======================================================================\n",
                        "\n",
                        "[55/81] physics | nn=10 nc=5 mcs=15 csm=eom mc=50\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
                        "  warnings.warn(\n",
                        "2026-02-13 01:18:44,008 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "  âœ“ Topics: 762 | Coherence: 0.6293 (57.2s)\n",
                        "\n",
                        "[56/81] physics | nn=10 nc=5 mcs=30 csm=eom mc=50\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
                        "  warnings.warn(\n",
                        "2026-02-13 01:21:00,040 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "  âœ“ Topics: 381 | Coherence: 0.6435 (56.2s)\n",
                        "\n",
                        "[57/81] physics | nn=10 nc=5 mcs=50 csm=eom mc=50\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
                        "  warnings.warn(\n",
                        "2026-02-13 01:23:00,282 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "  âœ“ Topics: 249 | Coherence: 0.6520 (55.8s)\n",
                        "\n",
                        "[58/81] physics | nn=10 nc=10 mcs=15 csm=eom mc=50\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
                        "  warnings.warn(\n",
                        "2026-02-13 01:24:54,050 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "  âœ“ Topics: 778 | Coherence: 0.6307 (57.7s)\n",
                        "\n",
                        "[59/81] physics | nn=10 nc=10 mcs=30 csm=eom mc=50\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
                        "  warnings.warn(\n",
                        "2026-02-13 01:27:09,966 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "  âœ“ Topics: 396 | Coherence: 0.6343 (57.6s)\n",
                        "\n",
                        "[60/81] physics | nn=10 nc=10 mcs=50 csm=eom mc=50\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
                        "  warnings.warn(\n",
                        "2026-02-13 01:29:13,297 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "  âœ“ Topics: 253 | Coherence: 0.6465 (58.2s)\n",
                        "  ðŸ’¾ Checkpoint saved (60/81)\n",
                        "\n",
                        "[61/81] physics | nn=10 nc=30 mcs=15 csm=eom mc=50\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
                        "  warnings.warn(\n",
                        "2026-02-13 01:31:08,556 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "  âœ“ Topics: 769 | Coherence: 0.6222 (69.6s)\n",
                        "\n",
                        "[62/81] physics | nn=10 nc=30 mcs=30 csm=eom mc=50\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
                        "  warnings.warn(\n",
                        "2026-02-13 01:33:37,821 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "  âœ“ Topics: 398 | Coherence: 0.6424 (69.5s)\n",
                        "\n",
                        "[63/81] physics | nn=10 nc=30 mcs=50 csm=eom mc=50\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
                        "  warnings.warn(\n",
                        "2026-02-13 01:35:52,935 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "  âœ“ Topics: 235 | Coherence: 0.6456 (70.1s)\n",
                        "\n",
                        "[64/81] physics | nn=15 nc=5 mcs=15 csm=eom mc=50\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
                        "  warnings.warn(\n",
                        "2026-02-13 01:37:59,842 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "  âœ“ Topics: 671 | Coherence: 0.6332 (58.9s)\n",
                        "\n",
                        "[65/81] physics | nn=15 nc=5 mcs=30 csm=eom mc=50\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
                        "  warnings.warn(\n",
                        "2026-02-13 01:40:14,905 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "  âœ“ Topics: 364 | Coherence: 0.6466 (58.5s)\n",
                        "\n",
                        "[66/81] physics | nn=15 nc=5 mcs=50 csm=eom mc=50\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
                        "  warnings.warn(\n",
                        "2026-02-13 01:42:16,939 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "  âœ“ Topics: 237 | Coherence: 0.6600 (58.9s)\n",
                        "\n",
                        "[67/81] physics | nn=15 nc=10 mcs=15 csm=eom mc=50\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
                        "  warnings.warn(\n",
                        "2026-02-13 01:44:12,612 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "  âœ“ Topics: 678 | Coherence: 0.6341 (60.0s)\n",
                        "\n",
                        "[68/81] physics | nn=15 nc=10 mcs=30 csm=eom mc=50\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
                        "  warnings.warn(\n",
                        "2026-02-13 01:46:29,799 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "  âœ“ Topics: 359 | Coherence: 0.6406 (58.7s)\n",
                        "\n",
                        "[69/81] physics | nn=15 nc=10 mcs=50 csm=eom mc=50\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
                        "  warnings.warn(\n",
                        "2026-02-13 01:48:32,023 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "  âœ“ Topics: 243 | Coherence: 0.6479 (58.9s)\n",
                        "\n",
                        "[70/81] physics | nn=15 nc=30 mcs=15 csm=eom mc=50\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
                        "  warnings.warn(\n",
                        "2026-02-13 01:50:28,747 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "  âœ“ Topics: 698 | Coherence: 0.6335 (72.5s)\n",
                        "  ðŸ’¾ Checkpoint saved (70/81)\n",
                        "\n",
                        "[71/81] physics | nn=15 nc=30 mcs=30 csm=eom mc=50\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
                        "  warnings.warn(\n",
                        "2026-02-13 01:53:03,300 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "  âœ“ Topics: 373 | Coherence: 0.6365 (77.4s)\n",
                        "\n",
                        "[72/81] physics | nn=15 nc=30 mcs=50 csm=eom mc=50\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
                        "  warnings.warn(\n",
                        "2026-02-13 01:55:22,765 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "  âœ“ Topics: 237 | Coherence: 0.6496 (72.8s)\n",
                        "\n",
                        "[73/81] physics | nn=30 nc=5 mcs=15 csm=eom mc=50\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
                        "  warnings.warn(\n",
                        "2026-02-13 01:57:32,028 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "  âœ“ Topics: 578 | Coherence: 0.6346 (66.0s)\n",
                        "\n",
                        "[74/81] physics | nn=30 nc=5 mcs=30 csm=eom mc=50\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
                        "  warnings.warn(\n",
                        "2026-02-13 01:59:49,948 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "  âœ“ Topics: 309 | Coherence: 0.6503 (65.7s)\n",
                        "\n",
                        "[75/81] physics | nn=30 nc=5 mcs=50 csm=eom mc=50\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
                        "  warnings.warn(\n",
                        "2026-02-13 02:01:57,304 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "  âœ“ Topics: 203 | Coherence: 0.6534 (65.5s)\n",
                        "\n",
                        "[76/81] physics | nn=30 nc=10 mcs=15 csm=eom mc=50\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
                        "  warnings.warn(\n",
                        "2026-02-13 02:03:56,503 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "  âœ“ Topics: 588 | Coherence: 0.6366 (67.1s)\n",
                        "\n",
                        "[77/81] physics | nn=30 nc=10 mcs=30 csm=eom mc=50\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
                        "  warnings.warn(\n",
                        "2026-02-13 02:06:19,074 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "  âœ“ Topics: 323 | Coherence: 0.6440 (67.8s)\n",
                        "\n",
                        "[78/81] physics | nn=30 nc=10 mcs=50 csm=eom mc=50\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
                        "  warnings.warn(\n",
                        "2026-02-13 02:08:28,931 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "  âœ“ Topics: 205 | Coherence: 0.6642 (67.5s)\n",
                        "\n",
                        "[79/81] physics | nn=30 nc=30 mcs=15 csm=eom mc=50\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
                        "  warnings.warn(\n",
                        "2026-02-13 02:10:31,457 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "  âœ“ Topics: 569 | Coherence: 0.6314 (81.8s)\n",
                        "\n",
                        "[80/81] physics | nn=30 nc=30 mcs=30 csm=eom mc=50\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
                        "  warnings.warn(\n",
                        "2026-02-13 02:13:06,771 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "  âœ“ Topics: 301 | Coherence: 0.6425 (81.9s)\n",
                        "  ðŸ’¾ Checkpoint saved (80/81)\n",
                        "\n",
                        "[81/81] physics | nn=30 nc=30 mcs=50 csm=eom mc=50\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
                        "  warnings.warn(\n",
                        "2026-02-13 02:15:29,351 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "  âœ“ Topics: 210 | Coherence: 0.6605 (82.4s)\n",
                        "\n",
                        "âœ… All results saved to tunning/sentence_transformers_all_MiniLM_L6_v2/tuning_results.csv\n",
                        "Total runs: 81\n"
                    ]
                }
            ],
            "source": [
                "results = []\n",
                "csv_path = OUTPUT_DIR / \"tuning_results.csv\"\n",
                "\n",
                "total_runs = len(all_combos) * len(all_embeddings)\n",
                "run_count = 0\n",
                "\n",
                "for subject in all_embeddings:\n",
                "    df = all_data[subject]\n",
                "    documents = df['text'].fillna('').tolist()\n",
                "    embs = all_embeddings[subject]\n",
                "\n",
                "    print(f\"\\n{'=' * 70}\")\n",
                "    print(f\"Subject: {subject.upper()} ({len(documents):,} documents)\")\n",
                "    print(f\"{'=' * 70}\")\n",
                "\n",
                "    for combo in all_combos:\n",
                "        run_count += 1\n",
                "        params = dict(zip(keys, combo))\n",
                "\n",
                "        umap_args = {\n",
                "            \"n_neighbors\": params[\"umap_n_neighbors\"],\n",
                "            \"n_components\": params[\"umap_n_components\"],\n",
                "            \"metric\": \"cosine\",\n",
                "        }\n",
                "        hdbscan_args = {\n",
                "            \"min_cluster_size\": params[\"hdbscan_min_cluster_size\"],\n",
                "            \"metric\": \"euclidean\",\n",
                "            \"cluster_selection_method\": params[\"hdbscan_cluster_selection_method\"],\n",
                "        }\n",
                "\n",
                "        print(f\"\\n[{run_count}/{total_runs}] {subject} | \"\n",
                "              f\"nn={params['umap_n_neighbors']} nc={params['umap_n_components']} \"\n",
                "              f\"mcs={params['hdbscan_min_cluster_size']} csm={params['hdbscan_cluster_selection_method']} \"\n",
                "              f\"mc={params['min_count']}\")\n",
                "\n",
                "        try:\n",
                "            start_time = time.time()\n",
                "\n",
                "            model = train_top2vec_with_precomputed(\n",
                "                documents=documents,\n",
                "                precomputed_embeddings=embs,\n",
                "                transformer_name=TRANSFORMER,\n",
                "                umap_args=umap_args,\n",
                "                hdbscan_args=hdbscan_args,\n",
                "                min_count=params[\"min_count\"],\n",
                "            )\n",
                "\n",
                "            n_topics = model.get_num_topics()\n",
                "            elapsed = time.time() - start_time\n",
                "\n",
                "            if n_topics <= 1:\n",
                "                print(f\"  âš  Only {n_topics} topic(s) found, skipping coherence ({elapsed:.1f}s)\")\n",
                "                coherence = None\n",
                "            else:\n",
                "                coherence = calculate_coherence(\n",
                "                    model,\n",
                "                    all_texts_tokenized[subject],\n",
                "                    all_dictionaries[subject]\n",
                "                )\n",
                "                print(f\"  âœ“ Topics: {n_topics} | Coherence: {coherence:.4f} ({elapsed:.1f}s)\")\n",
                "\n",
                "            result_row = {\n",
                "                \"subject\": subject,\n",
                "                \"umap_n_neighbors\": params[\"umap_n_neighbors\"],\n",
                "                \"umap_n_components\": params[\"umap_n_components\"],\n",
                "                \"hdbscan_min_cluster_size\": params[\"hdbscan_min_cluster_size\"],\n",
                "                \"hdbscan_cluster_selection_method\": params[\"hdbscan_cluster_selection_method\"],\n",
                "                \"min_count\": params[\"min_count\"],\n",
                "                \"n_topics\": n_topics,\n",
                "                \"coherence\": coherence,\n",
                "                \"time_seconds\": round(elapsed, 1),\n",
                "            }\n",
                "            results.append(result_row)\n",
                "\n",
                "            del model\n",
                "            gc.collect()\n",
                "\n",
                "        except Exception as e:\n",
                "            print(f\"  âœ— Error: {e}\")\n",
                "            result_row = {\n",
                "                \"subject\": subject,\n",
                "                \"umap_n_neighbors\": params[\"umap_n_neighbors\"],\n",
                "                \"umap_n_components\": params[\"umap_n_components\"],\n",
                "                \"hdbscan_min_cluster_size\": params[\"hdbscan_min_cluster_size\"],\n",
                "                \"hdbscan_cluster_selection_method\": params[\"hdbscan_cluster_selection_method\"],\n",
                "                \"min_count\": params[\"min_count\"],\n",
                "                \"n_topics\": None,\n",
                "                \"coherence\": None,\n",
                "                \"time_seconds\": None,\n",
                "            }\n",
                "            results.append(result_row)\n",
                "\n",
                "        if run_count % 10 == 0:\n",
                "            pd.DataFrame(results).to_csv(csv_path, index=False)\n",
                "            print(f\"  ðŸ’¾ Checkpoint saved ({run_count}/{total_runs})\")\n",
                "\n",
                "results_df = pd.DataFrame(results)\n",
                "results_df.to_csv(csv_path, index=False)\n",
                "print(f\"\\nâœ… All results saved to {csv_path}\")\n",
                "print(f\"Total runs: {len(results_df)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "results-markdown",
            "metadata": {},
            "source": [
                "## Results Summary"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "id": "results-summary",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Total runs: 81\n",
                        "Valid runs (>1 topic): 81\n",
                        "Skipped (1 topic or error): 0\n",
                        "\n",
                        "==========================================================================================\n",
                        "Best Parameters per Subject\n",
                        "==========================================================================================\n",
                        "\n",
                        "CS:\n",
                        "  Best coherence: 0.5893\n",
                        "  Topics: 239\n",
                        "  umap_n_neighbors: 30\n",
                        "  umap_n_components: 30\n",
                        "  hdbscan_min_cluster_size: 50\n",
                        "  hdbscan_cluster_selection_method: eom\n",
                        "  min_count: 50\n",
                        "\n",
                        "MATH:\n",
                        "  Best coherence: 0.5684\n",
                        "  Topics: 252\n",
                        "  umap_n_neighbors: 30\n",
                        "  umap_n_components: 5\n",
                        "  hdbscan_min_cluster_size: 30\n",
                        "  hdbscan_cluster_selection_method: eom\n",
                        "  min_count: 50\n",
                        "\n",
                        "PHYSICS:\n",
                        "  Best coherence: 0.6642\n",
                        "  Topics: 205\n",
                        "  umap_n_neighbors: 30\n",
                        "  umap_n_components: 10\n",
                        "  hdbscan_min_cluster_size: 50\n",
                        "  hdbscan_cluster_selection_method: eom\n",
                        "  min_count: 50\n",
                        "\n",
                        "==========================================================================================\n",
                        "Top 5 per Subject\n",
                        "==========================================================================================\n",
                        "\n",
                        "CS:\n",
                        " umap_n_neighbors  umap_n_components  hdbscan_min_cluster_size hdbscan_cluster_selection_method  min_count  n_topics  coherence\n",
                        "               30                 30                        50                              eom         50       239   0.589346\n",
                        "               30                  5                        50                              eom         50       261   0.585347\n",
                        "               30                 10                        50                              eom         50       258   0.582842\n",
                        "               30                  5                        15                              eom         50       678   0.581752\n",
                        "               10                 10                        30                              eom         50       516   0.580181\n",
                        "\n",
                        "MATH:\n",
                        " umap_n_neighbors  umap_n_components  hdbscan_min_cluster_size hdbscan_cluster_selection_method  min_count  n_topics  coherence\n",
                        "               30                  5                        30                              eom         50       252   0.568396\n",
                        "               30                  5                        50                              eom         50       154   0.567632\n",
                        "               30                 30                        30                              eom         50       256   0.566073\n",
                        "               15                 30                        50                              eom         50       176   0.564505\n",
                        "               10                 30                        30                              eom         50       330   0.561658\n",
                        "\n",
                        "PHYSICS:\n",
                        " umap_n_neighbors  umap_n_components  hdbscan_min_cluster_size hdbscan_cluster_selection_method  min_count  n_topics  coherence\n",
                        "               30                 10                        50                              eom         50       205   0.664215\n",
                        "               30                 30                        50                              eom         50       210   0.660490\n",
                        "               15                  5                        50                              eom         50       237   0.660044\n",
                        "               30                  5                        50                              eom         50       203   0.653390\n",
                        "               10                  5                        50                              eom         50       249   0.651975\n"
                    ]
                }
            ],
            "source": [
                "results_df = pd.read_csv(csv_path)\n",
                "valid_results = results_df.dropna(subset=[\"coherence\"])\n",
                "\n",
                "print(f\"Total runs: {len(results_df)}\")\n",
                "print(f\"Valid runs (>1 topic): {len(valid_results)}\")\n",
                "print(f\"Skipped (1 topic or error): {len(results_df) - len(valid_results)}\")\n",
                "\n",
                "print(\"\\n\" + \"=\" * 90)\n",
                "print(\"Best Parameters per Subject\")\n",
                "print(\"=\" * 90)\n",
                "\n",
                "best_per_subject = {}\n",
                "for subject in LIST_SUBJECT:\n",
                "    subj_results = valid_results[valid_results[\"subject\"] == subject]\n",
                "    if subj_results.empty:\n",
                "        print(f\"\\n{subject.upper()}: No valid results\")\n",
                "        continue\n",
                "\n",
                "    best_idx = subj_results[\"coherence\"].idxmax()\n",
                "    best_row = subj_results.loc[best_idx]\n",
                "    best_per_subject[subject] = best_row\n",
                "\n",
                "    print(f\"\\n{subject.upper()}:\")\n",
                "    print(f\"  Best coherence: {best_row['coherence']:.4f}\")\n",
                "    print(f\"  Topics: {int(best_row['n_topics'])}\")\n",
                "    print(f\"  umap_n_neighbors: {int(best_row['umap_n_neighbors'])}\")\n",
                "    print(f\"  umap_n_components: {int(best_row['umap_n_components'])}\")\n",
                "    print(f\"  hdbscan_min_cluster_size: {int(best_row['hdbscan_min_cluster_size'])}\")\n",
                "    print(f\"  hdbscan_cluster_selection_method: {best_row['hdbscan_cluster_selection_method']}\")\n",
                "    print(f\"  min_count: {int(best_row['min_count'])}\")\n",
                "\n",
                "print(\"\\n\" + \"=\" * 90)\n",
                "print(\"Top 5 per Subject\")\n",
                "print(\"=\" * 90)\n",
                "for subject in LIST_SUBJECT:\n",
                "    subj_results = valid_results[valid_results[\"subject\"] == subject]\n",
                "    if subj_results.empty:\n",
                "        continue\n",
                "    top5 = subj_results.nlargest(5, \"coherence\")\n",
                "    print(f\"\\n{subject.upper()}:\")\n",
                "    print(top5[[\"umap_n_neighbors\", \"umap_n_components\", \"hdbscan_min_cluster_size\",\n",
                "                \"hdbscan_cluster_selection_method\", \"min_count\", \"n_topics\", \"coherence\"]].to_string(index=False))"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "save-best-markdown",
            "metadata": {},
            "source": [
                "## Save Best Models"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "id": "save-best-models",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "======================================================================\n",
                        "Retraining best model for CS\n",
                        "======================================================================\n",
                        "  UMAP: {'n_neighbors': 30, 'n_components': 30, 'metric': 'cosine'}\n",
                        "  HDBSCAN: {'min_cluster_size': 50, 'metric': 'euclidean', 'cluster_selection_method': 'eom'}\n",
                        "  min_count: 50\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
                        "  warnings.warn(\n",
                        "2026-02-13 02:17:54,817 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "  Topics: 239 | Coherence: 0.5782\n",
                        "  âœ“ Model saved to tunning/sentence_transformers_all_MiniLM_L6_v2/best_model_cs\n",
                        "\n",
                        "======================================================================\n",
                        "Retraining best model for MATH\n",
                        "======================================================================\n",
                        "  UMAP: {'n_neighbors': 30, 'n_components': 5, 'metric': 'cosine'}\n",
                        "  HDBSCAN: {'min_cluster_size': 30, 'metric': 'euclidean', 'cluster_selection_method': 'eom'}\n",
                        "  min_count: 50\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
                        "  warnings.warn(\n",
                        "2026-02-13 02:20:38,520 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "  Topics: 254 | Coherence: 0.5768\n",
                        "  âœ“ Model saved to tunning/sentence_transformers_all_MiniLM_L6_v2/best_model_math\n",
                        "\n",
                        "======================================================================\n",
                        "Retraining best model for PHYSICS\n",
                        "======================================================================\n",
                        "  UMAP: {'n_neighbors': 30, 'n_components': 10, 'metric': 'cosine'}\n",
                        "  HDBSCAN: {'min_cluster_size': 50, 'metric': 'euclidean', 'cluster_selection_method': 'eom'}\n",
                        "  min_count: 50\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
                        "  warnings.warn(\n",
                        "2026-02-13 02:22:10,618 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "  Topics: 202 | Coherence: 0.6567\n",
                        "  âœ“ Model saved to tunning/sentence_transformers_all_MiniLM_L6_v2/best_model_physics\n",
                        "\n",
                        "âœ… All best models saved!\n"
                    ]
                }
            ],
            "source": [
                "for subject, best_row in best_per_subject.items():\n",
                "    print(f\"\\n{'=' * 70}\")\n",
                "    print(f\"Retraining best model for {subject.upper()}\")\n",
                "    print(f\"{'=' * 70}\")\n",
                "\n",
                "    df = all_data[subject]\n",
                "    documents = df['text'].fillna('').tolist()\n",
                "    embs = all_embeddings[subject]\n",
                "\n",
                "    umap_args = {\n",
                "        \"n_neighbors\": int(best_row[\"umap_n_neighbors\"]),\n",
                "        \"n_components\": int(best_row[\"umap_n_components\"]),\n",
                "        \"metric\": \"cosine\",\n",
                "    }\n",
                "    hdbscan_args = {\n",
                "        \"min_cluster_size\": int(best_row[\"hdbscan_min_cluster_size\"]),\n",
                "        \"metric\": \"euclidean\",\n",
                "        \"cluster_selection_method\": best_row[\"hdbscan_cluster_selection_method\"],\n",
                "    }\n",
                "\n",
                "    print(f\"  UMAP: {umap_args}\")\n",
                "    print(f\"  HDBSCAN: {hdbscan_args}\")\n",
                "    print(f\"  min_count: {int(best_row['min_count'])}\")\n",
                "\n",
                "    model = train_top2vec_with_precomputed(\n",
                "        documents=documents,\n",
                "        precomputed_embeddings=embs,\n",
                "        transformer_name=TRANSFORMER,\n",
                "        umap_args=umap_args,\n",
                "        hdbscan_args=hdbscan_args,\n",
                "        min_count=int(best_row[\"min_count\"]),\n",
                "    )\n",
                "\n",
                "    n_topics = model.get_num_topics()\n",
                "    coherence = calculate_coherence(\n",
                "        model,\n",
                "        all_texts_tokenized[subject],\n",
                "        all_dictionaries[subject]\n",
                "    )\n",
                "    print(f\"  Topics: {n_topics} | Coherence: {coherence:.4f}\")\n",
                "\n",
                "    save_path = OUTPUT_DIR / f\"best_model_{subject}\"\n",
                "    save_path.mkdir(parents=True, exist_ok=True)\n",
                "    model.save(str(save_path / \"model\"))\n",
                "    print(f\"  âœ“ Model saved to {save_path}\")\n",
                "\n",
                "    del model\n",
                "    gc.collect()\n",
                "\n",
                "print(\"\\nâœ… All best models saved!\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.13.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
