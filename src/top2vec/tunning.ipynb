{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro-markdown",
   "metadata": {},
   "source": [
    "# Top2Vec Hyperparameter Tuning\n",
    "\n",
    "Based on `coherence_results_v1.csv`, `sentence-transformers/all-MiniLM-L6-v2` achieved the highest average coherence across all subjects. This notebook performs grid-search hyperparameter tuning over UMAP and HDBSCAN parameters to find the best Top2Vec configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from typing import List, Optional, Dict, Any\n",
    "from tqdm import tqdm\n",
    "from itertools import product\n",
    "import warnings\n",
    "import time\n",
    "\n",
    "from top2vec import Top2Vec\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.preprocessing import normalize\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "config-markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "config",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding: sentence-transformers/all-MiniLM-L6-v2\n",
      "Output directory: tunning/sentence_transformers_all_MiniLM_L6_v2\n"
     ]
    }
   ],
   "source": [
    "VERSION = \"v1\"\n",
    "LIST_SUBJECT = [\"cs\", \"math\", \"physics\"]\n",
    "\n",
    "TRANSFORMER = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "EMBEDDING_DIM = 384\n",
    "\n",
    "BASE_DIR = Path(\"../../dataset\")\n",
    "EMBEDDING_DIR = Path(\"../bertopic/embedding\")\n",
    "TUNNING_DIR = Path(\"./tunning\")\n",
    "\n",
    "SAFE_MODEL_NAME = TRANSFORMER.replace(\"/\", \"_\").replace(\"-\", \"_\")\n",
    "OUTPUT_DIR = TUNNING_DIR / SAFE_MODEL_NAME\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Embedding: {TRANSFORMER}\")\n",
    "print(f\"Output directory: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grid-markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "grid",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameter combinations: 27\n",
      "Total runs (combinations x subjects): 81\n"
     ]
    }
   ],
   "source": [
    "PARAM_GRID = {\n",
    "    \"umap_n_neighbors\": [10, 15, 30],\n",
    "    \"umap_n_components\": [5, 10, 30],\n",
    "    \"hdbscan_min_cluster_size\": [15, 30, 50],\n",
    "    \"hdbscan_cluster_selection_method\": [\"eom\"],\n",
    "    \"min_count\": [50],\n",
    "}\n",
    "\n",
    "keys = list(PARAM_GRID.keys())\n",
    "values = list(PARAM_GRID.values())\n",
    "all_combos = list(product(*values))\n",
    "\n",
    "print(f\"Total parameter combinations: {len(all_combos)}\")\n",
    "print(f\"Total runs (combinations x subjects): {len(all_combos) * len(LIST_SUBJECT)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "helpers-markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "helper-functions",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_safe_name(model_name: str) -> str:\n",
    "    return model_name.replace(\"/\", \"_\").replace(\"-\", \"_\")\n",
    "\n",
    "\n",
    "def load_dataset(subject: str) -> Optional[pd.DataFrame]:\n",
    "    file_path = BASE_DIR / subject / \"emb\" / f\"{VERSION}.csv\"\n",
    "    if not file_path.exists():\n",
    "        print(f\"File not found: {file_path}\")\n",
    "        return None\n",
    "    return pd.read_csv(file_path)\n",
    "\n",
    "\n",
    "def load_mmap_embeddings(\n",
    "    mmap_path: str,\n",
    "    num_documents: int,\n",
    "    embedding_dim: int,\n",
    "    dtype: str = \"float32\"\n",
    ") -> Optional[np.ndarray]:\n",
    "    try:\n",
    "        embs = np.array(np.memmap(\n",
    "            mmap_path, dtype=dtype, mode=\"r\",\n",
    "            shape=(num_documents, embedding_dim)\n",
    "        ))\n",
    "        return normalize(embs)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Embedding not found: {mmap_path}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading embeddings: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def train_top2vec_with_precomputed(\n",
    "    documents: List[str],\n",
    "    precomputed_embeddings: np.ndarray,\n",
    "    transformer_name: str,\n",
    "    umap_args: Dict[str, Any] = None,\n",
    "    hdbscan_args: Dict[str, Any] = None,\n",
    "    min_count: int = 50,\n",
    ") -> Top2Vec:\n",
    "    num_docs = len(documents)\n",
    "    st_model = SentenceTransformer(transformer_name)\n",
    "\n",
    "    original_embed_docs = Top2Vec._embed_documents\n",
    "\n",
    "    def patched_embed_documents(self, train_corpus, batch_size):\n",
    "        if len(train_corpus) == num_docs:\n",
    "            return precomputed_embeddings\n",
    "        else:\n",
    "            return st_model.encode(train_corpus, batch_size=batch_size, show_progress_bar=False)\n",
    "\n",
    "    Top2Vec._embed_documents = patched_embed_documents\n",
    "\n",
    "    model = Top2Vec(\n",
    "        documents=documents,\n",
    "        embedding_model='all-MiniLM-L6-v2',\n",
    "        min_count=min_count,\n",
    "        contextual_top2vec=False,\n",
    "        ngram_vocab=False,\n",
    "        umap_args=umap_args,\n",
    "        hdbscan_args=hdbscan_args,\n",
    "        verbose=False,\n",
    "    )\n",
    "\n",
    "    Top2Vec._embed_documents = original_embed_docs\n",
    "    del st_model\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def calculate_coherence(\n",
    "    model: Top2Vec,\n",
    "    texts_tokenized: List[List[str]],\n",
    "    dictionary: Dictionary,\n",
    "    top_n: int = 5\n",
    ") -> float:\n",
    "    num_topics = model.get_num_topics()\n",
    "    topic_words, _, _ = model.get_topics(num_topics)\n",
    "    topic_words_sliced = topic_words[:, :top_n]\n",
    "\n",
    "    cm = CoherenceModel(\n",
    "        topics=topic_words_sliced.tolist(),\n",
    "        texts=texts_tokenized,\n",
    "        dictionary=dictionary,\n",
    "        coherence='c_v',\n",
    "        processes=1\n",
    "    )\n",
    "\n",
    "    return cm.get_coherence()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load-data-markdown",
   "metadata": {},
   "source": [
    "## Load Datasets, Embeddings & Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "load-data",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cs: 165,756 documents loaded\n",
      "  Embeddings loaded: (165756, 384)\n",
      "  Tokenizing for coherence...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  cs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 165756/165756 [00:02<00:00, 72310.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "math: 157,085 documents loaded\n",
      "  Embeddings loaded: (157085, 384)\n",
      "  Tokenizing for coherence...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  math: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157085/157085 [00:01<00:00, 134250.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "physics: 146,311 documents loaded\n",
      "  Embeddings loaded: (146311, 384)\n",
      "  Tokenizing for coherence...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  physics: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 146311/146311 [00:02<00:00, 63082.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Subjects ready: ['cs', 'math', 'physics']\n"
     ]
    }
   ],
   "source": [
    "all_data = {}\n",
    "all_embeddings = {}\n",
    "all_texts_tokenized = {}\n",
    "all_dictionaries = {}\n",
    "\n",
    "safe_name = get_model_safe_name(TRANSFORMER)\n",
    "\n",
    "for subject in LIST_SUBJECT:\n",
    "    df = load_dataset(subject)\n",
    "    if df is None:\n",
    "        continue\n",
    "\n",
    "    all_data[subject] = df\n",
    "    print(f\"{subject}: {len(df):,} documents loaded\")\n",
    "\n",
    "    mmap_path = EMBEDDING_DIR / subject / f\"{safe_name}_{VERSION}.mmap\"\n",
    "    embs = load_mmap_embeddings(str(mmap_path), len(df), EMBEDDING_DIM)\n",
    "    if embs is None:\n",
    "        print(f\"  âš  Skipping {subject}: embedding not found\")\n",
    "        continue\n",
    "    all_embeddings[subject] = embs\n",
    "    print(f\"  Embeddings loaded: {embs.shape}\")\n",
    "\n",
    "    print(f\"  Tokenizing for coherence...\")\n",
    "    texts_tokenized = [text.split() for text in tqdm(df['text'].fillna('').tolist(), desc=f\"  {subject}\")]\n",
    "    all_texts_tokenized[subject] = texts_tokenized\n",
    "    all_dictionaries[subject] = Dictionary(texts_tokenized)\n",
    "\n",
    "print(f\"\\nSubjects ready: {list(all_embeddings.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tuning-markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "tuning-loop",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Subject: CS (165,756 documents)\n",
      "======================================================================\n",
      "[1/81] cs | nn=10 nc=5 mcs=15 csm=eom mc=50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "2026-02-15 01:03:28,139 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Topics: 914 | Coherence: 0.5700 (82.2s)\n",
      "  ðŸ† New best for cs! Coherence: 0.5700 â†’ Model saved to tunning/sentence_transformers_all_MiniLM_L6_v2/best_model_cs\n",
      "[2/81] cs | nn=10 nc=5 mcs=30 csm=eom mc=50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "2026-02-15 01:07:00,148 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Topics: 505 | Coherence: 0.5748 (65.1s)\n",
      "  ðŸ† New best for cs! Coherence: 0.5748 â†’ Model saved to tunning/sentence_transformers_all_MiniLM_L6_v2/best_model_cs\n",
      "[3/81] cs | nn=10 nc=5 mcs=50 csm=eom mc=50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "2026-02-15 01:09:49,456 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Topics: 313 | Coherence: 0.5748 (65.2s)\n",
      "  ðŸ† New best for cs! Coherence: 0.5748 â†’ Model saved to tunning/sentence_transformers_all_MiniLM_L6_v2/best_model_cs\n",
      "[4/81] cs | nn=10 nc=10 mcs=15 csm=eom mc=50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "2026-02-15 01:12:21,526 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Topics: 919 | Coherence: 0.5728 (67.0s)\n",
      "[5/81] cs | nn=10 nc=10 mcs=30 csm=eom mc=50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "2026-02-15 01:15:42,917 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Topics: 506 | Coherence: 0.5762 (66.1s)\n",
      "  ðŸ† New best for cs! Coherence: 0.5762 â†’ Model saved to tunning/sentence_transformers_all_MiniLM_L6_v2/best_model_cs\n",
      "[6/81] cs | nn=10 nc=10 mcs=50 csm=eom mc=50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "2026-02-15 01:18:34,738 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Topics: 312 | Coherence: 0.5759 (66.9s)\n",
      "[7/81] cs | nn=10 nc=30 mcs=15 csm=eom mc=50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "2026-02-15 01:21:06,545 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Topics: 942 | Coherence: 0.5720 (82.7s)\n",
      "[8/81] cs | nn=10 nc=30 mcs=30 csm=eom mc=50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "2026-02-15 01:24:43,390 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Topics: 515 | Coherence: 0.5784 (83.4s)\n",
      "  ðŸ† New best for cs! Coherence: 0.5784 â†’ Model saved to tunning/sentence_transformers_all_MiniLM_L6_v2/best_model_cs\n",
      "[9/81] cs | nn=10 nc=30 mcs=50 csm=eom mc=50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "2026-02-15 01:27:51,654 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Topics: 304 | Coherence: 0.5779 (82.4s)\n",
      "[10/81] cs | nn=15 nc=5 mcs=15 csm=eom mc=50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "2026-02-15 01:30:39,157 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Topics: 815 | Coherence: 0.5754 (68.2s)\n",
      "  ðŸ’¾ Checkpoint saved (10/81)\n",
      "[11/81] cs | nn=15 nc=5 mcs=30 csm=eom mc=50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "2026-02-15 01:33:50,933 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Topics: 462 | Coherence: 0.5795 (66.8s)\n",
      "  ðŸ† New best for cs! Coherence: 0.5795 â†’ Model saved to tunning/sentence_transformers_all_MiniLM_L6_v2/best_model_cs\n",
      "[12/81] cs | nn=15 nc=5 mcs=50 csm=eom mc=50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "2026-02-15 01:36:40,872 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Topics: 286 | Coherence: 0.5716 (67.0s)\n",
      "[13/81] cs | nn=15 nc=10 mcs=15 csm=eom mc=50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "2026-02-15 01:39:09,134 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Topics: 829 | Coherence: 0.5789 (68.1s)\n",
      "[14/81] cs | nn=15 nc=10 mcs=30 csm=eom mc=50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "2026-02-15 01:42:25,268 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Topics: 487 | Coherence: 0.5789 (69.7s)\n",
      "[15/81] cs | nn=15 nc=10 mcs=50 csm=eom mc=50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "2026-02-15 01:45:16,181 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Topics: 300 | Coherence: 0.5880 (68.9s)\n",
      "  ðŸ† New best for cs! Coherence: 0.5880 â†’ Model saved to tunning/sentence_transformers_all_MiniLM_L6_v2/best_model_cs\n",
      "[16/81] cs | nn=15 nc=30 mcs=15 csm=eom mc=50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "2026-02-15 01:47:50,619 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Topics: 840 | Coherence: 0.5747 (85.0s)\n",
      "[17/81] cs | nn=15 nc=30 mcs=30 csm=eom mc=50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "2026-02-15 01:51:20,230 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Topics: 483 | Coherence: 0.5775 (84.7s)\n",
      "[18/81] cs | nn=15 nc=30 mcs=50 csm=eom mc=50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "2026-02-15 01:54:24,630 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Topics: 303 | Coherence: 0.5877 (85.2s)\n",
      "[19/81] cs | nn=30 nc=5 mcs=15 csm=eom mc=50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "2026-02-15 01:57:14,334 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Topics: 682 | Coherence: 0.5804 (76.1s)\n",
      "[20/81] cs | nn=30 nc=5 mcs=30 csm=eom mc=50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "2026-02-15 02:00:28,312 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Topics: 403 | Coherence: 0.5811 (75.1s)\n",
      "  ðŸ’¾ Checkpoint saved (20/81)\n",
      "[21/81] cs | nn=30 nc=5 mcs=50 csm=eom mc=50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "2026-02-15 02:03:14,394 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Topics: 255 | Coherence: 0.5832 (76.1s)\n",
      "[22/81] cs | nn=30 nc=10 mcs=15 csm=eom mc=50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "2026-02-15 02:05:49,577 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Topics: 706 | Coherence: 0.5745 (77.2s)\n",
      "[23/81] cs | nn=30 nc=10 mcs=30 csm=eom mc=50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "2026-02-15 02:09:04,576 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Topics: 431 | Coherence: 0.5776 (76.5s)\n",
      "[24/81] cs | nn=30 nc=10 mcs=50 csm=eom mc=50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "2026-02-15 02:11:59,100 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Topics: 248 | Coherence: 0.5934 (78.5s)\n",
      "  ðŸ† New best for cs! Coherence: 0.5934 â†’ Model saved to tunning/sentence_transformers_all_MiniLM_L6_v2/best_model_cs\n",
      "[25/81] cs | nn=30 nc=30 mcs=15 csm=eom mc=50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "2026-02-15 02:14:37,041 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Topics: 697 | Coherence: 0.5770 (96.6s)\n",
      "[26/81] cs | nn=30 nc=30 mcs=30 csm=eom mc=50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "2026-02-15 02:18:12,494 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Topics: 400 | Coherence: 0.5730 (96.3s)\n",
      "[27/81] cs | nn=30 nc=30 mcs=50 csm=eom mc=50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "2026-02-15 02:21:23,200 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Topics: 268 | Coherence: 0.5817 (99.5s)\n",
      "======================================================================\n",
      "Subject: MATH (157,085 documents)\n",
      "======================================================================\n",
      "[28/81] math | nn=10 nc=5 mcs=15 csm=eom mc=50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "2026-02-15 02:24:11,347 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Topics: 733 | Coherence: 0.5463 (50.4s)\n",
      "  ðŸ† New best for math! Coherence: 0.5463 â†’ Model saved to tunning/sentence_transformers_all_MiniLM_L6_v2/best_model_math\n",
      "[29/81] math | nn=10 nc=5 mcs=30 csm=eom mc=50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "2026-02-15 02:25:54,991 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Topics: 375 | Coherence: 0.5409 (50.2s)\n",
      "[30/81] math | nn=10 nc=5 mcs=50 csm=eom mc=50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "2026-02-15 02:27:26,937 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Topics: 246 | Coherence: 0.5534 (50.3s)\n",
      "  ðŸ† New best for math! Coherence: 0.5534 â†’ Model saved to tunning/sentence_transformers_all_MiniLM_L6_v2/best_model_math\n",
      "  ðŸ’¾ Checkpoint saved (30/81)\n",
      "[31/81] math | nn=10 nc=10 mcs=15 csm=eom mc=50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "2026-02-15 02:28:56,220 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Topics: 749 | Coherence: 0.5509 (51.6s)\n",
      "[32/81] math | nn=10 nc=10 mcs=30 csm=eom mc=50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "2026-02-15 02:30:43,131 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Topics: 391 | Coherence: 0.5468 (52.6s)\n",
      "[33/81] math | nn=10 nc=10 mcs=50 csm=eom mc=50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "2026-02-15 02:32:16,860 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Topics: 236 | Coherence: 0.5465 (51.6s)\n",
      "[34/81] math | nn=10 nc=30 mcs=15 csm=eom mc=50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "2026-02-15 02:33:45,276 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Topics: 745 | Coherence: 0.5407 (66.0s)\n",
      "[35/81] math | nn=10 nc=30 mcs=30 csm=eom mc=50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "2026-02-15 02:35:44,286 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Topics: 382 | Coherence: 0.5451 (65.0s)\n",
      "[36/81] math | nn=10 nc=30 mcs=50 csm=eom mc=50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "2026-02-15 02:37:31,543 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Topics: 235 | Coherence: 0.5427 (65.4s)\n",
      "[37/81] math | nn=15 nc=5 mcs=15 csm=eom mc=50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "2026-02-15 02:39:13,455 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Topics: 655 | Coherence: 0.5447 (52.7s)\n",
      "[38/81] math | nn=15 nc=5 mcs=30 csm=eom mc=50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "2026-02-15 02:40:57,178 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Topics: 357 | Coherence: 0.5490 (52.8s)\n",
      "[39/81] math | nn=15 nc=5 mcs=50 csm=eom mc=50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "2026-02-15 02:42:32,167 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Topics: 243 | Coherence: 0.5510 (53.2s)\n",
      "[40/81] math | nn=15 nc=10 mcs=15 csm=eom mc=50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "2026-02-15 02:44:02,023 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Topics: 663 | Coherence: 0.5460 (54.6s)\n",
      "  ðŸ’¾ Checkpoint saved (40/81)\n",
      "[41/81] math | nn=15 nc=10 mcs=30 csm=eom mc=50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "2026-02-15 02:45:48,849 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Topics: 372 | Coherence: 0.5515 (54.7s)\n",
      "[42/81] math | nn=15 nc=10 mcs=50 csm=eom mc=50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "2026-02-15 02:47:25,089 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Topics: 208 | Coherence: 0.5447 (54.3s)\n",
      "[43/81] math | nn=15 nc=30 mcs=15 csm=eom mc=50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "2026-02-15 02:48:55,243 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Topics: 648 | Coherence: 0.5443 (68.4s)\n",
      "[44/81] math | nn=15 nc=30 mcs=30 csm=eom mc=50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "2026-02-15 02:50:56,397 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Topics: 351 | Coherence: 0.5462 (68.9s)\n",
      "[45/81] math | nn=15 nc=30 mcs=50 csm=eom mc=50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "2026-02-15 02:52:46,790 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Topics: 237 | Coherence: 0.5491 (68.7s)\n",
      "[46/81] math | nn=30 nc=5 mcs=15 csm=eom mc=50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "2026-02-15 02:54:31,862 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Topics: 515 | Coherence: 0.5504 (61.4s)\n",
      "[47/81] math | nn=30 nc=5 mcs=30 csm=eom mc=50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "2026-02-15 02:56:20,741 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Topics: 317 | Coherence: 0.5523 (61.2s)\n",
      "[48/81] math | nn=30 nc=5 mcs=50 csm=eom mc=50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "2026-02-15 02:58:01,988 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Topics: 198 | Coherence: 0.5651 (61.5s)\n",
      "  ðŸ† New best for math! Coherence: 0.5651 â†’ Model saved to tunning/sentence_transformers_all_MiniLM_L6_v2/best_model_math\n",
      "[49/81] math | nn=30 nc=10 mcs=15 csm=eom mc=50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "2026-02-15 02:59:39,625 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Topics: 546 | Coherence: 0.5557 (63.1s)\n",
      "[50/81] math | nn=30 nc=10 mcs=30 csm=eom mc=50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "2026-02-15 03:01:30,605 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Topics: 335 | Coherence: 0.5535 (62.3s)\n",
      "  ðŸ’¾ Checkpoint saved (50/81)\n",
      "[51/81] math | nn=30 nc=10 mcs=50 csm=eom mc=50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "2026-02-15 03:03:14,712 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Topics: 202 | Coherence: 0.5555 (63.2s)\n",
      "[52/81] math | nn=30 nc=30 mcs=15 csm=eom mc=50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "2026-02-15 03:04:52,826 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Topics: 547 | Coherence: 0.5555 (78.5s)\n",
      "[53/81] math | nn=30 nc=30 mcs=30 csm=eom mc=50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "2026-02-15 03:06:59,687 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Topics: 305 | Coherence: 0.5567 (78.4s)\n",
      "[54/81] math | nn=30 nc=30 mcs=50 csm=eom mc=50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "2026-02-15 03:08:58,449 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Topics: 194 | Coherence: 0.5547 (79.1s)\n",
      "======================================================================\n",
      "Subject: PHYSICS (146,311 documents)\n",
      "======================================================================\n",
      "[55/81] physics | nn=10 nc=5 mcs=15 csm=eom mc=50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "2026-02-15 03:10:58,234 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Topics: 774 | Coherence: 0.6310 (54.9s)\n",
      "  ðŸ† New best for physics! Coherence: 0.6310 â†’ Model saved to tunning/sentence_transformers_all_MiniLM_L6_v2/best_model_physics\n",
      "[56/81] physics | nn=10 nc=5 mcs=30 csm=eom mc=50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "2026-02-15 03:13:15,388 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Topics: 407 | Coherence: 0.6343 (54.2s)\n",
      "  ðŸ† New best for physics! Coherence: 0.6343 â†’ Model saved to tunning/sentence_transformers_all_MiniLM_L6_v2/best_model_physics\n",
      "[57/81] physics | nn=10 nc=5 mcs=50 csm=eom mc=50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "2026-02-15 03:15:17,075 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Topics: 243 | Coherence: 0.6452 (53.2s)\n",
      "  ðŸ† New best for physics! Coherence: 0.6452 â†’ Model saved to tunning/sentence_transformers_all_MiniLM_L6_v2/best_model_physics\n",
      "[58/81] physics | nn=10 nc=10 mcs=15 csm=eom mc=50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "2026-02-15 03:17:10,896 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Topics: 763 | Coherence: 0.6272 (55.4s)\n",
      "[59/81] physics | nn=10 nc=10 mcs=30 csm=eom mc=50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "2026-02-15 03:19:25,815 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Topics: 401 | Coherence: 0.6359 (55.3s)\n",
      "[60/81] physics | nn=10 nc=10 mcs=50 csm=eom mc=50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "2026-02-15 03:21:26,178 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Topics: 247 | Coherence: 0.6539 (55.0s)\n",
      "  ðŸ† New best for physics! Coherence: 0.6539 â†’ Model saved to tunning/sentence_transformers_all_MiniLM_L6_v2/best_model_physics\n",
      "  ðŸ’¾ Checkpoint saved (60/81)\n",
      "[61/81] physics | nn=10 nc=30 mcs=15 csm=eom mc=50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "2026-02-15 03:23:19,903 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Topics: 776 | Coherence: 0.6257 (67.4s)\n",
      "[62/81] physics | nn=10 nc=30 mcs=30 csm=eom mc=50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "2026-02-15 03:25:47,645 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Topics: 413 | Coherence: 0.6325 (67.4s)\n",
      "[63/81] physics | nn=10 nc=30 mcs=50 csm=eom mc=50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "2026-02-15 03:28:02,487 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Topics: 249 | Coherence: 0.6484 (67.5s)\n",
      "[64/81] physics | nn=15 nc=5 mcs=15 csm=eom mc=50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "2026-02-15 03:30:09,380 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Topics: 682 | Coherence: 0.6359 (56.3s)\n",
      "[65/81] physics | nn=15 nc=5 mcs=30 csm=eom mc=50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "2026-02-15 03:32:24,122 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Topics: 352 | Coherence: 0.6450 (55.8s)\n",
      "[66/81] physics | nn=15 nc=5 mcs=50 csm=eom mc=50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "2026-02-15 03:34:25,130 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Topics: 224 | Coherence: 0.6565 (56.1s)\n",
      "  ðŸ† New best for physics! Coherence: 0.6565 â†’ Model saved to tunning/sentence_transformers_all_MiniLM_L6_v2/best_model_physics\n",
      "[67/81] physics | nn=15 nc=10 mcs=15 csm=eom mc=50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "2026-02-15 03:36:20,707 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Topics: 673 | Coherence: 0.6312 (57.8s)\n",
      "[68/81] physics | nn=15 nc=10 mcs=30 csm=eom mc=50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "2026-02-15 03:38:34,782 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Topics: 367 | Coherence: 0.6399 (57.9s)\n",
      "[69/81] physics | nn=15 nc=10 mcs=50 csm=eom mc=50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "2026-02-15 03:40:38,335 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Topics: 231 | Coherence: 0.6545 (56.7s)\n",
      "[70/81] physics | nn=15 nc=30 mcs=15 csm=eom mc=50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "2026-02-15 03:42:32,451 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Topics: 666 | Coherence: 0.6314 (69.6s)\n",
      "  ðŸ’¾ Checkpoint saved (70/81)\n",
      "[71/81] physics | nn=15 nc=30 mcs=30 csm=eom mc=50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "2026-02-15 03:44:58,646 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Topics: 371 | Coherence: 0.6389 (70.0s)\n",
      "[72/81] physics | nn=15 nc=30 mcs=50 csm=eom mc=50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "2026-02-15 03:47:13,640 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Topics: 231 | Coherence: 0.6515 (70.0s)\n",
      "[73/81] physics | nn=30 nc=5 mcs=15 csm=eom mc=50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "2026-02-15 03:49:20,474 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Topics: 578 | Coherence: 0.6390 (64.0s)\n",
      "[74/81] physics | nn=30 nc=5 mcs=30 csm=eom mc=50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "2026-02-15 03:51:42,184 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Topics: 309 | Coherence: 0.6521 (63.4s)\n",
      "[75/81] physics | nn=30 nc=5 mcs=50 csm=eom mc=50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "2026-02-15 03:53:48,628 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Topics: 207 | Coherence: 0.6583 (64.1s)\n",
      "  ðŸ† New best for physics! Coherence: 0.6583 â†’ Model saved to tunning/sentence_transformers_all_MiniLM_L6_v2/best_model_physics\n",
      "[76/81] physics | nn=30 nc=10 mcs=15 csm=eom mc=50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "2026-02-15 03:55:48,636 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Topics: 571 | Coherence: 0.6395 (65.5s)\n",
      "[77/81] physics | nn=30 nc=10 mcs=30 csm=eom mc=50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "2026-02-15 03:58:09,773 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Topics: 319 | Coherence: 0.6446 (64.9s)\n",
      "[78/81] physics | nn=30 nc=10 mcs=50 csm=eom mc=50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "2026-02-15 04:00:18,553 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Topics: 205 | Coherence: 0.6567 (64.5s)\n",
      "[79/81] physics | nn=30 nc=30 mcs=15 csm=eom mc=50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "2026-02-15 04:02:17,759 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Topics: 579 | Coherence: 0.6281 (78.9s)\n",
      "[80/81] physics | nn=30 nc=30 mcs=30 csm=eom mc=50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "2026-02-15 04:04:52,318 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Topics: 304 | Coherence: 0.6431 (80.0s)\n",
      "  ðŸ’¾ Checkpoint saved (80/81)\n",
      "[81/81] physics | nn=30 nc=30 mcs=50 csm=eom mc=50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nedo/Kuliah/TA/Program/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "2026-02-15 04:07:15,508 - top2vec - INFO - Downloading all-MiniLM-L6-v2 model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Topics: 207 | Coherence: 0.6623 (80.3s)\n",
      "  ðŸ† New best for physics! Coherence: 0.6623 â†’ Model saved to tunning/sentence_transformers_all_MiniLM_L6_v2/best_model_physics\n",
      "âœ… All results saved to tunning/sentence_transformers_all_MiniLM_L6_v2/tuning_results.csv\n",
      "Total runs: 81\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "csv_path = OUTPUT_DIR / \"tuning_results.csv\"\n",
    "best_coherence = {subject: -1.0 for subject in all_embeddings}\n",
    "\n",
    "total_runs = len(all_combos) * len(all_embeddings)\n",
    "run_count = 0\n",
    "\n",
    "for subject in all_embeddings:\n",
    "    df = all_data[subject]\n",
    "    documents = df[\"text\"].fillna(\"\").tolist()\n",
    "    embs = all_embeddings[subject]\n",
    "\n",
    "    print(f\"{\"=\" * 70}\")\n",
    "    print(f\"Subject: {subject.upper()} ({len(documents):,} documents)\")\n",
    "    print(f\"{\"=\" * 70}\")\n",
    "\n",
    "    for combo in all_combos:\n",
    "        run_count += 1\n",
    "        params = dict(zip(keys, combo))\n",
    "\n",
    "        umap_args = {\n",
    "            \"n_neighbors\": params[\"umap_n_neighbors\"],\n",
    "            \"n_components\": params[\"umap_n_components\"],\n",
    "            \"metric\": \"cosine\",\n",
    "        }\n",
    "        hdbscan_args = {\n",
    "            \"min_cluster_size\": params[\"hdbscan_min_cluster_size\"],\n",
    "            \"metric\": \"euclidean\",\n",
    "            \"cluster_selection_method\": params[\"hdbscan_cluster_selection_method\"],\n",
    "        }\n",
    "\n",
    "        print(f\"[{run_count}/{total_runs}] {subject} | \"\n",
    "              f\"nn={params[\"umap_n_neighbors\"]} nc={params[\"umap_n_components\"]} \"\n",
    "              f\"mcs={params[\"hdbscan_min_cluster_size\"]} csm={params[\"hdbscan_cluster_selection_method\"]} \"\n",
    "              f\"mc={params[\"min_count\"]}\")\n",
    "\n",
    "        try:\n",
    "            start_time = time.time()\n",
    "\n",
    "            model = train_top2vec_with_precomputed(\n",
    "                documents=documents,\n",
    "                precomputed_embeddings=embs,\n",
    "                transformer_name=TRANSFORMER,\n",
    "                umap_args=umap_args,\n",
    "                hdbscan_args=hdbscan_args,\n",
    "                min_count=params[\"min_count\"],\n",
    "            )\n",
    "\n",
    "            n_topics = model.get_num_topics()\n",
    "            elapsed = time.time() - start_time\n",
    "\n",
    "            if n_topics <= 1:\n",
    "                print(f\"  âš  Only {n_topics} topic(s) found, skipping coherence ({elapsed:.1f}s)\")\n",
    "                coherence = None\n",
    "            else:\n",
    "                coherence = calculate_coherence(\n",
    "                    model,\n",
    "                    all_texts_tokenized[subject],\n",
    "                    all_dictionaries[subject]\n",
    "                )\n",
    "                print(f\"  âœ“ Topics: {n_topics} | Coherence: {coherence:.4f} ({elapsed:.1f}s)\")\n",
    "\n",
    "                if coherence > best_coherence[subject]:\n",
    "                    best_coherence[subject] = coherence\n",
    "                    save_path = OUTPUT_DIR / f\"best_model_{subject}\"\n",
    "                    save_path.mkdir(parents=True, exist_ok=True)\n",
    "                    model.save(str(save_path / \"model\"))\n",
    "                    print(f\"  ðŸ† New best for {subject}! Coherence: {coherence:.4f} â†’ Model saved to {save_path}\")\n",
    "\n",
    "            result_row = {\n",
    "                \"subject\": subject,\n",
    "                \"umap_n_neighbors\": params[\"umap_n_neighbors\"],\n",
    "                \"umap_n_components\": params[\"umap_n_components\"],\n",
    "                \"hdbscan_min_cluster_size\": params[\"hdbscan_min_cluster_size\"],\n",
    "                \"hdbscan_cluster_selection_method\": params[\"hdbscan_cluster_selection_method\"],\n",
    "                \"min_count\": params[\"min_count\"],\n",
    "                \"n_topics\": n_topics,\n",
    "                \"coherence\": coherence,\n",
    "                \"time_seconds\": round(elapsed, 1),\n",
    "            }\n",
    "            results.append(result_row)\n",
    "\n",
    "            del model\n",
    "            gc.collect()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"  âœ— Error: {e}\")\n",
    "            result_row = {\n",
    "                \"subject\": subject,\n",
    "                \"umap_n_neighbors\": params[\"umap_n_neighbors\"],\n",
    "                \"umap_n_components\": params[\"umap_n_components\"],\n",
    "                \"hdbscan_min_cluster_size\": params[\"hdbscan_min_cluster_size\"],\n",
    "                \"hdbscan_cluster_selection_method\": params[\"hdbscan_cluster_selection_method\"],\n",
    "                \"min_count\": params[\"min_count\"],\n",
    "                \"n_topics\": None,\n",
    "                \"coherence\": None,\n",
    "                \"time_seconds\": None,\n",
    "            }\n",
    "            results.append(result_row)\n",
    "\n",
    "        if run_count % 10 == 0:\n",
    "            pd.DataFrame(results).to_csv(csv_path, index=False)\n",
    "            print(f\"  ðŸ’¾ Checkpoint saved ({run_count}/{total_runs})\")\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(csv_path, index=False)\n",
    "print(f\"âœ… All results saved to {csv_path}\")\n",
    "print(f\"Total runs: {len(results_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "results-markdown",
   "metadata": {},
   "source": [
    "## Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "results-summary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total runs: 81\n",
      "Valid runs (>1 topic): 81\n",
      "Skipped (1 topic or error): 0\n",
      "\n",
      "==========================================================================================\n",
      "Best Parameters per Subject\n",
      "==========================================================================================\n",
      "\n",
      "CS:\n",
      "  Best coherence: 0.5934\n",
      "  Topics: 248\n",
      "  umap_n_neighbors: 30\n",
      "  umap_n_components: 10\n",
      "  hdbscan_min_cluster_size: 50\n",
      "  hdbscan_cluster_selection_method: eom\n",
      "  min_count: 50\n",
      "\n",
      "MATH:\n",
      "  Best coherence: 0.5651\n",
      "  Topics: 198\n",
      "  umap_n_neighbors: 30\n",
      "  umap_n_components: 5\n",
      "  hdbscan_min_cluster_size: 50\n",
      "  hdbscan_cluster_selection_method: eom\n",
      "  min_count: 50\n",
      "\n",
      "PHYSICS:\n",
      "  Best coherence: 0.6623\n",
      "  Topics: 207\n",
      "  umap_n_neighbors: 30\n",
      "  umap_n_components: 30\n",
      "  hdbscan_min_cluster_size: 50\n",
      "  hdbscan_cluster_selection_method: eom\n",
      "  min_count: 50\n",
      "\n",
      "==========================================================================================\n",
      "Top 5 per Subject\n",
      "==========================================================================================\n",
      "\n",
      "CS:\n",
      " umap_n_neighbors  umap_n_components  hdbscan_min_cluster_size hdbscan_cluster_selection_method  min_count  n_topics  coherence\n",
      "               30                 10                        50                              eom         50       248   0.593423\n",
      "               15                 10                        50                              eom         50       300   0.587972\n",
      "               15                 30                        50                              eom         50       303   0.587718\n",
      "               30                  5                        50                              eom         50       255   0.583218\n",
      "               30                 30                        50                              eom         50       268   0.581675\n",
      "\n",
      "MATH:\n",
      " umap_n_neighbors  umap_n_components  hdbscan_min_cluster_size hdbscan_cluster_selection_method  min_count  n_topics  coherence\n",
      "               30                  5                        50                              eom         50       198   0.565063\n",
      "               30                 30                        30                              eom         50       305   0.556669\n",
      "               30                 10                        15                              eom         50       546   0.555746\n",
      "               30                 30                        15                              eom         50       547   0.555538\n",
      "               30                 10                        50                              eom         50       202   0.555503\n",
      "\n",
      "PHYSICS:\n",
      " umap_n_neighbors  umap_n_components  hdbscan_min_cluster_size hdbscan_cluster_selection_method  min_count  n_topics  coherence\n",
      "               30                 30                        50                              eom         50       207   0.662324\n",
      "               30                  5                        50                              eom         50       207   0.658320\n",
      "               30                 10                        50                              eom         50       205   0.656695\n",
      "               15                  5                        50                              eom         50       224   0.656546\n",
      "               15                 10                        50                              eom         50       231   0.654540\n"
     ]
    }
   ],
   "source": [
    "results_df = pd.read_csv(csv_path)\n",
    "valid_results = results_df.dropna(subset=[\"coherence\"])\n",
    "\n",
    "print(f\"Total runs: {len(results_df)}\")\n",
    "print(f\"Valid runs (>1 topic): {len(valid_results)}\")\n",
    "print(f\"Skipped (1 topic or error): {len(results_df) - len(valid_results)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 90)\n",
    "print(\"Best Parameters per Subject\")\n",
    "print(\"=\" * 90)\n",
    "\n",
    "best_per_subject = {}\n",
    "for subject in LIST_SUBJECT:\n",
    "    subj_results = valid_results[valid_results[\"subject\"] == subject]\n",
    "    if subj_results.empty:\n",
    "        print(f\"\\n{subject.upper()}: No valid results\")\n",
    "        continue\n",
    "\n",
    "    best_idx = subj_results[\"coherence\"].idxmax()\n",
    "    best_row = subj_results.loc[best_idx]\n",
    "    best_per_subject[subject] = best_row\n",
    "\n",
    "    print(f\"\\n{subject.upper()}:\")\n",
    "    print(f\"  Best coherence: {best_row['coherence']:.4f}\")\n",
    "    print(f\"  Topics: {int(best_row['n_topics'])}\")\n",
    "    print(f\"  umap_n_neighbors: {int(best_row['umap_n_neighbors'])}\")\n",
    "    print(f\"  umap_n_components: {int(best_row['umap_n_components'])}\")\n",
    "    print(f\"  hdbscan_min_cluster_size: {int(best_row['hdbscan_min_cluster_size'])}\")\n",
    "    print(f\"  hdbscan_cluster_selection_method: {best_row['hdbscan_cluster_selection_method']}\")\n",
    "    print(f\"  min_count: {int(best_row['min_count'])}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 90)\n",
    "print(\"Top 5 per Subject\")\n",
    "print(\"=\" * 90)\n",
    "for subject in LIST_SUBJECT:\n",
    "    subj_results = valid_results[valid_results[\"subject\"] == subject]\n",
    "    if subj_results.empty:\n",
    "        continue\n",
    "    top5 = subj_results.nlargest(5, \"coherence\")\n",
    "    print(f\"\\n{subject.upper()}:\")\n",
    "    print(top5[[\"umap_n_neighbors\", \"umap_n_components\", \"hdbscan_min_cluster_size\",\n",
    "                \"hdbscan_cluster_selection_method\", \"min_count\", \"n_topics\", \"coherence\"]].to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load-coherence-markdown",
   "metadata": {},
   "source": [
    "## Load Saved Models & Show Coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "load-coherence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CS: Topics=248 | Coherence=0.5934\n",
      "MATH: Topics=198 | Coherence=0.5651\n",
      "PHYSICS: Topics=207 | Coherence=0.6623\n"
     ]
    }
   ],
   "source": [
    "for subject in LIST_SUBJECT:\n",
    "    model_path = OUTPUT_DIR / f\"best_model_{subject}\" / \"model\"\n",
    "    if not model_path.exists():\n",
    "        print(f\"{subject.upper()}: No saved model found at {model_path}\")\n",
    "        continue\n",
    "\n",
    "    model = Top2Vec.load(str(model_path))\n",
    "    n_topics = model.get_num_topics()\n",
    "\n",
    "    coherence = calculate_coherence(\n",
    "        model,\n",
    "        all_texts_tokenized[subject],\n",
    "        all_dictionaries[subject]\n",
    "    )\n",
    "    print(f\"{subject.upper()}: Topics={n_topics} | Coherence={coherence:.4f}\")\n",
    "\n",
    "    del model\n",
    "    gc.collect()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
