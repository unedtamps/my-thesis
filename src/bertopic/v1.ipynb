{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "731bdf73",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88c344da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from typing import List, Optional, Tuple\n",
    "from umap import UMAP\n",
    "from hdbscan import HDBSCAN\n",
    "from bertopic import BERTopic\n",
    "import os\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da279334",
   "metadata": {},
   "outputs": [],
   "source": [
    "allminiLM = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "distilroberta = \"all-distilroberta-v1\"\n",
    "e5_base = \"intfloat/e5-base-v2\"\n",
    "mpnet_base = \"all-mpnet-base-v2\"\n",
    "\n",
    "ModelName = {\n",
    "    allminiLM : \"all-minilml6\",\n",
    "    distilroberta : \"distilrobertav1\",\n",
    "    e5_base : \"e5_basev2\",\n",
    "    mpnet_base : \"mpnet_basev2\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8afc8363",
   "metadata": {},
   "outputs": [],
   "source": [
    "CS = \"cs\"\n",
    "MATH = \"math\"\n",
    "STAT = \"stat\"\n",
    "SUBJECT = CS\n",
    "STRANSFORMER = mpnet_base\n",
    "EMBEDING_DIM = 768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6b219cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>submitted_date</th>\n",
       "      <th>tag_text</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fault Detection using Immune-Based Systems and Formal Language Algorithms</td>\n",
       "      <td>2000-10-03</td>\n",
       "      <td>Computational Engineering, Finance, and Science, Machine Learning</td>\n",
       "      <td>fault detection using immunebased systems and formal language algorithms. this paper describes two approaches for fault detection an immunebased mechanism and a formal language algorithm. the first one is based on the feature of immune systems in distinguish any foreign cell from the body own cell. the formal language approach assumes the system as a linguistic source capable of generating a certain language, characterised by a grammar. each algorithm has particular characteristics, which are analysed in the paper, namely in what cases they can be used with advantage. to test their practicality, both approaches were applied on the problem of fault detection in an induction motor.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Robust Classification for Imprecise Environments</td>\n",
       "      <td>2000-09-13</td>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>robust classification for imprecise environments. in realworld environments it usually is difficult to specify target operating conditions precisely, for example, target misclassification costs. this uncertainty makes building robust classification systems problematic. we show that it is possible to build a hybrid classifier that will perform at least as well as the best available classifier for any target conditions. in some cases, the performance of the hybrid actually can surpass that of the best known classifier. this robust performance extends across a wide variety of comparison frameworks, including the optimization of metrics such as accuracy, expected cost, lift, precision, recall, and workforce utilization. the hybrid also is efficient to build, to store, and to update. the hybrid is based on a method for the comparison of classifier performance that is robust to imprecise class distributions and misclassification costs. the roc convex hull rocch method combines techniques from roc analysis, decision analysis and computational geometry, and adapts them to the particulars of analyzing learned classifiers. the method is efficient and incremental, minimizes the management of classifier performance data, and allows for clear visual comparisons and sensitivity analyses. finally, we point to empirical evidence that a robust hybrid classifier indeed is needed for many realworld problems.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tagger Evaluation Given Hierarchical Tag Sets</td>\n",
       "      <td>2000-08-09</td>\n",
       "      <td>Computation and Language</td>\n",
       "      <td>tagger evaluation given hierarchical tag sets. we present methods for evaluating human and automatic taggers that extend current practice in three ways. first, we show how to evaluate taggers that assign multiple tags to each test instance, even if they do not assign probabilities. second, we show how to accommodate a common property of manually constructed gold standards that are typically used for objective evaluation, namely that there is often more than one correct answer. third, we show how to measure performance when the set of possible tags is treestructured in an isa hierarchy. to illustrate how our methods can be used to measure interannotator agreement, we show how to compute the kappa coefficient over hierarchical tag sets.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Description of GADEL</td>\n",
       "      <td>2000-03-07</td>\n",
       "      <td>Artificial Intelligence, Logic in Computer Science</td>\n",
       "      <td>description of gadel. this article describes the first implementation of the gadel system  a genetic algorithm for default logic. the goal of gadel is to compute extensions in reiters default logic. it accepts every kind of finite propositional default theories and is based on evolutionary principles of genetic algorithms. its first experimental results on certain instances of the problem show that this new approach of the problem can be successful.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The dynamics of iterated transportation simulations</td>\n",
       "      <td>2000-02-22</td>\n",
       "      <td>Adaptation and Self-Organizing Systems, Computational Engineering, Finance, and Science</td>\n",
       "      <td>the dynamics of iterated transportation simulations. iterating between a router and a traffic microsimulation is an increasibly accepted method for doing traffic assignment. this paper, after pointing out that the analytical theory of simulationbased assignment todate is insufficient for some practical cases, presents results of simulation studies from a real world study. specifically, we look into the issues of uniqueness, variability, and robustness and validation. regarding uniqueness, despite some cautionary notes from a theoretical point of view, we find no indication of metastable states for the iterations. variability however is considerable. by variability we mean the variation of the simulation of a given plan set by just changing the random seed. we show then results from three different microsimulations under the same iteration scenario in order to test for the robustness of the results under different implementations. we find the results encouraging, also when comparing to reality and with a traditional assignment result. keywords dynamic traffic assignment dta traffic microsimulation transims largescale simulations urban planning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159242</th>\n",
       "      <td>Mining the Long Tail: A Comparative Study of Data-Centric Criticality Metrics for Robust Offline Reinforcement Learning in Autonomous Motion Planning</td>\n",
       "      <td>2025-09-16</td>\n",
       "      <td>Robotics, Artificial Intelligence, Machine Learning</td>\n",
       "      <td>mining the long tail a comparative study of datacentric criticality metrics for robust offline reinforcement learning in autonomous motion planning. offline reinforcement learning rl presents a promising paradigm for training autonomous vehicle av planning policies from largescale, realworld driving logs. however, the extreme data imbalance in these logs, where mundane scenarios vastly outnumber rare longtail events, leads to brittle and unsafe policies when using standard uniform data sampling. in this work, we address this challenge through a systematic, largescale comparative study of data curation strategies designed to focus the learning process on informationrich samples. we investigate six distinct criticality weighting schemes which are categorized into three families heuristicbased, uncertaintybased, and behaviorbased. these are evaluated at two temporal scales, the individual timestep and the complete scenario. we train seven goalconditioned conservative qlearning cql agents with a stateoftheart, attentionbased architecture and evaluate them in the highfidelity waymax simulator. our results demonstrate that all data curation methods significantly outperform the baseline. notably, datadriven curation using model uncertainty as a signal achieves the most significant safety improvements, reducing the collision rate by nearly threefold from 16.0 to 5.5. furthermore, we identify a clear tradeoff where timesteplevel weighting excels at reactive safety while scenariolevel weighting improves longhorizon planning. our work provides a comprehensive framework for data curation in offline rl and underscores that intelligent, nonuniform sampling is a critical component for building safe and reliable autonomous agents.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159243</th>\n",
       "      <td>Adaptive Data-Knowledge Alignment in Genetic Perturbation Prediction</td>\n",
       "      <td>2025-10-01</td>\n",
       "      <td>Molecular Networks, Artificial Intelligence, Machine Learning</td>\n",
       "      <td>adaptive dataknowledge alignment in genetic perturbation prediction. the transcriptional response to genetic perturbation reveals fundamental insights into complex cellular systems. while current approaches have made progress in predicting genetic perturbation responses, they provide limited biological understanding and cannot systematically refine existing knowledge. overcoming these limitations requires an endtoend integration of datadriven learning and existing knowledge. however, this integration is challenging due to inconsistencies between data and knowledge bases, such as noise, misannotation, and incompleteness. to address this challenge, we propose aligned adaptive alignment for inconsistent genetic knowledge and data, a neurosymbolic framework based on the abductive learning abl paradigm. this endtoend framework aligns neural and symbolic components and performs systematic knowledge refinement. we introduce a balanced consistency metric to evaluate the predictions consistency against both data and knowledge. our results show that aligned outperforms stateoftheart methods by achieving the highest balanced consistency, while also rediscovering biologically meaningful knowledge. our work advances beyond existing methods to enable both the transparency and the evolution of mechanistic biological understanding.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159244</th>\n",
       "      <td>Sobolev Training of End-to-End Optimization Proxies</td>\n",
       "      <td>2025-05-16</td>\n",
       "      <td>Machine Learning, Optimization and Control</td>\n",
       "      <td>sobolev training of endtoend optimization proxies. optimization proxies  machine learning models trained to approximate the solution mapping of parametric optimization problems in a single forward pass  offer dramatic reductions in inference time compared to traditional iterative solvers. this work investigates the integration of solver sensitivities into such end to end proxies via a sobolev training paradigm and does so in two distinct settings i fully supervised proxies, where exact solver outputs and sensitivities are available, and ii self supervised proxies that rely only on the objective and constraint structure of the underlying optimization problem. by augmenting the standard training loss with directional derivative information extracted from the solver, the proxy aligns both its predicted solutions and local derivatives with those of the optimizer. under lipschitz continuity assumptions on the true solution mapping, matching first order sensitivities is shown to yield uniform approximation error proportional to the training set covering radius. empirically, different impacts are observed in each studied setting. on three large alternating current optimal power flow benchmarks, supervised sobolev training cuts mean squared error by up to 56 percent and the median worst case constraint violation by up to 400 percent while keeping the optimality gap below 0.22 percent. for a mean variance portfolio task trained without labeled solutions, self supervised sobolev training halves the average optimality gap in the medium risk region standard deviation above 10 percent of budget and matches the baseline elsewhere. together, these results highlight sobolev training whether supervised or self supervised as a path to fast reliable surrogates for safety critical large scale optimization workloads.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159245</th>\n",
       "      <td>Beyond Unimodal Boundaries: Generative Recommendation with Multimodal Semantics</td>\n",
       "      <td>2025-03-30</td>\n",
       "      <td>Information Retrieval, Artificial Intelligence, Computation and Language, Computer Vision and Pattern Recognition</td>\n",
       "      <td>beyond unimodal boundaries generative recommendation with multimodal semantics. generative recommendation gr has become a powerful paradigm in recommendation systems that implicitly links modality and semantics to item representation, in contrast to previous methods that relied on nonsemantic item identifiers in autoregressive models. however, previous research has predominantly treated modalities in isolation, typically assuming item content is unimodal usually text. we argue that this is a significant limitation given the rich, multimodal nature of realworld data and the potential sensitivity of gr models to modality choices and usage. our work aims to explore the critical problem of multimodal generative recommendation mgr, highlighting the importance of modality choices in gr nframeworks. we reveal that gr models are particularly sensitive to different modalities and examine the challenges in achieving effective gr when multiple modalities are available. by evaluating design strategies for effectively leveraging multiple modalities, we identify key challenges and introduce mgrlf, an enhanced late fusion framework that employs contrastive modality alignment and special tokens to denote different modalities, achieving a performance improvement of over 20 compared to singlemodality alternatives.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159246</th>\n",
       "      <td>Clinicians' Voice: Fundamental Considerations for XAI in Healthcare</td>\n",
       "      <td>2025-08-05</td>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>clinicians voice fundamental considerations for xai in healthcare. explainable ai xai holds the promise of advancing the implementation and adoption of aibased tools in practice, especially in highstakes environments like healthcare. however, most of the current research lacks input from end users, and therefore their practical value is limited. to address this, we conducted semistructured interviews with clinicians to discuss their thoughts, hopes, and concerns. clinicians from our sample generally think positively about developing aibased tools for clinical practice, but they have concerns about how these will fit into their workflow and how it will impact clinicianpatient relations. we further identify training of clinicians on ai as a crucial factor for the success of ai in healthcare and highlight aspects clinicians are looking for in xaibased tools. in contrast to other studies, we take on a holistic and exploratory perspective to identify general requirements for xai products for healthcare before moving on to testing specific tools.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159247 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                        title  \\\n",
       "0                                                                                   Fault Detection using Immune-Based Systems and Formal Language Algorithms   \n",
       "1                                                                                                            Robust Classification for Imprecise Environments   \n",
       "2                                                                                                               Tagger Evaluation Given Hierarchical Tag Sets   \n",
       "3                                                                                                                                        Description of GADEL   \n",
       "4                                                                                                         The dynamics of iterated transportation simulations   \n",
       "...                                                                                                                                                       ...   \n",
       "159242  Mining the Long Tail: A Comparative Study of Data-Centric Criticality Metrics for Robust Offline Reinforcement Learning in Autonomous Motion Planning   \n",
       "159243                                                                                   Adaptive Data-Knowledge Alignment in Genetic Perturbation Prediction   \n",
       "159244                                                                                                    Sobolev Training of End-to-End Optimization Proxies   \n",
       "159245                                                                        Beyond Unimodal Boundaries: Generative Recommendation with Multimodal Semantics   \n",
       "159246                                                                                    Clinicians' Voice: Fundamental Considerations for XAI in Healthcare   \n",
       "\n",
       "       submitted_date  \\\n",
       "0          2000-10-03   \n",
       "1          2000-09-13   \n",
       "2          2000-08-09   \n",
       "3          2000-03-07   \n",
       "4          2000-02-22   \n",
       "...               ...   \n",
       "159242     2025-09-16   \n",
       "159243     2025-10-01   \n",
       "159244     2025-05-16   \n",
       "159245     2025-03-30   \n",
       "159246     2025-08-05   \n",
       "\n",
       "                                                                                                                 tag_text  \\\n",
       "0                                                       Computational Engineering, Finance, and Science, Machine Learning   \n",
       "1                                                                                                        Machine Learning   \n",
       "2                                                                                                Computation and Language   \n",
       "3                                                                      Artificial Intelligence, Logic in Computer Science   \n",
       "4                                 Adaptation and Self-Organizing Systems, Computational Engineering, Finance, and Science   \n",
       "...                                                                                                                   ...   \n",
       "159242                                                                Robotics, Artificial Intelligence, Machine Learning   \n",
       "159243                                                      Molecular Networks, Artificial Intelligence, Machine Learning   \n",
       "159244                                                                         Machine Learning, Optimization and Control   \n",
       "159245  Information Retrieval, Artificial Intelligence, Computation and Language, Computer Vision and Pattern Recognition   \n",
       "159246                                                                                                   Machine Learning   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       text  \n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          fault detection using immunebased systems and formal language algorithms. this paper describes two approaches for fault detection an immunebased mechanism and a formal language algorithm. the first one is based on the feature of immune systems in distinguish any foreign cell from the body own cell. the formal language approach assumes the system as a linguistic source capable of generating a certain language, characterised by a grammar. each algorithm has particular characteristics, which are analysed in the paper, namely in what cases they can be used with advantage. to test their practicality, both approaches were applied on the problem of fault detection in an induction motor.  \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                      robust classification for imprecise environments. in realworld environments it usually is difficult to specify target operating conditions precisely, for example, target misclassification costs. this uncertainty makes building robust classification systems problematic. we show that it is possible to build a hybrid classifier that will perform at least as well as the best available classifier for any target conditions. in some cases, the performance of the hybrid actually can surpass that of the best known classifier. this robust performance extends across a wide variety of comparison frameworks, including the optimization of metrics such as accuracy, expected cost, lift, precision, recall, and workforce utilization. the hybrid also is efficient to build, to store, and to update. the hybrid is based on a method for the comparison of classifier performance that is robust to imprecise class distributions and misclassification costs. the roc convex hull rocch method combines techniques from roc analysis, decision analysis and computational geometry, and adapts them to the particulars of analyzing learned classifiers. the method is efficient and incremental, minimizes the management of classifier performance data, and allows for clear visual comparisons and sensitivity analyses. finally, we point to empirical evidence that a robust hybrid classifier indeed is needed for many realworld problems.  \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  tagger evaluation given hierarchical tag sets. we present methods for evaluating human and automatic taggers that extend current practice in three ways. first, we show how to evaluate taggers that assign multiple tags to each test instance, even if they do not assign probabilities. second, we show how to accommodate a common property of manually constructed gold standards that are typically used for objective evaluation, namely that there is often more than one correct answer. third, we show how to measure performance when the set of possible tags is treestructured in an isa hierarchy. to illustrate how our methods can be used to measure interannotator agreement, we show how to compute the kappa coefficient over hierarchical tag sets.  \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     description of gadel. this article describes the first implementation of the gadel system  a genetic algorithm for default logic. the goal of gadel is to compute extensions in reiters default logic. it accepts every kind of finite propositional default theories and is based on evolutionary principles of genetic algorithms. its first experimental results on certain instances of the problem show that this new approach of the problem can be successful.  \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  the dynamics of iterated transportation simulations. iterating between a router and a traffic microsimulation is an increasibly accepted method for doing traffic assignment. this paper, after pointing out that the analytical theory of simulationbased assignment todate is insufficient for some practical cases, presents results of simulation studies from a real world study. specifically, we look into the issues of uniqueness, variability, and robustness and validation. regarding uniqueness, despite some cautionary notes from a theoretical point of view, we find no indication of metastable states for the iterations. variability however is considerable. by variability we mean the variation of the simulation of a given plan set by just changing the random seed. we show then results from three different microsimulations under the same iteration scenario in order to test for the robustness of the results under different implementations. we find the results encouraging, also when comparing to reality and with a traditional assignment result. keywords dynamic traffic assignment dta traffic microsimulation transims largescale simulations urban planning  \n",
       "...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     ...  \n",
       "159242                                                                                     mining the long tail a comparative study of datacentric criticality metrics for robust offline reinforcement learning in autonomous motion planning. offline reinforcement learning rl presents a promising paradigm for training autonomous vehicle av planning policies from largescale, realworld driving logs. however, the extreme data imbalance in these logs, where mundane scenarios vastly outnumber rare longtail events, leads to brittle and unsafe policies when using standard uniform data sampling. in this work, we address this challenge through a systematic, largescale comparative study of data curation strategies designed to focus the learning process on informationrich samples. we investigate six distinct criticality weighting schemes which are categorized into three families heuristicbased, uncertaintybased, and behaviorbased. these are evaluated at two temporal scales, the individual timestep and the complete scenario. we train seven goalconditioned conservative qlearning cql agents with a stateoftheart, attentionbased architecture and evaluate them in the highfidelity waymax simulator. our results demonstrate that all data curation methods significantly outperform the baseline. notably, datadriven curation using model uncertainty as a signal achieves the most significant safety improvements, reducing the collision rate by nearly threefold from 16.0 to 5.5. furthermore, we identify a clear tradeoff where timesteplevel weighting excels at reactive safety while scenariolevel weighting improves longhorizon planning. our work provides a comprehensive framework for data curation in offline rl and underscores that intelligent, nonuniform sampling is a critical component for building safe and reliable autonomous agents.  \n",
       "159243                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            adaptive dataknowledge alignment in genetic perturbation prediction. the transcriptional response to genetic perturbation reveals fundamental insights into complex cellular systems. while current approaches have made progress in predicting genetic perturbation responses, they provide limited biological understanding and cannot systematically refine existing knowledge. overcoming these limitations requires an endtoend integration of datadriven learning and existing knowledge. however, this integration is challenging due to inconsistencies between data and knowledge bases, such as noise, misannotation, and incompleteness. to address this challenge, we propose aligned adaptive alignment for inconsistent genetic knowledge and data, a neurosymbolic framework based on the abductive learning abl paradigm. this endtoend framework aligns neural and symbolic components and performs systematic knowledge refinement. we introduce a balanced consistency metric to evaluate the predictions consistency against both data and knowledge. our results show that aligned outperforms stateoftheart methods by achieving the highest balanced consistency, while also rediscovering biologically meaningful knowledge. our work advances beyond existing methods to enable both the transparency and the evolution of mechanistic biological understanding.  \n",
       "159244  sobolev training of endtoend optimization proxies. optimization proxies  machine learning models trained to approximate the solution mapping of parametric optimization problems in a single forward pass  offer dramatic reductions in inference time compared to traditional iterative solvers. this work investigates the integration of solver sensitivities into such end to end proxies via a sobolev training paradigm and does so in two distinct settings i fully supervised proxies, where exact solver outputs and sensitivities are available, and ii self supervised proxies that rely only on the objective and constraint structure of the underlying optimization problem. by augmenting the standard training loss with directional derivative information extracted from the solver, the proxy aligns both its predicted solutions and local derivatives with those of the optimizer. under lipschitz continuity assumptions on the true solution mapping, matching first order sensitivities is shown to yield uniform approximation error proportional to the training set covering radius. empirically, different impacts are observed in each studied setting. on three large alternating current optimal power flow benchmarks, supervised sobolev training cuts mean squared error by up to 56 percent and the median worst case constraint violation by up to 400 percent while keeping the optimality gap below 0.22 percent. for a mean variance portfolio task trained without labeled solutions, self supervised sobolev training halves the average optimality gap in the medium risk region standard deviation above 10 percent of budget and matches the baseline elsewhere. together, these results highlight sobolev training whether supervised or self supervised as a path to fast reliable surrogates for safety critical large scale optimization workloads.  \n",
       "159245                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                beyond unimodal boundaries generative recommendation with multimodal semantics. generative recommendation gr has become a powerful paradigm in recommendation systems that implicitly links modality and semantics to item representation, in contrast to previous methods that relied on nonsemantic item identifiers in autoregressive models. however, previous research has predominantly treated modalities in isolation, typically assuming item content is unimodal usually text. we argue that this is a significant limitation given the rich, multimodal nature of realworld data and the potential sensitivity of gr models to modality choices and usage. our work aims to explore the critical problem of multimodal generative recommendation mgr, highlighting the importance of modality choices in gr nframeworks. we reveal that gr models are particularly sensitive to different modalities and examine the challenges in achieving effective gr when multiple modalities are available. by evaluating design strategies for effectively leveraging multiple modalities, we identify key challenges and introduce mgrlf, an enhanced late fusion framework that employs contrastive modality alignment and special tokens to denote different modalities, achieving a performance improvement of over 20 compared to singlemodality alternatives.  \n",
       "159246                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     clinicians voice fundamental considerations for xai in healthcare. explainable ai xai holds the promise of advancing the implementation and adoption of aibased tools in practice, especially in highstakes environments like healthcare. however, most of the current research lacks input from end users, and therefore their practical value is limited. to address this, we conducted semistructured interviews with clinicians to discuss their thoughts, hopes, and concerns. clinicians from our sample generally think positively about developing aibased tools for clinical practice, but they have concerns about how these will fit into their workflow and how it will impact clinicianpatient relations. we further identify training of clinicians on ai as a crucial factor for the success of ai in healthcare and highlight aspects clinicians are looking for in xaibased tools. in contrast to other studies, we take on a holistic and exploratory perspective to identify general requirements for xai products for healthcare before moving on to testing specific tools.  \n",
       "\n",
       "[159247 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(f\"dataset/arxiv_{SUBJECT}_emb.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "607db082",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"submitted_date\"] = pd.to_datetime(data[\"submitted_date\"], errors=\"coerce\")\n",
    "data[\"year\"] = data[\"submitted_date\"].dt.year\n",
    "idx = data.index.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06616c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_mmap_embeddings(\n",
    "    texts: List[str],\n",
    "    embedding_model: SentenceTransformer,\n",
    "    mmap_path: str,\n",
    "    batch_size: int = 1024\n",
    ") -> np.memmap:\n",
    "    N = len(texts)\n",
    "    emb_dim = embedding_model.get_sentence_embedding_dimension()\n",
    "    \n",
    "    if N == 0:\n",
    "        print(\"Error: List teks kosong.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Total dokumen: {N}\")\n",
    "    print(f\"Dimensi embedding: {emb_dim}\")\n",
    "    print(f\"Ukuran batch: {batch_size}\")\n",
    "    print(f\"Menyimpan ke: {mmap_path}\")\n",
    "\n",
    "    embs = np.memmap(\n",
    "        mmap_path, \n",
    "        dtype=\"float32\", \n",
    "        mode=\"w+\",\n",
    "        shape=(N, emb_dim)\n",
    "    )\n",
    "\n",
    "    for i in tqdm(range(0, N, batch_size)):\n",
    "        batch_texts = texts[i:i + batch_size]\n",
    "        \n",
    "        batch_embeddings = embedding_model.encode(\n",
    "            batch_texts, \n",
    "            show_progress_bar=False, \n",
    "            convert_to_numpy=True\n",
    "        )\n",
    "        \n",
    "        embs[i:i + len(batch_texts)] = batch_embeddings\n",
    "\n",
    "    embs.flush()\n",
    "    return embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d307eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mmap_embeddings(\n",
    "    mmap_path: str,\n",
    "    num_documents: int,\n",
    "    embedding_dim: int,\n",
    "    dtype: str = \"float32\"\n",
    ") -> Optional[np.memmap]:\n",
    "    \n",
    "    try:\n",
    "        embs = np.memmap(\n",
    "            mmap_path,\n",
    "            dtype=dtype,\n",
    "            mode=\"r\",\n",
    "            shape=(num_documents, embedding_dim)\n",
    "        )\n",
    "        print(\"Embeddings berhasil dimuat.\")\n",
    "        return embs\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File tidak ditemukan di path: {mmap_path}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error saat memuat file mmap: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a998009b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_bertopic_model(\n",
    "    documents: List[str],\n",
    "    embeddings: np.ndarray,\n",
    "    n_neighbors: int = 20,\n",
    "    n_components: int = 5,\n",
    "    min_dist: float = 0.0,\n",
    "    min_cluster_size: int = 200,\n",
    "    min_samples: int = 10,\n",
    "    random_state: int = 42\n",
    ") -> Tuple[BERTopic, List[int], Optional[np.ndarray]]:\n",
    "\n",
    "    print(f\"n_neighbors={n_neighbors}, min_dist={min_dist}, n_components={n_components}\")\n",
    "    umap_model = UMAP(\n",
    "        n_neighbors=n_neighbors,\n",
    "        n_components=n_components,\n",
    "        metric=\"cosine\",\n",
    "        random_state=random_state,\n",
    "        min_dist=min_dist,\n",
    "        verbose=True\n",
    "    )\n",
    "\n",
    "    print(f\"min_cluster_size={min_cluster_size}, min_samples={min_samples}\")\n",
    "    hdbscan_model = HDBSCAN(\n",
    "        min_cluster_size=min_cluster_size,\n",
    "        min_samples=min_samples,\n",
    "        metric=\"euclidean\",\n",
    "        cluster_selection_method=\"eom\",\n",
    "        prediction_data=True,\n",
    "        gen_min_span_tree=True\n",
    "    )\n",
    "\n",
    "    topic_model = BERTopic(\n",
    "        umap_model=umap_model,\n",
    "        hdbscan_model=hdbscan_model,\n",
    "        calculate_probabilities=False, # Set False agar lebih cepat\n",
    "        verbose=True\n",
    "    )\n",
    "\n",
    "    topics, probs = topic_model.fit_transform(documents, embeddings=embeddings)\n",
    "    print(f\"total topics found: {len(topic_model.get_topic_info()) - 1}\")\n",
    "    return topic_model, topics, probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45792572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start model embedings\n",
      "Total dokumen: 159247\n",
      "Dimensi embedding: 768\n",
      "Ukuran batch: 1024\n",
      "Menyimpan ke: model_results/bertopic/model_embedings/mpnet_basev2_cs.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [33:03<00:00, 12.72s/it]\n"
     ]
    }
   ],
   "source": [
    "emb_path = f\"model_results/bertopic/model_embedings/{ModelName[STRANSFORMER]}_{SUBJECT}.npy\"\n",
    "if os.path.exists(emb_path):\n",
    "    print(\"Embeddings exist\")\n",
    "    texts = data[\"text\"].tolist()\n",
    "    embs = load_mmap_embeddings(mmap_path=emb_path,num_documents=len(texts),embedding_dim=EMBEDING_DIM )\n",
    "else:\n",
    "    print(\"Start model embedings\")\n",
    "    embedding_model = SentenceTransformer(STRANSFORMER)\n",
    "    embs = generate_mmap_embeddings(texts=data['text'].tolist(), embedding_model=embedding_model,mmap_path=emb_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "713de1bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-19 19:30:19,265 - BERTopic - Dimensionality - Fitting the dimensionality reduction algorithm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_neighbors=20, min_dist=0.0, n_components=5\n",
      "min_cluster_size=200, min_samples=10\n",
      "UMAP(angular_rp_forest=True, metric='cosine', min_dist=0.0, n_components=5, n_jobs=1, n_neighbors=20, random_state=42, verbose=True)\n",
      "Wed Nov 19 19:30:19 2025 Construct fuzzy simplicial set\n",
      "Wed Nov 19 19:30:19 2025 Finding Nearest Neighbors\n",
      "Wed Nov 19 19:30:19 2025 Building RP forest with 25 trees\n",
      "Wed Nov 19 19:30:33 2025 NN descent for 17 iterations\n",
      "\t 1  /  17\n",
      "\t 2  /  17\n",
      "\t 3  /  17\n",
      "\t 4  /  17\n",
      "\tStopping threshold met -- exiting after 4 iterations\n",
      "Wed Nov 19 19:31:03 2025 Finished Nearest Neighbor Search\n",
      "Wed Nov 19 19:31:06 2025 Construct embedding\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3faa013741104cb18e410d4f2365f9b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs completed:   0%|            0/200 [00:00]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tcompleted  0  /  200 epochs\n",
      "\tcompleted  20  /  200 epochs\n",
      "\tcompleted  40  /  200 epochs\n",
      "\tcompleted  60  /  200 epochs\n",
      "\tcompleted  80  /  200 epochs\n",
      "\tcompleted  100  /  200 epochs\n",
      "\tcompleted  120  /  200 epochs\n",
      "\tcompleted  140  /  200 epochs\n",
      "\tcompleted  160  /  200 epochs\n",
      "\tcompleted  180  /  200 epochs\n",
      "Wed Nov 19 19:32:36 2025 Finished embedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-19 19:32:37,853 - BERTopic - Dimensionality - Completed ✓\n",
      "2025-11-19 19:32:37,855 - BERTopic - Cluster - Start clustering the reduced embeddings\n",
      "2025-11-19 19:32:42,479 - BERTopic - Cluster - Completed ✓\n",
      "2025-11-19 19:32:42,495 - BERTopic - Representation - Fine-tuning topics using representation models.\n",
      "2025-11-19 19:32:53,934 - BERTopic - Representation - Completed ✓\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total topics found: 143\n"
     ]
    }
   ],
   "source": [
    "sample_embeddings = embs[idx]\n",
    "topic_model, topics , probs = train_bertopic_model(data['text'].tolist(),sample_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "002035f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-19 19:32:57,518 - BERTopic - WARNING: When you use `pickle` to save/load a BERTopic model,please make sure that the environments in which you saveand load the model are **exactly** the same. The version of BERTopic,its dependencies, and python need to remain the same.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Nov 19 19:33:03 2025 Worst tree score: 0.41104071\n",
      "Wed Nov 19 19:33:03 2025 Mean tree score: 0.42233562\n",
      "Wed Nov 19 19:33:03 2025 Best tree score: 0.43516675\n",
      "Wed Nov 19 19:33:06 2025 Forward diversification reduced edges from 3184940 to 1112790\n",
      "Wed Nov 19 19:33:08 2025 Reverse diversification reduced edges from 1112790 to 1112790\n",
      "Wed Nov 19 19:33:10 2025 Degree pruning reduced edges from 1299792 to 1299583\n",
      "Wed Nov 19 19:33:10 2025 Resorting data and graph based on tree order\n",
      "Wed Nov 19 19:33:10 2025 Building and compiling search function\n"
     ]
    }
   ],
   "source": [
    "topic_model.save(f\"model_results/bertopic/{ModelName[STRANSFORMER]}_{SUBJECT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2fc753",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0dbc7fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Nov 19 20:45:21 2025 Building and compiling search function\n"
     ]
    }
   ],
   "source": [
    "loaded_model = BERTopic.load(f\"model_results/bertopic/{ModelName[STRANSFORMER]}_{SUBJECT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc4a91be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26it [01:17,  2.99s/it]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "docs = data['text'].tolist()\n",
    "timestamps = pd.to_datetime(data[\"submitted_date\"]).dt.year\n",
    "topics_over_time = loaded_model.topics_over_time(\n",
    "    docs,\n",
    "    timestamps,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "474ecf4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "customdata": [
          [
           "neurofuzzy, robot, ccgolog, actuator, ripple",
           8,
           320
          ],
          [
           "policy, observable, planning, actions, partially",
           8,
           314
          ],
          [
           "motion, topological, planning, policy, instabilities",
           11,
           432
          ],
          [
           "controller, gotools, metareasoning, genetic, system",
           8,
           568
          ],
          [
           "robot, planning, robots, control, eap",
           25,
           580
          ],
          [
           "robot, robots, control, multivehicle, optimal",
           11,
           654
          ],
          [
           "robot, robots, control, opening, chess",
           18,
           644
          ],
          [
           "orthoglide, workspace, kinematic, parallel, manipulators",
           36,
           650
          ],
          [
           "telerobotics, control, helicopter, assemblymode, robot",
           17,
           600
          ],
          [
           "robots, stiffness, robot, manipulator, policy",
           16,
           651
          ],
          [
           "planning, conformant, robot, agents, clfs",
           16,
           854
          ],
          [
           "planning, control, search, reinforcement, robot",
           47,
           1077
          ],
          [
           "planning, robot, robots, policy, reinforcement",
           34,
           1457
          ],
          [
           "control, planning, reinforcement, robot, policy",
           47,
           1743
          ],
          [
           "planning, robots, robot, control, robotic",
           72,
           1980
          ],
          [
           "robots, robot, control, planning, policy",
           69,
           2156
          ],
          [
           "robot, robots, control, reinforcement, planning",
           135,
           2808
          ],
          [
           "robot, reinforcement, robots, control, policy",
           251,
           3726
          ],
          [
           "robot, reinforcement, robots, policy, control",
           345,
           5178
          ],
          [
           "reinforcement, robot, policy, control, learning",
           561,
           6807
          ],
          [
           "reinforcement, robot, policy, control, learning",
           724,
           8980
          ],
          [
           "robot, reinforcement, control, policy, robots",
           862,
           10435
          ],
          [
           "robot, reinforcement, policy, control, robots",
           1018,
           11173
          ],
          [
           "robot, reinforcement, control, robots, policy",
           1206,
           13355
          ],
          [
           "robot, reinforcement, control, robots, policy",
           1538,
           17664
          ],
          [
           "robot, policy, control, reinforcement, robots",
           1765,
           19610
          ]
         ],
         "hovertemplate": "Topic=0<br>Timestamp=%{x}<br>Percentage=%{y}<br>Words=%{customdata[0]}<br>Frequency=%{customdata[1]}<br>Total=%{customdata[2]}<extra></extra>",
         "legendgroup": "0",
         "line": {
          "color": "#636efa",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "0",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": {
          "bdata": "0AcAANEHAADSBwAA0wcAANQHAADVBwAA1gcAANcHAADYBwAA2QcAANoHAADbBwAA3AcAAN0HAADeBwAA3wcAAOAHAADhBwAA4gcAAOMHAADkBwAA5QcAAOYHAADnBwAA6AcAAOkHAAA=",
          "dtype": "i4"
         },
         "xaxis": "x",
         "y": {
          "bdata": "mpmZmZmZmT8CS3r50xaaPy+hvYT2Epo/C5sDiVbYjD98GmG5pxGmP5ITYVwmOZE/gU8OlwGfnD+Dko5PX1usPwOdNtBpA50/dKtkAN0qmT/6HWrtXC+TPzQUX7DyV6Y/eEOABkvllz9WO9S1tpybP54S5ClBnqI/vK+KVMpioD/ZiZ3YiZ2oPwqsBDLMPrE/kIcpDIkOsT/Dy5r0KBm1PzTYuK+/o7Q/YniH+rQltT+gCSwmJlO3P48vbUAdHrc/xc8o8TNKtj8sYpD+kgq3Pw==",
          "dtype": "f8"
         },
         "yaxis": "y"
        },
        {
         "customdata": [
          [
           "logic, semantics, programs, programming, revision",
           137,
           320
          ],
          [
           "logic, programs, programming, semantics, program",
           78,
           314
          ],
          [
           "logic, programs, semantics, programming, program",
           135,
           432
          ],
          [
           "logic, programs, semantics, program, of",
           137,
           568
          ],
          [
           "logic, programs, constraint, of, rules",
           123,
           580
          ],
          [
           "logic, semantics, programs, programming, of",
           107,
           654
          ],
          [
           "logic, automata, of, semantics, is",
           126,
           644
          ],
          [
           "logic, of, programs, type, automata",
           92,
           650
          ],
          [
           "logic, automata, of, languages, semantics",
           88,
           600
          ],
          [
           "logic, automata, of, is, proof",
           91,
           651
          ],
          [
           "logic, semantics, of, programs, is",
           124,
           854
          ],
          [
           "logic, semantics, programs, of, is",
           150,
           1077
          ],
          [
           "logic, of, semantics, automata, program",
           161,
           1457
          ],
          [
           "logic, of, semantics, theory, proof",
           226,
           1743
          ],
          [
           "logic, semantics, automata, of, programs",
           239,
           1980
          ],
          [
           "logic, automata, of, proof, is",
           222,
           2156
          ],
          [
           "logic, automata, of, semantics, is",
           210,
           2808
          ],
          [
           "logic, of, semantics, programs, theory",
           252,
           3726
          ],
          [
           "logic, proof, semantics, of, theory",
           262,
           5178
          ],
          [
           "logic, programs, of, semantics, automata",
           272,
           6807
          ],
          [
           "logic, automata, semantics, programs, of",
           271,
           8980
          ],
          [
           "logic, semantics, of, programs, automata",
           296,
           10435
          ],
          [
           "logic, proof, of, semantics, theory",
           271,
           11173
          ],
          [
           "logic, semantics, proof, of, programs",
           291,
           13355
          ],
          [
           "logic, proof, of, semantics, automata",
           337,
           17664
          ],
          [
           "logic, proof, automata, semantics, of",
           381,
           19610
          ]
         ],
         "hovertemplate": "Topic=1<br>Timestamp=%{x}<br>Percentage=%{y}<br>Words=%{customdata[0]}<br>Frequency=%{customdata[1]}<br>Total=%{customdata[2]}<extra></extra>",
         "legendgroup": "1",
         "line": {
          "color": "#EF553B",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "1",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": {
          "bdata": "0AcAANEHAADSBwAA0wcAANQHAADVBwAA1gcAANcHAADYBwAA2QcAANoHAADbBwAA3AcAAN0HAADeBwAA3wcAAOAHAADhBwAA4gcAAOMHAADkBwAA5QcAAOYHAADnBwAA6AcAAOkHAAA=",
          "dtype": "i4"
         },
         "xaxis": "x",
         "y": {
          "bdata": "ZmZmZmZm2z9qCw1Y0svPPwAAAAAAANQ/8tulnozfzj83UbJrEyXLPxJPDRkg8cQ/kYUsZCELyT9FiLer7h3CP8aSXyz5xcI/5JFHHnnkwT8Kzf4F4pXCP4xkFc7J08E//m3uo8tJvD+PLs2Fv5jAPzw0FZmo5r4/I5WyGCRcuj9TMiVTMiWzP2o27O9iULE/LECjMRLoqT+mAzkMfXWkP2f+tfQG554/hs/nHf8LnT97h5vMRtaYP2n4o8ICUJY/+RklfkaJkz8ZmrrpKOWTPw==",
          "dtype": "f8"
         },
         "yaxis": "y"
        },
        {
         "customdata": [
          [
           "speech, sound, music, prosodic, word",
           9,
           320
          ],
          [
           "phonotactic, resonances, multisyllable, speech, sourcefilter",
           6,
           314
          ],
          [
           "phonology, speech, speechdriven, recognition, retrieval",
           8,
           432
          ],
          [
           "speech, vocabulary, recognition, lecture, cepstral",
           8,
           568
          ],
          [
           "lecture, fst, speech, simons, compiler",
           3,
           580
          ],
          [
           "music, speech, articulatory, filter, wiener",
           4,
           654
          ],
          [
           "speech, bss, voiced, kl2, selfconsistent",
           7,
           644
          ],
          [
           "speech, easyvoice, recognition, audio, cmu",
           5,
           650
          ],
          [
           "notes, raga, vadisamvadi, rageshree, vadi",
           2,
           600
          ],
          [
           "instruments, romanian, speech, instrumentality, disorders",
           2,
           651
          ],
          [
           "cry, sift, infants, frequency, fundamental",
           3,
           854
          ],
          [
           "speech, pronunciations, song, pba, bpsk",
           6,
           1077
          ],
          [
           "speech, windowing, audio, multichannel, signal",
           7,
           1457
          ],
          [
           "speech, audio, music, speaker, recognition",
           24,
           1743
          ],
          [
           "speech, music, audio, sound, binaural",
           28,
           1980
          ],
          [
           "speech, speaker, music, audio, acoustic",
           28,
           2156
          ],
          [
           "speech, acoustic, audio, music, recognition",
           70,
           2808
          ],
          [
           "speech, music, audio, speaker, recognition",
           107,
           3726
          ],
          [
           "speech, audio, music, acoustic, speaker",
           191,
           5178
          ],
          [
           "speech, speaker, audio, music, asr",
           217,
           6807
          ],
          [
           "speech, audio, speaker, music, asr",
           382,
           8980
          ],
          [
           "speech, audio, speaker, music, asr",
           427,
           10435
          ],
          [
           "speech, audio, speaker, asr, music",
           509,
           11173
          ],
          [
           "speech, audio, asr, music, speaker",
           541,
           13355
          ],
          [
           "speech, audio, music, asr, speaker",
           590,
           17664
          ],
          [
           "speech, audio, music, asr, speaker",
           637,
           19610
          ]
         ],
         "hovertemplate": "Topic=3<br>Timestamp=%{x}<br>Percentage=%{y}<br>Words=%{customdata[0]}<br>Frequency=%{customdata[1]}<br>Total=%{customdata[2]}<extra></extra>",
         "legendgroup": "3",
         "line": {
          "color": "#00cc96",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "3",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": {
          "bdata": "0AcAANEHAADSBwAA0wcAANQHAADVBwAA1gcAANcHAADYBwAA2QcAANoHAADbBwAA3AcAAN0HAADeBwAA3wcAAOAHAADhBwAA4gcAAOMHAADkBwAA5QcAAOYHAADnBwAA6AcAAOkHAAA=",
          "dtype": "i4"
         },
         "xaxis": "x",
         "y": {
          "bdata": "zczMzMzMnD9BuBv7HpGTP2gvob2E9pI/C5sDiVbYjD+0+lJBqy91P9WQARJPDXk/ZCELWchChj8g+IEf+IF/P08b6LSBTms/dKtkAN0qaT/3LB9kC8dsP2HIgSam0XY/Nt2lUMWtcz95FumjHDOMP0xyDXos9ow/vmNqYO+Yij9vmDHE7YaZP1tYG38FaJ0/gOV7l9Tioj/L9GX/b1KgPzpOKimrx6U/xB7etnbzpD+gCSwmJlOnP72M9kaevaQ/UuJnlPgZoT9L6LvvqqGgPw==",
          "dtype": "f8"
         },
         "yaxis": "y"
        },
        {
         "customdata": [
          [
           "graphs, rectilinear, polygon, graph, time",
           23,
           320
          ],
          [
           "graphs, graph, planar, edges, vertices",
           28,
           314
          ],
          [
           "graphs, graph, gg, problem, spanning",
           43,
           432
          ],
          [
           "graphs, graph, problem, edges, vertices",
           41,
           568
          ],
          [
           "graphs, graph, gg, problem, equivpiso",
           36,
           580
          ],
          [
           "graphs, graph, vertex, coloring, problem",
           35,
           654
          ],
          [
           "graphs, graph, packing, vertices, problem",
           56,
           644
          ],
          [
           "graphs, graph, vertices, gg, vertex",
           52,
           650
          ],
          [
           "graphs, graph, vertices, gg, problem",
           55,
           600
          ],
          [
           "graphs, graph, problem, gg, set",
           56,
           651
          ],
          [
           "graphs, graph, problem, gg, vertices",
           73,
           854
          ],
          [
           "graphs, graph, vertices, vertex, problem",
           112,
           1077
          ],
          [
           "graphs, graph, vertices, gg, vertex",
           134,
           1457
          ],
          [
           "graphs, graph, vertices, vertex, gg",
           146,
           1743
          ],
          [
           "graphs, graph, vertices, gg, problem",
           156,
           1980
          ],
          [
           "graphs, graph, gg, vertices, vertex",
           169,
           2156
          ],
          [
           "graphs, graph, vertices, gg, problem",
           185,
           2808
          ],
          [
           "graphs, graph, vertices, vertex, problem",
           226,
           3726
          ],
          [
           "graphs, graph, gg, vertices, problem",
           226,
           5178
          ],
          [
           "graphs, graph, gg, vertex, vertices",
           211,
           6807
          ],
          [
           "graphs, graph, gg, vertex, vertices",
           263,
           8980
          ],
          [
           "graphs, graph, gg, vertices, vertex",
           245,
           10435
          ],
          [
           "graphs, graph, vertex, gg, vertices",
           240,
           11173
          ],
          [
           "graphs, graph, gg, vertices, vertex",
           280,
           13355
          ],
          [
           "graphs, graph, vertices, gg, problem",
           299,
           17664
          ],
          [
           "graphs, graph, gg, vertices, vertex",
           312,
           19610
          ]
         ],
         "hovertemplate": "Topic=4<br>Timestamp=%{x}<br>Percentage=%{y}<br>Words=%{customdata[0]}<br>Frequency=%{customdata[1]}<br>Total=%{customdata[2]}<extra></extra>",
         "legendgroup": "4",
         "line": {
          "color": "#ab63fa",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "4",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": {
          "bdata": "0AcAANEHAADSBwAA0wcAANQHAADVBwAA1gcAANcHAADYBwAA2QcAANoHAADbBwAA3AcAAN0HAADeBwAA3wcAAOAHAADhBwAA4gcAAOMHAADkBwAA5QcAAOYHAADnBwAA6AcAAOkHAAA=",
          "dtype": "i4"
         },
         "xaxis": "x",
         "y": {
          "bdata": "ZmZmZmZmsj+hAUt6+dO2P7SX0F5Ce7k/U0/Gb5d6sj8OePzhgMevP2m2sXuOZqs/ZCELWchCtj97FK5H4Xq0P3d3d3d3d7c/BhZYYIEFtj8xCs3+BeK1P8Zpl9dBn7o/87pYN1WLtz9sPvlxiHG1PysUt0JxK7Q/HLIrLBkRtD/cDTOGuN2wP1lR0EwnDq8/U+MJTMtYpj8SzzIvz72fP/yfwcZ9/Z0/QWKJYMsKmD/X4A8v8v6VP6K+9cQXeJU/VVVVVVVVkT9pmn7LxkqQPw==",
          "dtype": "f8"
         },
         "yaxis": "y"
        },
        {
         "customdata": [
          [
           "vjlab, students, java, corr, plata",
           2,
           320
          ],
          [
           "software, debugger, coverage, code, section",
           4,
           314
          ],
          [
           "ifpug, ipfug, measurement, 41, fpa",
           2,
           432
          ],
          [
           "software, web, engineering, refactoring, code",
           11,
           568
          ],
          [
           "software, lap, jartege, opensource, macintosh",
           10,
           580
          ],
          [
           "software, requirements, debian, engineering, code",
           13,
           654
          ],
          [
           "software, crosscutting, networkcentric, concerns, mvc",
           10,
           644
          ],
          [
           "software, crosscutting, code, reuse, networkcentric",
           14,
           650
          ],
          [
           "array, java, arrays, restructured, restructuring",
           2,
           600
          ],
          [
           "software, nfrs, students, educational, code",
           13,
           651
          ],
          [
           "software, elearning, students, agile, code",
           20,
           854
          ],
          [
           "software, bug, engineering, teaching, projects",
           18,
           1077
          ],
          [
           "software, development, code, students, education",
           32,
           1457
          ],
          [
           "software, development, code, students, projects",
           45,
           1743
          ],
          [
           "software, students, code, development, projects",
           73,
           1980
          ],
          [
           "software, projects, code, development, students",
           48,
           2156
          ],
          [
           "software, code, students, development, projects",
           50,
           2808
          ],
          [
           "software, code, students, developers, development",
           106,
           3726
          ],
          [
           "software, code, projects, developers, development",
           158,
           5178
          ],
          [
           "software, code, students, developers, development",
           161,
           6807
          ],
          [
           "software, code, students, developers, development",
           195,
           8980
          ],
          [
           "software, code, developers, students, projects",
           274,
           10435
          ],
          [
           "software, code, developers, students, projects",
           259,
           11173
          ],
          [
           "code, software, students, developers, projects",
           364,
           13355
          ],
          [
           "code, software, students, llms, developers",
           561,
           17664
          ],
          [
           "code, software, students, llms, development",
           692,
           19610
          ]
         ],
         "hovertemplate": "Topic=5<br>Timestamp=%{x}<br>Percentage=%{y}<br>Words=%{customdata[0]}<br>Frequency=%{customdata[1]}<br>Total=%{customdata[2]}<extra></extra>",
         "legendgroup": "5",
         "line": {
          "color": "#FFA15A",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "5",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": {
          "bdata": "0AcAANEHAADSBwAA0wcAANQHAADVBwAA1gcAANcHAADYBwAA2QcAANoHAADbBwAA3AcAAN0HAADeBwAA3wcAAOAHAADhBwAA4gcAAOMHAADkBwAA5QcAAOYHAADnBwAA6AcAAOkHAAA=",
          "dtype": "i4"
         },
         "xaxis": "x",
         "y": {
          "bdata": "mpmZmZmZeT8CS3r50xaKP2gvob2E9nI/l3oyfrvUkz+WexphuaeRP61FoT7QWpQ/j+YPNh7Njz9Jx6evLQ6WP08b6LSBTms/TstRkNNylD95pcQoNPuXP0lW4Zw8HZE/YiHiyXN9lj8RharZ6m+aPzbosdhz4KI/EHrt5DrMlj+9I5FnzjuSP9wufYeqIZ0/cksJivw+nz/KnOEXQziYP299JMBvPJY/ufWgNVLjmj8KiaewuryXP9N3P7Pr6Js/ZCELWchCoD+luyHESBGiPw==",
          "dtype": "f8"
         },
         "yaxis": "y"
        },
        {
         "customdata": [
          [
           "quantum, classical, gates, complexity, computation",
           17,
           320
          ],
          [
           "quantum, classical, complexity, lower, bound",
           33,
           314
          ],
          [
           "quantum, classical, protocol, protocols, coin",
           27,
           432
          ],
          [
           "quantum, classical, entanglement, circuits, commitment",
           40,
           568
          ],
          [
           "quantum, classical, states, computation, complexity",
           67,
           580
          ],
          [
           "quantum, classical, codes, entanglement, states",
           60,
           654
          ],
          [
           "quantum, classical, codes, entanglement, states",
           39,
           644
          ],
          [
           "quantum, classical, codes, states, nonlocality",
           26,
           650
          ],
          [
           "quantum, codes, subsystem, classical, circuits",
           25,
           600
          ],
          [
           "quantum, classical, nosignaling, states, provers",
           22,
           651
          ],
          [
           "quantum, classical, codes, qubits, entanglementassisted",
           33,
           854
          ],
          [
           "quantum, classical, states, state, tensor",
           32,
           1077
          ],
          [
           "quantum, classical, channels, bell, codes",
           37,
           1457
          ],
          [
           "quantum, classical, entanglement, codes, circuits",
           59,
           1743
          ],
          [
           "quantum, classical, entanglement, codes, state",
           69,
           1980
          ],
          [
           "quantum, classical, states, entanglement, of",
           63,
           2156
          ],
          [
           "quantum, classical, of, circuits, circuit",
           71,
           2808
          ],
          [
           "quantum, classical, circuits, qubits, circuit",
           57,
           3726
          ],
          [
           "quantum, classical, states, qubits, circuits",
           89,
           5178
          ],
          [
           "quantum, classical, qubits, entanglement, circuits",
           124,
           6807
          ],
          [
           "quantum, classical, circuits, entanglement, qubits",
           188,
           8980
          ],
          [
           "quantum, classical, qubits, circuits, states",
           194,
           10435
          ],
          [
           "quantum, classical, circuits, circuit, states",
           235,
           11173
          ],
          [
           "quantum, classical, circuits, qubits, circuit",
           267,
           13355
          ],
          [
           "quantum, classical, circuits, circuit, qubits",
           404,
           17664
          ],
          [
           "quantum, classical, circuits, circuit, qubits",
           463,
           19610
          ]
         ],
         "hovertemplate": "Topic=6<br>Timestamp=%{x}<br>Percentage=%{y}<br>Words=%{customdata[0]}<br>Frequency=%{customdata[1]}<br>Total=%{customdata[2]}<extra></extra>",
         "legendgroup": "6",
         "line": {
          "color": "#19d3f3",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "6",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": {
          "bdata": "0AcAANEHAADSBwAA0wcAANQHAADVBwAA1gcAANcHAADYBwAA2QcAANoHAADbBwAA3AcAAN0HAADeBwAA3wcAAOAHAADhBwAA4gcAAOMHAADkBwAA5QcAAOYHAADnBwAA6AcAAOkHAAA=",
          "dtype": "i4"
         },
         "xaxis": "x",
         "y": {
          "bdata": "MzMzMzMzqz9aHUaZiue6PwAAAAAAALA/50CiFTYHsj+bKNm1iZK9P8h34SB6fLc/zIBPDpcBrz97FK5H4XqkP1VVVVVVVaU/4DVF8HdNoT/qbtXU18ijPywLrYjdbJ4/mnZt4Q0Bmj96QGfvvlShP9iReh2p16E/NbB3TA3snT9FnjnvSOSZP9l6bkSCVI8/MhLoGcKZkT+fzgZtW6eSP9Kq7rcXcJU//PQqo5cJkz8ojL94oomVP1t6s8fqeJQ/d2CuHZhrlz+NNXFQUy2YPw==",
          "dtype": "f8"
         },
         "yaxis": "y"
        },
        {
         "customdata": [
          [
           "retrieval, caption, natural, appear, anvil",
           1,
           320
          ],
          [
           "instructional, sheet, frames, board, podium",
           2,
           568
          ],
          [
           "transcript, transcripts, course, textbook, lectures",
           1,
           580
          ],
          [
           "presentation, augmented, segmented, audio, track",
           1,
           654
          ],
          [
           "figures, annotation, plsawords, imagined, keywords",
           2,
           600
          ],
          [
           "reranking, stl, interactive, video, search",
           1,
           1077
          ],
          [
           "emm, generativediscriminative, aia, semantic, video",
           2,
           1457
          ],
          [
           "tv, video, visual, catalogue, imagetags",
           4,
           1743
          ],
          [
           "video, visual, image, attractiveness, tags",
           7,
           1980
          ],
          [
           "visual, video, image, retrieval, multimodal",
           18,
           2156
          ],
          [
           "visual, video, image, captioning, multimodal",
           39,
           2808
          ],
          [
           "visual, image, video, multimodal, captioning",
           49,
           3726
          ],
          [
           "visual, captioning, image, video, multimodal",
           72,
           5178
          ],
          [
           "visual, image, multimodal, reasoning, video",
           105,
           6807
          ],
          [
           "visual, multimodal, video, captioning, image",
           135,
           8980
          ],
          [
           "visual, multimodal, video, captioning, image",
           150,
           10435
          ],
          [
           "visual, video, multimodal, visionlanguage, vqa",
           191,
           11173
          ],
          [
           "visual, multimodal, video, visionlanguage, image",
           327,
           13355
          ],
          [
           "visual, multimodal, video, visionlanguage, models",
           578,
           17664
          ],
          [
           "visual, multimodal, reasoning, video, visionlanguage",
           846,
           19610
          ]
         ],
         "hovertemplate": "Topic=7<br>Timestamp=%{x}<br>Percentage=%{y}<br>Words=%{customdata[0]}<br>Frequency=%{customdata[1]}<br>Total=%{customdata[2]}<extra></extra>",
         "legendgroup": "7",
         "line": {
          "color": "#FF6692",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "7",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": {
          "bdata": "0AcAANMHAADUBwAA1QcAANgHAADbBwAA3AcAAN0HAADeBwAA3wcAAOAHAADhBwAA4gcAAOMHAADkBwAA5QcAAOYHAADnBwAA6AcAAOkHAAA=",
          "dtype": "i4"
         },
         "xaxis": "x",
         "y": {
          "bdata": "mpmZmZmZaT8LmwOJVthsP/D4wwGPP1w/1ZABEk8NWT9PG+i0gU5rPywLrYjdbE4/YiHiyXN9Vj9QZJvCvcxiP0xyDXos9mw/jBuyKywZgT8cx3Ecx3GMP97ii8rS7oo/yebKLDd6jD/8n+5hTJePP5py987VyY4/w4I6pXtwjT+JPJZnS4GRP361DLumEpk/zLUDc+3AoD8JpQtKnBamPw==",
          "dtype": "f8"
         },
         "yaxis": "y"
        },
        {
         "customdata": [
          [
           "word, ngrams, relative, criterion, backoff",
           3,
           320
          ],
          [
           "trigram, perplexity, reductions, smoothing, kneserney",
           1,
           314
          ],
          [
           "backingoff, factorization, lattice, factorizations, factored",
           1,
           568
          ],
          [
           "irlm, lms, lcus, mrsc, irlms",
           1,
           1743
          ],
          [
           "gpgpus, optimizations, polyglot, language, mnih",
           3,
           1980
          ],
          [
           "gengencnn, word, history, dennlm, rnns",
           4,
           2156
          ],
          [
           "heldout, snm, metafeatures, leaveoneout, skipngram",
           3,
           2808
          ],
          [
           "rnn, language, recurrent, iog, nnlms",
           8,
           3726
          ],
          [
           "language, segmental, lms, models, rnn",
           16,
           5178
          ],
          [
           "language, models, attention, transformer, bert",
           35,
           6807
          ],
          [
           "bert, language, models, attention, tasks",
           63,
           8980
          ],
          [
           "language, models, transformer, attention, bert",
           95,
           10435
          ],
          [
           "language, models, tasks, finetuning, model",
           121,
           11173
          ],
          [
           "language, models, llms, finetuning, tasks",
           207,
           13355
          ],
          [
           "language, llms, models, finetuning, llm",
           557,
           17664
          ],
          [
           "language, llms, models, llm, large",
           832,
           19610
          ]
         ],
         "hovertemplate": "Topic=8<br>Timestamp=%{x}<br>Percentage=%{y}<br>Words=%{customdata[0]}<br>Frequency=%{customdata[1]}<br>Total=%{customdata[2]}<extra></extra>",
         "legendgroup": "8",
         "line": {
          "color": "#B6E880",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "8",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": {
          "bdata": "0AcAANEHAADTBwAA3QcAAN4HAADfBwAA4AcAAOEHAADiBwAA4wcAAOQHAADlBwAA5gcAAOcHAADoBwAA6QcAAA==",
          "dtype": "i4"
         },
         "xaxis": "x",
         "y": {
          "bdata": "MzMzMzMzgz8CS3r50xZqPwubA4lW2Fw/UGSbwr3MQj/TGDCNAdNYP2tN59ujZV4/EhiBERiBUT/qX4rnvZZhPwgGXwsxUGk//r9JQYgPdT8pnpEnYbx8P79B2BsbpYI/6jVj3t4thj9wfrSoXb6PP+JnlPgZJaA/jHhTDwm5pT8=",
          "dtype": "f8"
         },
         "yaxis": "y"
        },
        {
         "customdata": [
          [
           "radio, broadcasters, internet, broadcasting, diversity",
           2,
           314
          ],
          [
           "recommender, connectioncentric, viewpoint, systems, issuessuch",
           1,
           568
          ],
          [
           "ranking, matrix, user, completion, engine",
           4,
           644
          ],
          [
           "simrank, click, query, rewrites, queries",
           1,
           650
          ],
          [
           "slope, ratingbased, filtering, collaborative, user",
           1,
           600
          ],
          [
           "recommendation, ranking, divergencefree, hodge, helmholtzian",
           3,
           651
          ],
          [
           "ssnr, decay, timeaware, cf, itembased",
           2,
           854
          ],
          [
           "recommendation, comparisons, relevance, ranking, pairwise",
           4,
           1077
          ],
          [
           "movie, ratings, items, users, recommendation",
           9,
           1457
          ],
          [
           "ranking, recommendation, ndcg, click, user",
           10,
           1743
          ],
          [
           "recommendation, ranking, user, recommender, users",
           19,
           1980
          ],
          [
           "recommendation, items, ranking, recommender, recommendations",
           21,
           2156
          ],
          [
           "recommendation, recommender, user, item, users",
           44,
           2808
          ],
          [
           "recommendation, recommender, items, user, item",
           65,
           3726
          ],
          [
           "recommendation, recommender, user, items, users",
           102,
           5178
          ],
          [
           "recommendation, recommender, items, user, users",
           105,
           6807
          ],
          [
           "recommendation, recommender, user, items, users",
           141,
           8980
          ],
          [
           "recommendation, recommender, user, items, item",
           203,
           10435
          ],
          [
           "recommendation, recommender, user, items, item",
           173,
           11173
          ],
          [
           "recommendation, recommender, user, item, items",
           215,
           13355
          ],
          [
           "recommendation, recommender, user, items, item",
           291,
           17664
          ],
          [
           "recommendation, recommender, user, items, item",
           288,
           19610
          ]
         ],
         "hovertemplate": "Topic=9<br>Timestamp=%{x}<br>Percentage=%{y}<br>Words=%{customdata[0]}<br>Frequency=%{customdata[1]}<br>Total=%{customdata[2]}<extra></extra>",
         "legendgroup": "9",
         "line": {
          "color": "#FF97FF",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "9",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": {
          "bdata": "0QcAANMHAADWBwAA1wcAANgHAADZBwAA2gcAANsHAADcBwAA3QcAAN4HAADfBwAA4AcAAOEHAADiBwAA4wcAAOQHAADlBwAA5gcAAOcHAADoBwAA6QcAAA==",
          "dtype": "i4"
         },
         "xaxis": "x",
         "y": {
          "bdata": "Akt6+dMWej8LmwOJVthcP3K4DPjkcHk/5iybf8Y0WT9PG+i0gU5bP5eAS8Al4HI/+h1q7VwvYz8sC62I3WxuP45lHkMiTXk/ZT1CM+1/dz/8aBvlC6eDP87KT4iz8oM/uwBhZasLkD9qiSjfGN2RP864DxXnK5Q//J/uYUyXjz8dAPPJERSQP0QIpdOv65M/vn1Qe/K1jz89aarSNnyQP05vetOb3pA/mrrpKOUTjj8=",
          "dtype": "f8"
         },
         "yaxis": "y"
        },
        {
         "customdata": [
          [
           "ift, memory, watershed, buckets, implementation",
           1,
           432
          ],
          [
           "gel, electrophoresis, 2d, reflectance, serums",
           2,
           568
          ],
          [
           "fuzzy, selfperception, noise, attribute, breast",
           2,
           580
          ],
          [
           "discrete, noisecorrupted, channel, denoising, channels",
           2,
           654
          ],
          [
           "denoising, tomographic, graylevel, staircasing, functionals",
           5,
           644
          ],
          [
           "sdude, pedicle, eit, screws, computerassisted",
           6,
           650
          ],
          [
           "stone, catheter, ct, composition, lowdose",
           4,
           651
          ],
          [
           "image, intensity, images, twodimensional, registration",
           9,
           854
          ],
          [
           "segmentation, implant, bm3d, images, image",
           14,
           1077
          ],
          [
           "image, caelinux, images, imaging, nlm",
           16,
           1457
          ],
          [
           "image, segmentation, denoising, images, breast",
           22,
           1743
          ],
          [
           "image, segmentation, images, denoising, ct",
           25,
           1980
          ],
          [
           "image, segmentation, imaging, images, reconstruction",
           42,
           2156
          ],
          [
           "segmentation, image, images, ct, imaging",
           50,
           2808
          ],
          [
           "segmentation, image, images, medical, ct",
           144,
           3726
          ],
          [
           "segmentation, images, image, medical, ct",
           222,
           5178
          ],
          [
           "segmentation, images, image, medical, imaging",
           342,
           6807
          ],
          [
           "segmentation, image, images, medical, imaging",
           448,
           8980
          ],
          [
           "segmentation, medical, images, image, ct",
           505,
           10435
          ],
          [
           "segmentation, medical, image, images, imaging",
           552,
           11173
          ],
          [
           "segmentation, medical, image, images, imaging",
           671,
           13355
          ],
          [
           "segmentation, medical, image, images, imaging",
           928,
           17664
          ],
          [
           "segmentation, medical, image, imaging, images",
           980,
           19610
          ]
         ],
         "hovertemplate": "Topic=2<br>Timestamp=%{x}<br>Percentage=%{y}<br>Words=%{customdata[0]}<br>Frequency=%{customdata[1]}<br>Total=%{customdata[2]}<extra></extra>",
         "legendgroup": "2",
         "line": {
          "color": "#FECB52",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "2",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": {
          "bdata": "0gcAANMHAADUBwAA1QcAANYHAADXBwAA2QcAANoHAADbBwAA3AcAAN0HAADeBwAA3wcAAOAHAADhBwAA4gcAAOMHAADkBwAA5QcAAOYHAADnBwAA6AcAAOkHAAA=",
          "dtype": "i4"
         },
         "xaxis": "x",
         "y": {
          "bdata": "aC+hvYT2Yj8LmwOJVthsP/D4wwGPP2w/1ZABEk8NaT+P5g82Hs1/P61htN+U54I/dKtkAN0qeT+5YReLSJWFP8Zpl9dBn4o/YiHiyXN9hj/vqZXrhNmJPzFvZ0jM24k/zspPiLPykz+9I5FnzjuSP+ere6SVyaM/O2fch4rzpT+lc4scX7mpP7NTugYBi6k/U3JE3jTHqD8q3OuClkupPyPiQTl/uak/rh2Yawfmqj9MKlwOQpapPw==",
          "dtype": "f8"
         },
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "title": {
          "text": "Topic"
         },
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Topic Proportion Over Time"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Time"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Proportion"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = topics_over_time.copy()\n",
    "df = df[df['Topic'] != -1]\n",
    "totals = df.groupby(\"Timestamp\")[\"Frequency\"].sum().reset_index()\n",
    "totals = totals.rename(columns={\"Frequency\": \"Total\"})\n",
    "\n",
    "df = df.merge(totals, on=\"Timestamp\")\n",
    "df[\"Proportion\"] = df[\"Frequency\"] / df[\"Total\"] \n",
    "df[\"Percentage\"] = df[\"Proportion\"]\n",
    "\n",
    "topic_totals = df.groupby(\"Topic\")[\"Frequency\"].sum()\n",
    "top10 = topic_totals.sort_values(ascending=False).head(10).index.tolist()\n",
    "\n",
    "df_top10 = df[df[\"Topic\"].isin(top10)]\n",
    "\n",
    "\n",
    "fig = px.line(\n",
    "    df_top10,\n",
    "    x=\"Timestamp\",\n",
    "    y=\"Percentage\",\n",
    "    color=\"Topic\",\n",
    "    hover_data=[\"Words\", \"Frequency\", \"Total\"],\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Topic Proportion Over Time\",\n",
    "    yaxis_title=\"Proportion\",\n",
    "    xaxis_title=\"Time\",\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe48073",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f02783aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.utils import simple_preprocess\n",
    "from gensim.corpora import Dictionary\n",
    "from tqdm.notebook import tqdm\n",
    "from gensim.models import CoherenceModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d7e593df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8cfbe792b1345af8ebe1f08b2fd6ee5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing for Coherence:   0%|          | 0/159247 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize_for_coherence(text):\n",
    "    return [\n",
    "        token for token in simple_preprocess(str(text), deacc=True)\n",
    "    ]\n",
    "texts_for_coherence = [tokenize_for_coherence(text) for text in tqdm(data['text'], desc=\"Tokenizing for Coherence\")]\n",
    "dictionary_coherence = Dictionary(texts_for_coherence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "33c4a3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bertopic_topics(model, top_n=10):\n",
    "    topics_list = []\n",
    "    for topic_id in range(len(model.get_topic_info()) - 1): \n",
    "        words_scores = model.get_topic(topic_id)\n",
    "        if words_scores: \n",
    "            top_words = [word for word, score in words_scores[:top_n]]\n",
    "            topics_list.append(top_words)\n",
    "    return topics_list[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2d3d92fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Nov 19 21:00:52 2025 Building and compiling search function\n",
      "\n",
      "Skor Koherensi BERTopic all-minilml6: 0.7199\n",
      "Wed Nov 19 21:05:38 2025 Building and compiling search function\n",
      "\n",
      "Skor Koherensi BERTopic distilrobertav1: 0.7253\n",
      "Wed Nov 19 21:10:41 2025 Building and compiling search function\n",
      "\n",
      "Skor Koherensi BERTopic e5_basev2: 0.7057\n",
      "Wed Nov 19 21:15:11 2025 Building and compiling search function\n",
      "\n",
      "Skor Koherensi BERTopic mpnet_basev2: 0.7088\n"
     ]
    }
   ],
   "source": [
    "for m in ModelName.values():\n",
    "    bertopic = BERTopic.load(f\"model_results/bertopic/{m}_{SUBJECT}\") \n",
    "    all_topic_ids = bertopic.get_topics().keys()\n",
    "    bertopic_topics_list = [] \n",
    "    for topic_id in all_topic_ids:\n",
    "        topic_words = [word for word, _ in bertopic.get_topic(topic_id)]\n",
    "        bertopic_topics_list.append(topic_words)\n",
    "    bertopic_topics = get_bertopic_topics(bertopic, top_n=20)\n",
    "    cm_bertopic = CoherenceModel(\n",
    "        topics=bertopic_topics_list,        \n",
    "        texts=texts_for_coherence,\n",
    "        dictionary=dictionary_coherence, \n",
    "        coherence='c_v',   \n",
    "        processes=1\n",
    "    )\n",
    "    coherence_bertopic = cm_bertopic.get_coherence()\n",
    "    print(f\"\\nSkor Koherensi BERTopic {m}: {coherence_bertopic:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
