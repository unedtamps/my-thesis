{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "intro-markdown",
            "metadata": {},
            "source": [
                "# BERTopic Training with Pre-computed Embeddings\n",
                "\n",
                "This notebook loads pre-computed embeddings, trains BERTopic models for each subject and embedding combination, and evaluates coherence scores."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "id": "imports",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "from pathlib import Path\n",
                "from typing import List, Optional, Tuple\n",
                "from tqdm import tqdm\n",
                "import warnings\n",
                "\n",
                "from umap import UMAP\n",
                "from hdbscan import HDBSCAN\n",
                "from bertopic import BERTopic\n",
                "from gensim.utils import simple_preprocess\n",
                "from gensim.corpora import Dictionary\n",
                "from gensim.models import CoherenceModel\n",
                "\n",
                "pd.set_option('display.max_colwidth', None)\n",
                "warnings.filterwarnings(\"ignore\", category=SyntaxWarning)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "id": "config",
            "metadata": {},
            "outputs": [],
            "source": [
                "VERSION = \"v1\"\n",
                "LIST_SUBJECT = [\"cs\",\"math\", \"physics\"]\n",
                "\n",
                "TRANSFORMERS = [\n",
                "    \"sentence-transformers/all-MiniLM-L6-v2\",\n",
                "    \"all-distilroberta-v1\",\n",
                "    \"intfloat/e5-base-v2\",\n",
                "    \"all-mpnet-base-v2\", \n",
                "    \"BAAI/bge-base-en-v1.5\",\n",
                "    \"allenai/specter2\"\n",
                "]\n",
                "\n",
                "EMBEDDING_DIMS = {\n",
                "    \"sentence-transformers/all-MiniLM-L6-v2\": 384,\n",
                "    \"all-distilroberta-v1\": 768,\n",
                "    \"intfloat/e5-base-v2\": 768,\n",
                "    \"all-mpnet-base-v2\": 768,\n",
                "    \"BAAI/bge-base-en-v1.5\": 768,\n",
                "    \"allenai/specter2\": 768\n",
                "}\n",
                "\n",
                "BASE_DIR = Path(\"../../dataset\")\n",
                "EMBEDDING_DIR = Path(\"./embedding\")\n",
                "RESULT_DIR = Path(\"./transformer\")\n",
                "\n",
                "RESULT_DIR.mkdir(parents=True, exist_ok=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "helper-functions",
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_model_safe_name(model_name: str) -> str:\n",
                "    return model_name.replace(\"/\", \"_\").replace(\"-\", \"_\")\n",
                "\n",
                "\n",
                "def load_dataset(subject: str) -> pd.DataFrame:\n",
                "    file_path = BASE_DIR / subject / \"emb\" / f\"{VERSION}.csv\"\n",
                "    if not file_path.exists():\n",
                "        print(f\"File not found: {file_path}\")\n",
                "        return None\n",
                "    return pd.read_csv(file_path)\n",
                "\n",
                "\n",
                "def load_mmap_embeddings(\n",
                "    mmap_path: str,\n",
                "    num_documents: int,\n",
                "    embedding_dim: int,\n",
                "    dtype: str = \"float32\"\n",
                ") -> Optional[np.memmap]:\n",
                "    try:\n",
                "        embs = np.memmap(\n",
                "            mmap_path,\n",
                "            dtype=dtype,\n",
                "            mode=\"r\",\n",
                "            shape=(num_documents, embedding_dim)\n",
                "        )\n",
                "        return embs\n",
                "    except FileNotFoundError:\n",
                "        print(f\"Embedding not found: {mmap_path}\")\n",
                "        return None\n",
                "    except Exception as e:\n",
                "        print(f\"Error loading embeddings: {e}\")\n",
                "        return None\n",
                "\n",
                "\n",
                "def train_bertopic_model(\n",
                "    documents: List[str],\n",
                "    embeddings: np.ndarray,\n",
                "    n_neighbors: int = 15,\n",
                "    n_components: int = 5,\n",
                "    min_dist: float = 0.0,\n",
                "    min_cluster_size: int = 150,\n",
                "    min_samples: int = 10,\n",
                "    random_state: int = 42\n",
                ") -> Tuple[BERTopic, List[int], Optional[np.ndarray]]:\n",
                "    \n",
                "    umap_model = UMAP(\n",
                "        n_neighbors=n_neighbors,\n",
                "        n_components=n_components,\n",
                "        metric=\"cosine\",\n",
                "        random_state=random_state,\n",
                "        min_dist=min_dist,\n",
                "        verbose=False\n",
                "    )\n",
                "\n",
                "    hdbscan_model = HDBSCAN(\n",
                "        min_cluster_size=min_cluster_size,\n",
                "        min_samples=min_samples,\n",
                "        metric=\"euclidean\",\n",
                "        cluster_selection_method=\"eom\",\n",
                "        prediction_data=True\n",
                "    )\n",
                "\n",
                "    topic_model = BERTopic(\n",
                "        umap_model=umap_model,\n",
                "        hdbscan_model=hdbscan_model,\n",
                "        calculate_probabilities=False,\n",
                "        verbose=False\n",
                "    )\n",
                "\n",
                "    topics, probs = topic_model.fit_transform(documents, embeddings=embeddings)\n",
                "    return topic_model, topics, probs\n",
                "\n",
                "\n",
                "def tokenize_for_coherence(text: str) -> List[str]:\n",
                "    return [token for token in simple_preprocess(str(text), deacc=True)]\n",
                "\n",
                "\n",
                "def calculate_coherence(\n",
                "    topic_model: BERTopic,\n",
                "    texts_tokenized: List[List[str]],\n",
                "    dictionary: Dictionary,\n",
                "    top_n: int = 10\n",
                ") -> float:\n",
                "    all_topic_ids = topic_model.get_topics().keys()\n",
                "    topics_list = []\n",
                "    \n",
                "    for topic_id in all_topic_ids:\n",
                "        if topic_id == -1:\n",
                "            continue\n",
                "        topic_words = [word for word, _ in topic_model.get_topic(topic_id)[:top_n]]\n",
                "        topics_list.append(topic_words)\n",
                "    \n",
                "    if not topics_list:\n",
                "        return 0.0\n",
                "    \n",
                "    cm = CoherenceModel(\n",
                "        topics=topics_list,\n",
                "        texts=texts_tokenized,\n",
                "        dictionary=dictionary,\n",
                "        coherence='c_v',\n",
                "        processes=1\n",
                "    )\n",
                "    \n",
                "    return cm.get_coherence()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "load-data",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "math: 157,085 documents loaded\n",
                        "  Tokenizing for coherence...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "  math: 100%|██████████| 157085/157085 [00:17<00:00, 8975.04it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Total subjects loaded: 1\n"
                    ]
                }
            ],
            "source": [
                "all_data = {}\n",
                "all_texts_tokenized = {}\n",
                "all_dictionaries = {}\n",
                "\n",
                "for subject in LIST_SUBJECT:\n",
                "    df = load_dataset(subject)\n",
                "    if df is not None:\n",
                "        all_data[subject] = df\n",
                "        print(f\"{subject}: {len(df):,} documents loaded\")\n",
                "        \n",
                "        print(f\"  Tokenizing for coherence...\")\n",
                "        texts_tokenized = [tokenize_for_coherence(text) for text in tqdm(df['text'], desc=f\"  {subject}\")]\n",
                "        all_texts_tokenized[subject] = texts_tokenized\n",
                "        all_dictionaries[subject] = Dictionary(texts_tokenized)\n",
                "\n",
                "print(f\"\\nTotal subjects loaded: {len(all_data)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "run-bertopic",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "======================================================================\n",
                        "Subject: MATH (157,085 documents)\n",
                        "======================================================================\n",
                        "\n",
                        "[sentence-transformers/all-MiniLM-L6-v2]\n",
                        "  Training BERTopic...\n",
                        "  Topics found: 166\n",
                        "  Calculating coherence...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2026-02-14 13:20:31,944 - BERTopic - WARNING: When you use `pickle` to save/load a BERTopic model,please make sure that the environments in which you saveand load the model are **exactly** the same. The version of BERTopic,its dependencies, and python need to remain the same.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "  Coherence (c_v): 0.7221\n",
                        "  ✓ Saved to transformer/math/sentence_transformers_all_MiniLM_L6_v2_v1\n",
                        "\n",
                        "[all-distilroberta-v1]\n",
                        "  Training BERTopic...\n",
                        "  Topics found: 167\n",
                        "  Calculating coherence...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2026-02-14 13:24:17,087 - BERTopic - WARNING: When you use `pickle` to save/load a BERTopic model,please make sure that the environments in which you saveand load the model are **exactly** the same. The version of BERTopic,its dependencies, and python need to remain the same.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "  Coherence (c_v): 0.7115\n",
                        "  ✓ Saved to transformer/math/all_distilroberta_v1_v1\n",
                        "\n",
                        "[intfloat/e5-base-v2]\n",
                        "  Training BERTopic...\n",
                        "  Topics found: 127\n",
                        "  Calculating coherence...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2026-02-14 13:27:54,187 - BERTopic - WARNING: When you use `pickle` to save/load a BERTopic model,please make sure that the environments in which you saveand load the model are **exactly** the same. The version of BERTopic,its dependencies, and python need to remain the same.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "  Coherence (c_v): 0.7165\n",
                        "  ✓ Saved to transformer/math/intfloat_e5_base_v2_v1\n",
                        "\n",
                        "[all-mpnet-base-v2]\n",
                        "  Training BERTopic...\n",
                        "  Topics found: 165\n",
                        "  Calculating coherence...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2026-02-14 13:31:22,526 - BERTopic - WARNING: When you use `pickle` to save/load a BERTopic model,please make sure that the environments in which you saveand load the model are **exactly** the same. The version of BERTopic,its dependencies, and python need to remain the same.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "  Coherence (c_v): 0.7160\n",
                        "  ✓ Saved to transformer/math/all_mpnet_base_v2_v1\n",
                        "\n",
                        "[BAAI/bge-base-en-v1.5]\n",
                        "  Training BERTopic...\n",
                        "  Topics found: 150\n",
                        "  Calculating coherence...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2026-02-14 13:35:11,095 - BERTopic - WARNING: When you use `pickle` to save/load a BERTopic model,please make sure that the environments in which you saveand load the model are **exactly** the same. The version of BERTopic,its dependencies, and python need to remain the same.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "  Coherence (c_v): 0.7229\n",
                        "  ✓ Saved to transformer/math/BAAI_bge_base_en_v1.5_v1\n",
                        "\n",
                        "[allenai/specter2]\n",
                        "  Training BERTopic...\n",
                        "  Topics found: 1\n",
                        "  Calculating coherence...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2026-02-14 13:37:53,469 - BERTopic - WARNING: When you use `pickle` to save/load a BERTopic model,please make sure that the environments in which you saveand load the model are **exactly** the same. The version of BERTopic,its dependencies, and python need to remain the same.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "  Coherence (c_v): 0.4117\n",
                        "  ✓ Saved to transformer/math/allenai_specter2_v1\n",
                        "\n",
                        "======================================================================\n",
                        "All training complete!\n",
                        "======================================================================\n"
                    ]
                }
            ],
            "source": [
                "results = []\n",
                "\n",
                "for subject, df in all_data.items():\n",
                "    print(f\"\\n{'='*70}\")\n",
                "    print(f\"Subject: {subject.upper()} ({len(df):,} documents)\")\n",
                "    print(f\"{'='*70}\")\n",
                "    \n",
                "    texts = df[\"text\"].fillna(\"\").tolist()\n",
                "    texts_tokenized = all_texts_tokenized[subject]\n",
                "    dictionary = all_dictionaries[subject]\n",
                "    \n",
                "    subject_result_dir = RESULT_DIR / subject\n",
                "    subject_result_dir.mkdir(parents=True, exist_ok=True)\n",
                "    \n",
                "    for model_name in TRANSFORMERS:\n",
                "        model_safe_name = get_model_safe_name(model_name)\n",
                "\n",
                "        embedding_path = str(EMBEDDING_DIR / subject / f\"{model_safe_name}_{VERSION}.mmap\")\n",
                "        model_save_path = str(subject_result_dir / f\"{model_safe_name}_{VERSION}\")\n",
                "        print(f\"\\n[{model_name}]\")\n",
                "        \n",
                "        if os.path.exists(model_save_path):\n",
                "            print(f\"  Loading existing model...\")\n",
                "            try:\n",
                "                topic_model = BERTopic.load(model_save_path)\n",
                "                n_topics = len(topic_model.get_topic_info()) - 1\n",
                "                coherence = calculate_coherence(topic_model, texts_tokenized, dictionary)\n",
                "                print(f\"  Topics: {n_topics} | Coherence: {coherence:.4f}\")\n",
                "                results.append({\n",
                "                    \"subject\": subject,\n",
                "                    \"model\": model_name,\n",
                "                    \"n_topics\": n_topics,\n",
                "                    \"coherence\": coherence\n",
                "                })\n",
                "                continue\n",
                "            except Exception as e:\n",
                "                print(f\"  Failed to load, retraining: {e}\")\n",
                "        \n",
                "        emb_dim = EMBEDDING_DIMS[model_name]\n",
                "        embeddings = load_mmap_embeddings(embedding_path, len(texts), emb_dim)\n",
                "        \n",
                "        if embeddings is None:\n",
                "            print(f\"  Skipping (no embeddings)\")\n",
                "            continue\n",
                "        \n",
                "        print(f\"  Training BERTopic...\")\n",
                "        try:\n",
                "            topic_model, topics, probs = train_bertopic_model(texts, embeddings)\n",
                "            n_topics = len(topic_model.get_topic_info()) - 1\n",
                "            print(f\"  Topics found: {n_topics}\")\n",
                "            \n",
                "            print(f\"  Calculating coherence...\")\n",
                "            coherence = calculate_coherence(topic_model, texts_tokenized, dictionary)\n",
                "            print(f\"  Coherence (c_v): {coherence:.4f}\")\n",
                "            \n",
                "            topic_model.save(model_save_path)\n",
                "            print(f\"  ✓ Saved to {model_save_path}\")\n",
                "            \n",
                "            results.append({\n",
                "                \"subject\": subject,\n",
                "                \"model\": model_name,\n",
                "                \"n_topics\": n_topics,\n",
                "                \"coherence\": coherence\n",
                "            })\n",
                "            \n",
                "            del embeddings, topic_model\n",
                "            import gc\n",
                "            gc.collect()\n",
                "            \n",
                "        except Exception as e:\n",
                "            print(f\"  ✗ Error: {e}\")\n",
                "            results.append({\n",
                "                \"subject\": subject,\n",
                "                \"model\": model_name,\n",
                "                \"n_topics\": None,\n",
                "                \"coherence\": None,\n",
                "                \"error\": str(e)\n",
                "            })\n",
                "\n",
                "print(\"\\n\" + \"=\"*70)\n",
                "print(\"All training complete!\")\n",
                "print(\"=\"*70)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "id": "show-results",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "======================================================================\n",
                        "COHERENCE SCORE SUMMARY\n",
                        "======================================================================\n",
                        "\n",
                        "subject                                   math    mean\n",
                        "model                                                 \n",
                        "BAAI/bge-base-en-v1.5                   0.7229  0.7229\n",
                        "sentence-transformers/all-MiniLM-L6-v2  0.7221  0.7221\n",
                        "intfloat/e5-base-v2                     0.7165  0.7165\n",
                        "all-mpnet-base-v2                       0.7160  0.7160\n",
                        "all-distilroberta-v1                    0.7115  0.7115\n",
                        "allenai/specter2                        0.4117  0.4117\n",
                        "\n",
                        "Results saved to: transformer/coherence_results_v1.csv\n"
                    ]
                }
            ],
            "source": [
                "results_df = pd.DataFrame(results)\n",
                "results_df.to_csv(RESULT_DIR / f\"coherence_results_{VERSION}.csv\", index=False)\n",
                "\n",
                "print(\"\\n\" + \"=\"*70)\n",
                "print(\"COHERENCE SCORE SUMMARY\")\n",
                "print(\"=\"*70 + \"\\n\")\n",
                "\n",
                "if len(results_df) > 0:\n",
                "    pivot = results_df.pivot(index='model', columns='subject', values='coherence')\n",
                "    pivot['mean'] = pivot.mean(axis=1)\n",
                "    pivot = pivot.sort_values('mean', ascending=False)\n",
                "    print(pivot.round(4))\n",
                "    \n",
                "    print(f\"\\nResults saved to: {RESULT_DIR / f'coherence_results_{VERSION}.csv'}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "id": "2c042618",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Top 2 Models per Subject:\n",
                        "--------------------------------------------------------------------------------------------------------------\n",
                        "CS         | #1 | all-distilroberta-v1                          | 0.7322\n",
                        "CS         | #2 | intfloat/e5-base-v2                           | 0.7242\n",
                        "CS         | #3 | allenai/specter2                              | 0.7210\n",
                        "CS         | #4 | BAAI/bge-base-en-v1.5                         | 0.7198\n",
                        "CS         | #5 | sentence-transformers/all-MiniLM-L6-v2        | 0.7148\n",
                        "CS         | #6 | all-mpnet-base-v2                             | 0.7146\n",
                        "--------------------------------------------------------------------------------------------------------------\n",
                        "MATH       | #1 | BAAI/bge-base-en-v1.5                         | 0.7229\n",
                        "MATH       | #2 | sentence-transformers/all-MiniLM-L6-v2        | 0.7221\n",
                        "MATH       | #3 | intfloat/e5-base-v2                           | 0.7165\n",
                        "MATH       | #4 | all-mpnet-base-v2                             | 0.7160\n",
                        "MATH       | #5 | all-distilroberta-v1                          | 0.7115\n",
                        "MATH       | #6 | allenai/specter2                              | 0.4117\n",
                        "--------------------------------------------------------------------------------------------------------------\n",
                        "PHYSICS    | #1 | all-distilroberta-v1                          | 0.7387\n",
                        "PHYSICS    | #2 | all-mpnet-base-v2                             | 0.7336\n",
                        "PHYSICS    | #3 | BAAI/bge-base-en-v1.5                         | 0.7331\n",
                        "PHYSICS    | #4 | sentence-transformers/all-MiniLM-L6-v2        | 0.7327\n",
                        "PHYSICS    | #5 | allenai/specter2                              | 0.7253\n",
                        "PHYSICS    | #6 | intfloat/e5-base-v2                           | 0.7220\n",
                        "--------------------------------------------------------------------------------------------------------------\n"
                    ]
                }
            ],
            "source": [
                "print(\"\\nTop 2 Models per Subject:\")\n",
                "print(\"-\" * 110)\n",
                "results_df = pd.read_csv(f\"{RESULT_DIR}/coherence_results_{VERSION}.csv\")\n",
                "\n",
                "for subject in LIST_SUBJECT:\n",
                "    subject_results = results_df[results_df['subject'] == subject]\n",
                "    if len(subject_results) > 0 and subject_results['coherence'].notna().any():\n",
                "        top2 = subject_results.nlargest(6, 'coherence')\n",
                "        for rank, (_, row) in enumerate(top2.iterrows(), 1):\n",
                "            print(f\"{subject.upper():10s} | #{rank} | {row['model']:45s} | {row['coherence']:.4f}\")\n",
                "        print(\"-\" * 110)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "id": "36fc8909",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "===================================================================================================================\n",
                        "MODEL RANKING BY COHERENCE SCORE\n",
                        "===================================================================================================================\n",
                        "\n",
                        "Model                                        |       CS (Score)|     MATH (Score)|  PHYSICS (Score)|    MEAN |  TOTAL | RANK\n",
                        "-------------------------------------------------------------------------------------------------------------------\n",
                        "all-distilroberta-v1                         | 0.7322  (6)  | 0.7115  (2)  | 0.7387  (6)  | 0.7274  |   14   |  #1\n",
                        "BAAI/bge-base-en-v1.5                        | 0.7198  (3)  | 0.7229  (6)  | 0.7331  (4)  | 0.7253  |   13   |  #2\n",
                        "sentence-transformers/all-MiniLM-L6-v2       | 0.7148  (2)  | 0.7221  (5)  | 0.7327  (3)  | 0.7232  |   10   |  #3\n",
                        "intfloat/e5-base-v2                          | 0.7242  (5)  | 0.7165  (4)  | 0.7220  (1)  | 0.7209  |   10   |  #3\n",
                        "all-mpnet-base-v2                            | 0.7146  (1)  | 0.7160  (3)  | 0.7336  (5)  | 0.7214  |    9   |  #5\n",
                        "allenai/specter2                             | 0.7210  (4)  | 0.4117  (1)  | 0.7253  (2)  | 0.6193  |    7   |  #6\n",
                        "===================================================================================================================\n",
                        "\n",
                        "Scoring: 6 = best coherence per subject, 1 = worst\n"
                    ]
                }
            ],
            "source": [
                "import pandas as pd\n",
                "\n",
                "results_df = pd.read_csv(\"./transformer/coherence_results_v1.csv\")\n",
                "\n",
                "def rank_models(df):\n",
                "    scored = df.copy()\n",
                "    \n",
                "    # For each subject, rank coherence: 6 = highest, 1 = lowest\n",
                "    scored['score'] = scored.groupby('subject')['coherence'].rank(method='min').astype(int)\n",
                "    \n",
                "    # Pivot to show scores per subject\n",
                "    score_pivot = scored.pivot(index='model', columns='subject', values='score')\n",
                "    score_pivot.columns = [f\"{col}_score\" for col in score_pivot.columns]\n",
                "    \n",
                "    # Pivot coherence values too for reference\n",
                "    coherence_pivot = scored.pivot(index='model', columns='subject', values='coherence')\n",
                "    coherence_pivot.columns = [f\"{col}_coherence\" for col in coherence_pivot.columns]\n",
                "    \n",
                "    # Merge and calculate total\n",
                "    ranking = pd.concat([coherence_pivot, score_pivot], axis=1)\n",
                "    ranking['mean_coherence'] = coherence_pivot.mean(axis=1)\n",
                "    ranking['total_score'] = score_pivot.sum(axis=1).astype(int)\n",
                "    ranking['overall_rank'] = ranking['total_score'].rank(ascending=False, method='min').astype(int)\n",
                "    ranking = ranking.sort_values('overall_rank')\n",
                "    \n",
                "    return ranking\n",
                "\n",
                "ranking = rank_models(results_df)\n",
                "\n",
                "# Display\n",
                "subjects = [\"cs\", \"math\", \"physics\"]\n",
                "print(\"=\" * 115)\n",
                "print(\"MODEL RANKING BY COHERENCE SCORE\")\n",
                "print(\"=\" * 115)\n",
                "print(f\"\\n{'Model':<45}\", end=\"\")\n",
                "for s in subjects:\n",
                "    print(f\"| {s.upper():>8} (Score)\", end=\"\")\n",
                "print(f\"| {'MEAN':>7} | {'TOTAL':>6} | {'RANK':>4}\")\n",
                "print(\"-\" * 115)\n",
                "\n",
                "for model, row in ranking.iterrows():\n",
                "    print(f\"{model:<45}\", end=\"\")\n",
                "    for s in subjects:\n",
                "        print(f\"| {row[f'{s}_coherence']:.4f}  ({int(row[f'{s}_score'])})\", end=\"  \")\n",
                "    print(f\"| {row['mean_coherence']:.4f}  |   {int(row['total_score']):>2}   |  #{int(row['overall_rank'])}\")\n",
                "\n",
                "print(\"=\" * 115)\n",
                "print(\"\\nScoring: 6 = best coherence per subject, 1 = worst\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.11"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
